<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>hexo搭建个人博客</title>
      <link href="/2023/07/23/hexoBuild/"/>
      <url>/2023/07/23/hexoBuild/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>​本篇笔记将手把手从0到1搭建属于自己的个人博客，大部分都有图解，博客使用技术为hexo，使用主题为matery，当然还有其他主题可以进行选择，其他主题配置应该也大致相同，主题链接：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a>   官网链接： <a href="https://hexo.io/">https://hexo.io</a>    </p><p>​本篇笔记暂时不进行将博客部署至服务器，后期会部署，笔记会更新，目前个人博客跑到github上；</p><p>​博客搭建至美化前用了两个小时，搭建博客+笔记编写，难度不大很简单，推荐搞一个自己的博客，耐心搞就完事了，不需要动什么脑子，就是配置多，不懂就问吧</p><p>​我的博客链接：<a href="https://anwenyy.github.io/">https://anwenyy.github.io</a></p><p>​笔记的美化与配置很多不是正确的，参照链接：<a href="https://blog.csdn.net/kuashijidexibao/article/details/112971657?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-112971657-blog-112271581.235v38pc_relevant_default_base&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3">https://blog.csdn.net/kuashijidexibao/article/details/112971657?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-112971657-blog-112271581.235v38pc_relevant_default_base&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3</a></p><p>​可以自行去网上搜美化教程，搜索关键字：Matery美化</p><h2 id="个人博客的好处"><a href="#个人博客的好处" class="headerlink" title="个人博客的好处"></a>个人博客的好处</h2><ul><li><p>可以装杯！</p></li><li><p>拥有一个属于自己的个人博客，感觉还是很美好的</p></li><li><p>作为一个记录文档，笔记的地方</p></li><li><p>面试，相信一个好的个人博客比简历上密密麻麻的字要好很多，并且你可以在博客中放一些表示自己经验或者很牛逼的文章，以此来包装自己</p></li></ul><h2 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h2><p><a href="https://link.zhihu.com/?target=https://hexo.io/zh-cn/">Hexo</a>是一个快速、简洁且高效的博客框架。Hexo 使用 <a href="https://link.zhihu.com/?target=http://daringfireball.net/projects/markdown/">Markdown</a>（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。即把用户的markdown文件，按照指定的主题解析成静态网页。</p><p><strong>个人理解：</strong>你想要自己搭一个博客，如果自己写前后端，将会是一个漫长且复杂困难的事情，而使用hexo，只需要利用它搭建好框架，就可以生成一个个人博客，当然这个博客没有后台，一切改动包括美化都在配置文件中进行配置</p><h2 id="matery"><a href="#matery" class="headerlink" title="matery"></a>matery</h2><p>matery是hexo博客框架中的一个主题，而hexo中还有很多的主题，这个主题是我看着挺顺眼的一个主题，hexo官网的主题里matery已经不能访问了，下面是一些已经搭建好的以matery为主题的个人博客</p><p><a href="https://tianjuewudi.gitee.io/">https://tianjuewudi.gitee.io/</a>微笑紫瞳星</p><p><a href="https://wzz778.github.io/github_personal_blog/">https://wzz778.github.io/github_personal_blog/</a>阿泽</p><p><a href="https://blog.hitushen.cn/">https://blog.hitushen.cn/</a>途深</p><h1 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h1><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li><p>很多命令既可以用Windows的cmd来完成，也可以使用git bash来完成，但是部分命令会有一些问题，为避免不必要的问题，建议全部使用git bash来执行</p></li><li><p>hexo不同版本差别比较大，网上很多文章的配置信息都是基于2.x的，所以注意不要被误导</p></li><li><p>hexo有2种_config.yml文件，一个是根目录下的全局的_config.yml，一个是各个theme下的</p></li></ul><h2 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h2><h3 id="下载并安装node-js"><a href="#下载并安装node-js" class="headerlink" title="下载并安装node.js"></a><strong>下载并安装node.js</strong></h3><p>官网下载：<a href="https://nodejs.org/en/">https://nodejs.org/en/</a></p><p>安装与使用：这个网上自己搜</p><p>安装后验证：node -v </p><p><img src="/./images/image-20230722091738569.png" alt="image-20230722091738569"></p><h3 id="下载并安装git"><a href="#下载并安装git" class="headerlink" title="下载并安装git"></a>下载并安装git</h3><p>官网下载:  <a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a></p><p>安装与使用：这个网上自己搜</p><p>安装后验证：git -v</p><p><img src="/./images/image-20230722091840043.png" alt="image-20230722091840043"></p><h3 id="命令行安装cnpm"><a href="#命令行安装cnpm" class="headerlink" title="命令行安装cnpm"></a>命令行安装cnpm</h3><p>命令：npm install -g cnpm –registry==<a href="https://registry.npm.taobao.org/">https://registry.npm.taobao.org</a></p><p>安装后验证：cnpm -v </p><p><img src="/./images/image-20230722091932772.png" alt="image-20230722091932772"></p><h3 id="命令行安装hexo"><a href="#命令行安装hexo" class="headerlink" title="命令行安装hexo"></a>命令行安装hexo</h3><p>命令：cnpm install -g hexo-cli</p><p>安装后验证：hexo  -v</p><h2 id="配置github"><a href="#配置github" class="headerlink" title="配置github"></a>配置github</h2><h3 id="在github上创建仓库"><a href="#在github上创建仓库" class="headerlink" title="在github上创建仓库"></a>在github上创建仓库</h3><p><strong>创建：</strong></p><ul><li><p>打开github登录自己的账号</p></li><li><p>打开您的存储库  Your projects  <img src="/./images/image-20230722095334261.png" alt="image-20230722095334261"></p></li><li><p>新建一个名为你的用户名.github.io的仓库<img src="/./images/image-20230722095643250.png" alt="image-20230722095643250"></p></li><li><p>比如说，如果你的github用户名是test，那么你就新建test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 <a href="http://test.github.io/">http://test.github.io</a> 了，是不是很方便？由此可见，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。</p><ul><li>这里图放错了，存储库名称少了**.github.io<strong>，全称应该是</strong>anwenyy.github.io**</li></ul></li></ul><p><img src="/./images/image-20230722095716871.png" alt="image-20230722095716871"></p><p><strong>注意事项：</strong></p><ul><li>注册的邮箱一定要验证，否则不会成功；</li><li>仓库名字必须是：username.github.io，其中username是你的用户名；</li><li>仓库创建成功不会立即生效，需要过一段时间，大概10-30分钟，或者更久；</li></ul><p>创建成功后，默认会在你这个仓库里生成一些示例页面，以后你的网站所有代码都是放在这个仓库里啦。</p><h3 id="配置SSH免密登录"><a href="#配置SSH免密登录" class="headerlink" title="配置SSH免密登录"></a>配置SSH免密登录</h3><p>为什么要配置这个呢？因为你提交代码肯定要拥有你的github权限才可以，但是直接使用用户名和密码太不安全了，所以我们使用ssh key来解决本地和服务器的连接问题。 </p><p><strong>操作步骤：</strong></p><p>第一步：首先打开电脑文件夹，找到C:\Users\张三\.ssh文件夹并删除</p><p>第二步：在C:\Users\张三文件夹下右键打开Git Bash Here输入命令：ssh-keygen -t rsa -C github邮件地址   生成.ssh秘钥，输入后连敲三次回车，出现下图情况代表成功 </p><p><img src="/./images/image-20230722100619590.png" alt="image-20230722100619590"></p><p>第三步：最终生成了一个新的 C:\Users\王海洋.ssh文件夹，打开这个文件夹，找到.ssh\id_rsa.pub文件，记事本打开并复制里面的内容</p><p>第四步：打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key，把复制的内容粘贴进去，title随便填，保存即可，我们的公钥就添加成功了，设置好如下图： </p><p><img src="/./images/image-20230722101458057.png" alt="image-20230722101458057"></p><p><img src="/./images/image-20230722101526777.png" alt="image-20230722101526777"></p><p><img src="/./images/image-20230722101539955.png" alt="image-20230722101539955"></p><p>第五步：检测是否设置成功：</p><p>输入命令：  $ ssh -T <a href="mailto:git@github.com">git@github.com</a> # 注意邮箱地址不用改</p><p>如果提示Are you sure you want to continue connecting (yes/no)?，输入yes，然后会看到：</p><p>Hi liuxianan! You’ve successfully authenticated, but GitHub does not provide shell access.</p><p>看到这个信息说明SSH已配置成功！</p><p><img src="/./images/image-20230722101733524.png" alt="image-20230722101733524"></p><p>第六步：此时你还需要配置：</p><p>$ git config –global user.name “liuxianan”// 你的github用户名，非昵称$ git config –global user.email  “<a href="mailto:xxx@qq.com">xxx@qq.com</a>“// 填写你的github注册邮箱 </p><h1 id="使用hexo搭建博客"><a href="#使用hexo搭建博客" class="headerlink" title="使用hexo搭建博客"></a>使用hexo搭建博客</h1><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p><strong>第一步</strong>：在电脑的某个地方新建一个名为hexo的文件夹（名字可以随便取），比如我的是F:\个人博客\hexo，由于这个文件夹将来就作为你存放代码的地方，所以最好不要随便放</p><p><strong>第二步</strong>：在F:\个人博客\hexo文件夹下右键打开 Git Bash Here，输入hexo init 初始化 </p><ul><li>hexo会自动下载一些文件到这个目录，包括node_modules，目录结构如下图：</li></ul><p><img src="/./images/image-20230722102241830.png" alt="image-20230722102241830"></p><p><strong>第三步</strong>：执行以下命令之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github去的： </p><p><img src="/./images/image-20230722102407856.png" alt="image-20230722102407856"></p><p>第四步：hexo s 是开启本地预览服务，打开浏览器访问 <a href="http://localhost:4000/">http://localhost:4000</a> 即可看到内容，很多人会碰到浏览器一直在转圈但是就是加载不出来的问题，一般情况下是因为端口占用的缘故，因为4000这个端口太常见了，解决端口冲突问题请参考这篇文章<a href="https://www.runoob.com/w3cnote/windows-finds-port-usage.html">https://www.runoob.com/w3cnote/windows-finds-port-usage.html</a> </p><p><img src="/./images/image-20230722102422823.png" alt="image-20230722102422823"></p><ul><li>到这里就初始化完成啦！</li></ul><h2 id="将博客部署到-github-个人主页上"><a href="#将博客部署到-github-个人主页上" class="headerlink" title="将博客部署到 github 个人主页上"></a>将博客部署到 github 个人主页上</h2><p><strong>第一步</strong>：在F:\个人博客\hexo目录下安装 hexo-deployer-git 插件</p><ul><li><p>安装命令： npm install hexo-deployer-git –save  </p></li><li><p>必须安装，否则执行hexo d 的话会报如下错误：<img src="/./images/image-20230722102520524.png" alt="image-20230722102520524"></p></li></ul><p><strong>第二步</strong>：编辑F:\个人博客\hexo目录下的 _config.yml 文件, 在文件末尾添加如下内容：</p><p><img src="/./images/image-20230722102555752.png" alt="image-20230722102555752"></p><pre><code class="xml">deploy:  type: git  repository: git@github.com:RecluseW/RecluseW.github.io.git  branch: master</code></pre><ul><li>注意：其中 repo 中的内容即为 github 个人主页链接地址，具体看下图：</li></ul><p><img src="/./images/image-20230722102912568.png" alt="image-20230722102912568"></p><p><strong>第三步</strong>：在F:\个人博客\hexo目录下, 输入命令：hexo d 将本地 blog 推送到 github仓库, 也可能需要输入 username &amp; pwd。 </p><ul><li>推送成功后, 在浏览器中输入对应域名, 即可访问 <a href="https://anwenyy.github.io/">https://anwenyy.github.io/</a></li></ul><p><img src="/./images/image-20230722103812768.png" alt="image-20230722103812768"></p><ul><li>OK!到这里你已经成功一大步，接下来再搞一下主题，就要成功了！<img src="/./images/image-20230722103943586.png" alt="image-20230722103943586"></li></ul><h1 id="更换主题"><a href="#更换主题" class="headerlink" title="更换主题"></a>更换主题</h1><h2 id="寻找主题"><a href="#寻找主题" class="headerlink" title="寻找主题"></a>寻找主题</h2><ul><li><p>既然默认主题很丑，那我们别的不做，首先来替换一个好看点的主题。</p></li><li><p>这是hexo官网：<a href="https://hexo.io/themes/%EF%BC%8C%E5%8F%AF%E5%9C%A8%E9%87%8C%E9%9D%A2%E4%B8%8B%E8%BD%BD%E4%B8%BB%E9%A2%98%EF%BC%8C%E7%82%B9%E5%87%BB%E4%B8%BB%E9%A2%98%E5%90%8D%E5%8D%B3%E5%8F%AF%E8%B7%B3%E8%BD%AC%E5%88%B0github%E4%B8%8A%EF%BC%8C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E5%9C%A8github%E4%B8%8A%E6%90%9C%E7%B4%A2%E4%B8%BB%E9%A2%98">https://hexo.io/themes/，可在里面下载主题，点击主题名即可跳转到github上，也可以直接在github上搜索主题</a></p></li><li><p>在这里我使用github上一个大佬的主题blinkfox/hexo-theme-matery</p></li><li><p>链接：<a href="https://github.com/blinkfox/hexo-theme-matery">https://github.com/blinkfox/hexo-theme-matery</a></p></li></ul><h2 id="下载主题"><a href="#下载主题" class="headerlink" title="下载主题"></a>下载主题</h2><p>第一步：Git Bash Here中先cd到E:\xpzsData\hexocode目录</p><p>第二步：再输入命令 $ git clone 主题http链接  themes/主题名称<img src="/./images/image-20230722104131543.png" alt="image-20230722104131543"><img src="/./images/image-20230722104359233.png" alt="image-20230722104359233"></p><p>注意：</p><ul><li>F:\个人博客\hexo目录下的 theme 文件夹下存放的就是博客的主题，主题是否下载成功可到该目录下查看：</li></ul><p><img src="/./images/image-20230722104433840.png" alt="image-20230722104433840"></p><h2 id="使用主题"><a href="#使用主题" class="headerlink" title="使用主题"></a>使用主题</h2><ul><li><p>打开F:\个人博客\hexo目录下的_config.yml文件，在里面找到theme: landscape改为theme: matery（matery为我们要使用的主题名）,然后重新执行hexo g来重新生成,再运行hexo s来运行<img src="/./images/image-20230722105447620.png" alt="image-20230722105447620"><img src="/./images/image-20230722105524760.png" alt="image-20230722105524760"><img src="/./images/image-20230722105722645.png" alt="image-20230722105722645"></p></li><li><p>如果出现一些莫名其妙的问题，可以先执行hexo clean来清理一下public的内容，然后再执行hexo g 和 hexo s 重新生成和发布。</p></li><li><p>再次在浏览器中输入对应域名, 即可发现主题已更换</p></li></ul><h2 id="修改主题内容"><a href="#修改主题内容" class="headerlink" title="修改主题内容"></a>修改主题内容</h2><p>在这里我使用的是blinkfox主题，后期相关修改参考这个主题文档</p><p>文档链接：<a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md</a></p><ul><li><p>注意：一些非md文件可以把他们放到source文件夹下，这里的所有文件都会原样复制（除了md文件）到public目录的</p></li><li><p>大致在下图的文件夹里面修改文件，记得修改后的文件需要关闭后，再在hexocode根目录右键打开Git Bash Here，输入两个命令：hexo g 重新生成，hexo s 开启本地预览服务,等修改的符合要求了，再输入 hexo d 推送到github仓库即可</p></li><li><p>这样就可以输入网址查看更改后的内容了</p></li></ul><h1 id="美化与配置"><a href="#美化与配置" class="headerlink" title="美化与配置"></a>美化与配置</h1><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>下载blinkfox主题</p><p>下载链接：<a href="https://codeload.github.com/blinkfox/hexo-theme-matery/zip/master">https://codeload.github.com/blinkfox/hexo-theme-matery/zip/master</a></p><p>下载载 <code>master</code> 分支的最新稳定版的代码，解压缩后，将 <code>hexo-theme-matery</code> 的文件夹复制到你 Hexo 的 <code>themes</code> 文件夹中即可。</p><p>当然你也可以在你的 <code>themes</code> 文件夹下使用 <code>git clone</code> 命令来下载:</p><pre><code class="git">git clone https://github.com/blinkfox/hexo-theme-matery.git</code></pre><h2 id="切换主题"><a href="#切换主题" class="headerlink" title="切换主题"></a>切换主题</h2><p>修改 Hexo 根目录下的 <code>_config.yml</code> 的  <code>theme</code> 的值：<code>theme: hexo-theme-matery</code></p><ul><li>请修改 <code>_config.yml</code> 的 <code>url</code> 的值为你的网站主 <code>URL</code>（如：<code>http://xxx.github.io</code>）。</li><li>建议修改两个 <code>per_page</code> 的分页条数值为 <code>6</code> 的倍数，如：<code>12</code>、<code>18</code> 等，这样文章列表在各个屏幕下都能较好的显示。</li><li>如果你是中文用户，则建议修改 <code>language</code> 的值为 <code>zh-CN</code>。</li></ul><p>到这里我用了差不多2个小时</p><h2 id="美化"><a href="#美化" class="headerlink" title="美化"></a>美化</h2><h3 id="新建分类-categories-页"><a href="#新建分类-categories-页" class="headerlink" title="新建分类 categories 页"></a>新建分类 categories 页</h3><p><code>categories</code> 页是用来展示所有分类的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>categories/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre><code>hexo new page "categories"</code></pre><p>编辑你刚刚新建的页面文件 <code>/source/categories/index.md</code>，至少需要以下内容：</p><pre><code>---title: categoriesdate: 2018-09-30 17:25:30type: "categories"layout: "categories"---</code></pre><h3 id="标签页"><a href="#标签页" class="headerlink" title="标签页"></a>标签页</h3><pre><code>hexo new page "tags"</code></pre><p>编辑新建的/source/tags/index.md文件</p><pre><code>---title: tagsdate: 2020-02-23 19:37:07type: "tags"layout: "tags"---</code></pre><h3 id="分类页"><a href="#分类页" class="headerlink" title="分类页"></a>分类页</h3><pre><code>hexo new page "categories"</code></pre><p>编辑新建的/source/categories/index.md文件</p><hr><pre><code>---title: categoriesdate: 2020-02-23 19:37:07type: "categories"layout: "categories"---</code></pre><h3 id="关于页面"><a href="#关于页面" class="headerlink" title="关于页面"></a>关于页面</h3><pre><code>hexo new page "about"</code></pre><p>编辑新建的/source/about/index.md文件</p><pre><code>---title: aboutdate: 2020-02-23 19:37:07type: "about"layout: "about"---</code></pre><h3 id="留言板"><a href="#留言板" class="headerlink" title="留言板"></a>留言板</h3><pre><code>hexo new page "contact"</code></pre><p>编辑新建的/source/contact/index.md文件</p><hr><pre><code>---title: contactdate: 2020-02-23 19:37:07type: "contact"layout: "contact"---</code></pre><h3 id="友情链接"><a href="#友情链接" class="headerlink" title="友情链接"></a>友情链接</h3><pre><code>hexo new page "friends"</code></pre><p>编辑新建的/source/friends/index.md文件</p><pre><code>---title: friendsdate: 2020-02-23 19:37:07type: "friends"layout: "friends"---</code></pre><p>然后在博客 source 目录下新建 _data 目录，在 _data 目录中新建 friends.json 文件，文件内容如下所示：</p><h3 id="添加-404-页面"><a href="#添加-404-页面" class="headerlink" title="添加 404 页面"></a>添加 404 页面</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/7e4658accfa8e6e1df5b04cd88e7ce0e.png" alt="img"></p><p>首先再站点根目录下的 source 文件夹下新建 404.md 文件，里面内容如下：</p><pre><code>---title: 404date: 2020-02-23 19:37:07type: "404"layout: "404"description: "Oops～，我崩溃了！找不到你想要的页面了"---</code></pre><p>紧接着再新建主题文件夹的 layout 目录下新建 404.ejs 文件，添加内容如下：<strong>我这边文件中自带了，目录：F:\个人博客\hexo\themes\hexo-theme-matery-master\layout</strong></p><pre><code>&lt;style type="text/css"&gt;    /* don't remove. */    .about-cover {        height: 90.2vh;    }&lt;/style&gt;&lt;div class="bg-cover pd-header about-cover"&gt;    &lt;div class="container"&gt;        &lt;div class="row"&gt;            &lt;div class="col s10 offset-s1 m8 offset-m2 l8 offset-l2"&gt;                &lt;div class="brand"&gt;                    &lt;div class="title center-align"&gt;                        404                    &lt;/div&gt;                    &lt;div class="description center-align"&gt;                        &lt;%= page.description %&gt;                    &lt;/div&gt;                &lt;/div&gt;            &lt;/div&gt;        &lt;/div&gt;    &lt;/div&gt;&lt;/div&gt;&lt;script&gt;    // 每天切换 banner 图.  Switch banner image every day.    $('.bg-cover').css('background-image', 'url(/medias/banner/' + new Date().getDay() + '.jpg)');&lt;/script&gt;</code></pre><h3 id="添加自定义页面"><a href="#添加自定义页面" class="headerlink" title="添加自定义页面"></a>添加自定义页面</h3><p>首先在站点目录下的 source 文件夹下新建 aboutme 文件，文件名可自定义，然后编写一个 index.html 放入 aboutme 文件夹下，然后在主题配置文件下的导航配置信息添加下面的配置：</p><pre><code>About:    url: /    icon: fas fa-address-card    children:      - name: 关于我        url: /about        icon: fas fa-user-circle      - name: Another    #这是新添加的，在原有配置基础上添加        url: /aboutme        icon: fa fa-user-secret</code></pre><p>然后在站点配置文件下，找到 skip_render，在后面添加属性，如下：</p><pre><code># 其意思为在对文件进行渲染时跳过aboutme文件下的所有文件skip_render:     - aboutme/**     - aaa/**    - bbb/**</code></pre><h3 id="配置菜单导航"><a href="#配置菜单导航" class="headerlink" title="配置菜单导航"></a>配置菜单导航</h3><p>配置基本菜单导航的名称、路径 url 和图标 icon.</p><p>图标 icon 可以在 <a href="https://fontawesome.com/icons">Font Awesome</a> 中查找</p><pre><code># main menu navigation url and icon# 配置菜单导航的名称、路径和图标icon.menu:  Index:    url: /    icon: fas fa-home  Tags:    url: /tags    icon: fas fa-tags  Categories:    url: /categories    icon: fas fa-bookmark  Archives:    url: /archives    icon: fas fa-archive  About:    url: /about    icon: fas fa-user-circle  Contact:    url: /contact    icon: fas fa-comments  Friends:    url: /friends    icon: fas fa-address-book</code></pre><h3 id="二级菜单配置方法"><a href="#二级菜单配置方法" class="headerlink" title="二级菜单配置方法"></a>二级菜单配置方法</h3><p>如果你需要二级菜单则可以在原基本菜单导航的基础上如下操作<strong>我这里暂时没添加</strong></p><ol><li>在需要添加二级菜单的一级菜单下添加children关键字(如:About菜单下添加children)</li><li>在children下创建二级菜单的 名称name,路径url和图标icon.</li><li>注意每个二级菜单模块前要加 -.</li><li>注意缩进格式</li></ol><pre><code>menu:  Index:    url: /    icon: fas fa-home  Tags:    url: /tags    icon: fas fa-tags  Categories:    url: /categories    icon: fas fa-bookmark  Archives:    url: /archives    icon: fas fa-archive  About:    url: /about    icon: fas fa-user-circle-o  Friends:    url: /friends    icon: fas fa-address-book  Medias:    icon: fas fa-list    children:      - name: Musics        url: /musics        icon: fas fa-music      - name: Movies        url: /movies        icon: fas fa-film      - name: Books        url: /books        icon: fas fa-book      - name: Galleries        url: /galleries        icon: fas fa-image</code></pre><h3 id="添加-emoji-表情支持"><a href="#添加-emoji-表情支持" class="headerlink" title="添加 emoji 表情支持"></a>添加 emoji 表情支持</h3><p>需要安装插件 hexo-filter-<a href="https://so.csdn.net/so/search?q=github&amp;spm=1001.2101.3001.7020">github</a>-emojis</p><pre><code>npm install hexo-filter-github-emojis --save</code></pre><p><strong>没成功</strong></p><p>在 Hexo 根目录下的 _config.yml 文件中，新增以下的配置项：</p><pre><code>githubEmojis:  enable: true  className: github-emoji  inject: true  styles:  customEmojis:</code></pre><p>在网站<a href="https://www.webfx.com/tools/emoji-cheat-sheet/%E5%8F%AF%E4%BB%A5%E6%90%9C%E7%B4%A2%E5%B8%B8%E7%94%A8%E8%A1%A8%E6%83%85%E5%AF%B9%E5%BA%94%E4%BB%A3%E7%A0%81">https://www.webfx.com/tools/emoji-cheat-sheet/可以搜索常用表情对应代码</a></p><p>在 emoji-cheat-sheet 中找到你想要的表情，然后点击即可复制。使用方法和 GitHub 一样，比如你想发一个笑脸 😄 直接输入笑脸对应的 emoji 编码 :smile： 就可以。</p><h3 id="代码高亮"><a href="#代码高亮" class="headerlink" title="代码高亮"></a>代码高亮</h3><p>原本的代码显示行号和内容分开了，不美观</p><p>代码美化需要安装hexo-prism-plugin 插件</p><pre><code>npm i -S hexo-prism-plugin</code></pre><p>修改 Hexo 根目录下 _config.yml 文件中 highlight.enable 的值为 false，并新增 prism 插件相关的配置，主要配置如下：</p><pre><code>highlight:#代码块的设置  enable: false#开启代码块高亮  line_number: true#如果未指定语言，则启用自动检测  auto_detect: false#显示行数  tab_replace: ''#用n个空格替换tabs；如果值为空，则不会替换tabs  wrap: true  hljs: false# 关闭原有的代码高亮，使用自己的prism_plugin:  mode: 'preprocess'    # realtime/preprocess  theme: 'tomorrow'  line_number: false    # default false  custom_css:</code></pre><table><thead><tr><th>参数KEY</th><th>可选值</th></tr></thead><tbody><tr><td>mode</td><td>realtime (Parse code on browser in real time) preprocess (Preprocess code in node)</td></tr><tr><td>theme</td><td>default coy dark funky okaidia solarizedlight tomorrow twilight 如果要更多的选择访问： hexo-prism-plugin</td></tr><tr><td>line_number</td><td>true (Show line numbers) false (Default, Hide line numbers)</td></tr><tr><td>no_assets</td><td>true (Stop loading asset files) false (Default, load script and stylesheets files)</td></tr></tbody></table><p><strong>注意：</strong></p><p>hexo花括号显示失败的话，需要将hexo版本降级，改成hexo4.2.0版本就好了</p><p>卸载hexo5.0</p><pre><code>npm uninstall hexo --save</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/91cccfeb6967936038c56f582b1d67e5.png" alt="img"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/898a784da02aceb7a0eb1a335829af5c.png" alt="img"></p><h3 id="主题的搜索功能"><a href="#主题的搜索功能" class="headerlink" title="主题的搜索功能"></a>主题的搜索功能</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/39cb1d20d3ab8aec49c89547534971fc.png" alt="image-20210119204534310"></p><p>需要安装hexo-generator-search插件</p><pre><code>npm install hexo-generator-search --save</code></pre><p>在Hexo 根目录下的 _config.yml 文件中，新增以下的配置项：</p><pre><code>search:  path: search.xml  field: post</code></pre><h3 id="文章字数统计插件这个我没弄明白"><a href="#文章字数统计插件这个我没弄明白" class="headerlink" title="文章字数统计插件这个我没弄明白"></a>文章字数统计插件这个我没弄明白</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/662c63a522fa862fbea79c0cd5978576.png" alt="image-20210119204355226"></p><p>需要安装 hexo-wordcount 插件</p><pre><code>npm i --save hexo-wordcount</code></pre><p>主题下的 _config.yml 文件中，激活以下配置项即可：</p><pre><code>wordCount:  enable: false # 将这个值设置为 true 即可.  postWordCount: true  min2read: true  totalCount: true</code></pre><p>保存后报错</p><p><img src="https://img-blog.csdnimg.cn/img_convert/563272a84cd22d44dd09c7da3aecef19.png" alt="image-20210117140326262"></p><pre><code>npm ls --depth 0</code></pre><p>命令查看 npm 安装各 hexo 插件的情况</p><p><img src="https://img-blog.csdnimg.cn/img_convert/eb3612270fba079022596168fff630b6.png" alt="image-20210117142653510"></p><p>无问题，改为以下不报错</p><p>一天后问题自动恢复</p><h3 id="添加-RSS-订阅支持这个也没弄明白"><a href="#添加-RSS-订阅支持这个也没弄明白" class="headerlink" title="添加 RSS 订阅支持这个也没弄明白"></a>添加 RSS 订阅支持这个也没弄明白</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/f00f819bd8a8e1961de4b1e5d7eae29b.png" alt="image-20210120134517461"></p><p>需要安装hexo-generator-feed插件</p><pre><code>npm install hexo-generator-feed --save</code></pre><p>Hexo 根目录下的 _config.yml 文件中，新增以下的配置项：</p><pre><code>feed:  type: atom  path: atom.xml  limit: 20  hub:  content:  content_limit: 140  content_limit_delim: ' '  order_by: -date</code></pre><p>在 public 文件夹中即可看到 atom.xml 文件，则已经安装成功</p><h3 id="修改页脚"><a href="#修改页脚" class="headerlink" title="修改页脚"></a>修改页脚</h3><p>页脚信息可能需要做定制化修改，而且它不便于做成配置信息，所以可能需要你自己去再修改和加工。修改的地方在主题文件的 /layout/_partial/footer.ejs 文件中，包括站点、使用的主题、访问量等。</p><h3 id="修改社交链接"><a href="#修改社交链接" class="headerlink" title="修改社交链接"></a>修改社交链接</h3><p>在主题的 config.yml 文件中，默认支持 QQ、GitHub 和邮箱等的配置，你可以在主题文件的 /layout/_partial/social-link.ejs 文件中，新增、修改你需要的社交链接地址，增加链接可参考如下代码：</p><pre><code>&lt;% if (theme.socialLink.github) { %&gt;    &lt;a href="&lt;%= theme.socialLink.github %&gt;" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-github"&gt;&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;</code></pre><h3 id="修改打赏的二维码图片"><a href="#修改打赏的二维码图片" class="headerlink" title="修改打赏的二维码图片"></a>修改打赏的二维码图片</h3><p>在主题文件的 source/medias/reward 文件中修改</p><h3 id="配置音乐播放器"><a href="#配置音乐播放器" class="headerlink" title="配置音乐播放器"></a>配置音乐播放器</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/29cae7820140cae42300533bdbc22a16.png" alt="image-20210121162930869"></p><p>支持接入第三方音乐，如 QQ 音乐，网易云音乐，酷狗音乐等等</p><p>主题的 _config.yml 配置文件中激活 music 配置即可：</p><pre><code># Whether to display the musics.# 是否在首页显示音乐.music:  enable: true  title: #非吸底模式有效    enable: true    show: 咕咕星的歌单  autoHide: true    # hide automaticaly  server: netease   #requiremusic platform: netease, tencent, kugou, xiami, baidu  type: playlist    #require song, playlist, album, search, artist  id: 2888085740     #requiresong id / playlist id / album id / search keyword  fixed: false       # 开启吸底模式  autoplay: false   # 是否自动播放  theme: '#42b983'  loop: 'all'       # 音频循环播放, 可选值: 'all', 'one', 'none'  order: 'random'   # 音频循环顺序, 可选值: 'list', 'random'  preload: 'auto'   # 预加载，可选值: 'none', 'metadata', 'auto'  volume: 0.7       # 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效  listFolded: true  # 列表默认折叠  hideLrc: true     # 隐藏歌词</code></pre><pre><code>server 可选 netease（网易云音乐），tencent（QQ 音乐），kugou（酷狗音乐），xiami（虾米音乐），baidu（百度音乐）。type 可选 song（歌曲），playlist（歌单），album（专辑），search（搜索关键字），artist（歌手）id 获取示例：浏览器打开网易云音乐，点击我喜欢的音乐歌单，地址栏有一串数字，playlist 的 id 即为这串数字</code></pre><p>这个牛</p><h3 id="文章-Front-matter-介绍"><a href="#文章-Front-matter-介绍" class="headerlink" title="文章 Front-matter 介绍"></a>文章 Front-matter 介绍</h3><table><thead><tr><th>配置选项</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>title</td><td>Markdown 的文件标题</td><td>文章标题，强烈建议填写此选项</td></tr><tr><td>date</td><td>文件创建时的日期时间</td><td>发布时间，强烈建议填写此选项，且最好保证全局唯一</td></tr><tr><td>author</td><td>根 _config.yml 中的 author</td><td>文章作者</td></tr><tr><td>img</td><td>featureImages 中的某个值</td><td>文章特征图，推荐使用图床</td></tr><tr><td>top</td><td>true</td><td>推荐文章（文章是否置顶），如果 top 值为 true，则会作为首页推荐文章</td></tr><tr><td>cover</td><td>false</td><td>v1.0.2 版本新增，表示该文章是否需要加入到首页轮播封面中</td></tr><tr><td>coverImg</td><td>无</td><td>v1.0.2 版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td></tr><tr><td>password</td><td>无</td><td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 password 的值，该值必须是用 SHA256 加密后的密码，防止被他人识破。前提是在主题的 config.yml 中激活了 verifyPassword 选项</td></tr><tr><td>toc</td><td>true</td><td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 config.yml 中激活了 toc 选项</td></tr><tr><td>mathjax</td><td>false</td><td>是否开启数学公式支持 ，本文章是否开启 mathjax，且需要在主题的 _config.yml 文件中也需要开启才行</td></tr><tr><td>summary</td><td>无</td><td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td></tr><tr><td>categories</td><td>无</td><td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td></tr><tr><td>tags</td><td>无</td><td>文章标签，一篇文章可以多个标签</td></tr><tr><td>reprintPolicy</td><td>cc_by</td><td>文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td></tr></tbody></table><p>注意:</p><ol><li><strong>如果 img 属性不填写的话，文章特色图会根据文章标题的 hashcode 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章都的特色图各有特色。</strong></li><li>date 的值尽量保证每篇文章是唯一的，因为本主题中 Gitalk 和 Gitment 识别 id 是通过 date 的值来作为唯一标识的。</li><li>如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 _config.yml 中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：开源中国在线工具、chahuo、站长工具。</li><li>您可以在文章 md 文件的 front-matter 中指定 reprintPolicy 来给单个文章配置转载规则</li></ol><h4 id="最简示例"><a href="#最简示例" class="headerlink" title="最简示例"></a>最简示例</h4><pre><code>---title: typora-vue-theme主题介绍date: 2018-09-07 09:25:00---</code></pre><h4 id="最全示例"><a href="#最全示例" class="headerlink" title="最全示例"></a>最全示例</h4><pre><code>---title: typora-vue-theme主题介绍date: 2018-09-07 09:25:00author: 赵奇img: /source/images/xxx.jpgtop: truecover: truecoverImg: /images/1.jpgpassword: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92toc: falsemathjax: falsesummary: 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要categories: Markdowntags:  - Typora  - Markdown---</code></pre><h3 id="自定制修改"><a href="#自定制修改" class="headerlink" title="自定制修改"></a>自定制修改</h3><h4 id="修改主题颜色"><a href="#修改主题颜色" class="headerlink" title="修改主题颜色"></a>修改主题颜色</h4><p>在主题文件的 /source/css/matery.css 文件中修改</p><pre><code>/* 整体背景颜色，包括导航、移动端的导航、页尾、标签页等的背景颜色. */.bg-color {    background-image: linear-gradient(to right, #2558FF 0%, #0f9d58 100%);}/*如果想去掉banner图的颜色渐变效果，请将以下的css属性注释掉或者删除掉即可*/@-webkit-keyframes rainbow {   /* 动态切换背景颜色. */}@keyframes rainbow {    /* 动态切换背景颜色. */}</code></pre><h4 id="修改-banner-图和文章特色图"><a href="#修改-banner-图和文章特色图" class="headerlink" title="修改 banner 图和文章特色图"></a>修改 banner 图和文章特色图</h4><p>在 /source/medias/banner 文件夹中更换你喜欢的 banner 图片，主题代码中是每天动态切换一张，只需 7 张即可。如果你会 JavaScript 代码，可以修改成你自己喜欢切换逻辑，如：随机切换等，banner 切换的代码位置在 /layout/_partial/bg-cover-content.ejs 文件的 代码中：</p><pre><code>$('.bg-cover').css('background-image', 'url(/medias/banner/' + new Date().getDay() + '.jpg)');</code></pre><p>在 /source/medias/featureimages 文件夹中默认有 24 张特色图片，你可以再增加或者减少，并需要在 _config.yml 做同步修改。</p><p>如果想改为每小时或者每分钟切换 banner 图的话，需要将 getDay() 改为 getHours() 或者 getMinutes() 即可。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/d388f57880ddbaaf25977bd7e0719d23.png" alt="image-20210121164726675"></p><p>修改文章特色图见front_matter</p><h3 id="修改网站相关信息"><a href="#修改网站相关信息" class="headerlink" title="修改网站相关信息"></a>修改网站相关信息</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/ae1941eec39efd37c4da722d0543d9bf.png" alt="img"></p><pre><code>#这是根目录下的配置文件信息# Sitetitle: 咕咕星Blog#网站标题subtitle: 世界很暗，但是你来了 #网站副标题description: 本网站是个人兴趣爱好，总结分享经验，记录生活点滴的平台，希望在以后的学习旅途中，走出自己的风景。#网站描述description 主要用于5E0，告诉搜索引擎一个关于您站点的简单描述keywords: [HTML, CSS, JavaScript, JQuery, java, linux等]#网站的关键词。使用半角逗号“，”分隔多个关键词author: 咕咕星#您的名字language: zh-CN#网站使用的语言。建议修改为zh-CNtimezone:#网站时区。Hexo默认使用您电脑的时区。# 这是主题配置文件的相关信息# 配置网站favicon和网站LOGO# 此处我用的CDN，也可以使用本地文件favicon: https://cdn.jsdelivr.net/gh/guixinchn/image/blog/favicon.pnglogo: https://cdn.jsdelivr.net/gh/guixinchn/image/blog/logo.png# 网站副标题，打字效果# 如果有符号 ‘ ，请在 ’ 前面加上 \subtitle:  enable: true  loop: true # 是否循环  showCursor: true # 是否显示光标  startDelay: 300 # 开始延迟  typeSpeed: 100 # 打字速度  backSpeed: 50 # 删除速度  sub1: 如果放弃太早，你永远都不知道自己会错过什么。  sub2: 没有伞的孩子必须努力奔跑！  sub3: 花开不是为了花落，而是为了开的更加灿烂。  sub4: 没有礁石，就没有美丽的浪花；没有挫折，就没有壮丽的人生。</code></pre><p>注意：</p><p>网站打字效果副标题默认有两个，即 sub1 和 sub2，如果想写多个，则需要修改两处地方，首先修改配置文件，如上面所示，在 sub1 和 sub2 后面继续添加即可，然后在去主题目录下的 layout 文件夹下的_partial 文件夹，修改 bg-cover-content.ejs 文件，大约在 12 行左右，如下面所示：</p><pre><code>&lt;div class="description center-align"&gt;                &lt;% if (theme.subtitle.enable) { %&gt;                &lt;span id="subtitle"&gt;&lt;/span&gt;                &lt;script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11"&gt;&lt;/script&gt;                &lt;script&gt;                    var typed = new Typed("#subtitle", {                        strings: ['&lt;%= theme.subtitle.sub1 %&gt;',                   '&lt;%= theme.subtitle.sub2 %&gt;',                                  '&lt;%= theme.subtitle.sub3 %&gt;',                   '&lt;%= theme.subtitle.sub4 %&gt;'],                        startDelay: &lt;%= theme.subtitle.startDelay %&gt;,                        typeSpeed: &lt;%= theme.subtitle.typeSpeed %&gt;,                        loop: &lt;%= theme.subtitle.loop %&gt;,                        backSpeed: &lt;%= theme.subtitle.backSpeed %&gt;,                        showCursor: &lt;%= theme.subtitle.showCursor %&gt;                    });                &lt;/script&gt;                &lt;% } else { %&gt;                    &lt;%= config.description %&gt;                &lt;% } %&gt;            &lt;/div&gt;</code></pre><h3 id="社交链接的修改"><a href="#社交链接的修改" class="headerlink" title="社交链接的修改"></a><strong>社交链接的修改</strong></h3><p>在主题的配置文件中修改：</p><pre><code># 首页 banner 中的第二行个人信息配置，留空即不启用socialLink:  qq: 1563972718  weixin: https://gitee.com/marmalade0/images/blob/master/www.marmalade.vip/wechat.jpg  github: #https://github.com/marmalade0  email: 1563972718@qq.com  facebook: # https://www.facebook.com/xxx  twitter: # https://twitter.com/xxx  weibo: # https://weibo.com/xxx  zhihu: # https://www.zhihu.com/xxx  csdn: https://blog.csdn.net/kuashijidexibao  cnblogs: https://www.cnblogs.com/kuashijidexibao  rss: true # true、false</code></pre><p>期中的 weixin 我是用的图片链接，会跳转到一个新的标签页，之后还需要修改 ejs 文件，文件在主题目录下的 layout 文件夹下的_partial 文件夹，修改 social-link.ejs，添加相关的配置，比如：</p><pre><code>&lt;% if (theme.socialLink.github) { %&gt;    &lt;a href="&lt;%= theme.socialLink.github %&gt;" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-github"&gt;&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.email) { %&gt;    &lt;a href="mailto:&lt;%= theme.socialLink.email %&gt;" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"&gt;        &lt;i class="fas fa-envelope-open"&gt;&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.facebook) { %&gt;    &lt;a href="&lt;%= theme.socialLink.facebook %&gt;" class="tooltipped" target="_blank" data-tooltip="关注我的Facebook: &lt;%= theme.socialLink.facebook %&gt;" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-facebook-f"&gt;&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.twitter) { %&gt;    &lt;a href="&lt;%= theme.socialLink.twitter %&gt;" class="tooltipped" target="_blank" data-tooltip="关注我的Twitter: &lt;%= theme.socialLink.twitter %&gt;" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-twitter"&gt;&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.qq) { %&gt;    &lt;a href="tencent://AddContact/?fromId=50&amp;fromSubId=1&amp;subcmd=all&amp;uin=&lt;%= theme.socialLink.qq %&gt;" class="tooltipped" target="_blank" data-tooltip="QQ联系我: &lt;%= theme.socialLink.qq %&gt;" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-qq"&gt;&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.weibo) { %&gt;    &lt;a href="&lt;%= theme.socialLink.weibo %&gt;" class="tooltipped" target="_blank" data-tooltip="关注我的微博: &lt;%= theme.socialLink.weibo %&gt;" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-weibo"&gt;&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.zhihu) { %&gt;    &lt;a href="&lt;%= theme.socialLink.zhihu %&gt;" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: &lt;%= theme.socialLink.zhihu %&gt;" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-zhihu1"&gt;知&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.rss) { %&gt;    &lt;a href="&lt;%- url_for('/atom.xml') %&gt;" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50"&gt;        &lt;i class="fas fa-rss"&gt;&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.jianshu) { %&gt;    &lt;a href="&lt;%= theme.socialLink.jianshu %&gt;" class="tooltipped" target="_blank" data-tooltip="关注我的简书: &lt;%= theme.socialLink.jianshu %&gt;" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-jianshu"&gt;简&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.csdn) { %&gt;    &lt;a href="&lt;%= theme.socialLink.csdn %&gt;" class="tooltipped" target="_blank" data-tooltip="关注我的CSDN: &lt;%= theme.socialLink.csdn %&gt;" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-csdn"&gt;C&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.juejin) { %&gt;    &lt;a href="&lt;%= theme.socialLink.juejin %&gt;" class="tooltipped" target="_blank" data-tooltip="关注我的掘金: &lt;%= theme.socialLink.juejin %&gt;" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-juejin"&gt;掘&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.cnblogs) { %&gt;    &lt;a href="&lt;%= theme.socialLink.cnblogs %&gt;" class="tooltipped" target="_blank" data-tooltip="关注我的博客园: &lt;%= theme.socialLink.cnblogs %&gt;" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-juejin"&gt;博&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;&lt;% if (theme.socialLink.weixin) { %&gt;    &lt;a href="&lt;%= theme.socialLink.weixin %&gt;" class="tooltipped" target="_blank" data-tooltip="微信联系我: &lt;%= theme.socialLink.weixin %&gt;" data-position="top" data-delay="50"&gt;        &lt;i class="fab fa-weixin"&gt;&lt;/i&gt;    &lt;/a&gt;&lt;% } %&gt;</code></pre><h3 id="其他一些个性DIY"><a href="#其他一些个性DIY" class="headerlink" title="其他一些个性DIY"></a>其他一些个性DIY</h3><h4 id="动态标题"><a href="#动态标题" class="headerlink" title="动态标题"></a>动态标题</h4><p><img src="https://img-blog.csdnimg.cn/img_convert/852e0a0f925f350540a3edcf0db0e2f1.png" alt="img"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/fcb8a9deebfa0f8eb9641daab4746530.png" alt="img"></p><p>实现方法，引入 js 文件，在主题文件下的 /source/js/ 下新建 FunnyTitle.js，增加以下代码：</p><pre><code> var OriginTitle = document.title; var titleTime; document.addEventListener('visibilitychange', function () {     if (document.hidden) {         $('[rel="icon"]').attr('href', "https://cdn.jsdelivr.net/gh/guixinchn/image/blog/favicon.png");         document.title = '我相信你还会回来的！';         clearTimeout(titleTime);     }     else {         $('[rel="icon"]').attr('href', "https://cdn.jsdelivr.net/gh/guixinchn/image/blog/favicon.png");         document.title = '哈哈，我就知道！' + OriginTitle;         titleTime = setTimeout(function () {             document.title = OriginTitle;         }, 2000);     } });</code></pre><p>然后在添加到 themes/matery/layout/layout.ejs 引入</p><h3 id="关于我页面添加个人简历这里搞不了"><a href="#关于我页面添加个人简历这里搞不了" class="headerlink" title="关于我页面添加个人简历这里搞不了"></a>关于我页面添加个人简历这里搞不了</h3><p><img src="https://img-blog.csdnimg.cn/img_convert/ace8ee988a7e65ac74e6c42a3cebc707.png" alt="img"></p><p>打开 theme/matery/layout/about.ejs 文件，大约在 13 行。有一个 `` 标签，找出其对应结尾的标签，大约在 61 行左右，然后在新增如下代码：</p><pre><code>&lt;div class="card"&gt;     &lt;div class="card-content"&gt;         &lt;div class="card-content article-card-content"&gt;             &lt;div class="title center-align" data-aos="zoom-in-up"&gt;                 &lt;i class="fa fa-address-book"&gt;&lt;/i&gt;&amp;nbsp;&amp;nbsp;&lt;%- __('个人简历') %&gt;              &lt;/div&gt;                 &lt;div id="articleContent" data-aos="fade-up"&gt;                     &lt;%- page.content %&gt;                 &lt;/div&gt;           &lt;/div&gt;      &lt;/div&gt;&lt;/div&gt;</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/7024e13cb618b1c4f5e84d5e24752a4c.png" alt="img"></p><p>可以在about页面自定义内容</p><h3 id="修改网站背景图"><a href="#修改网站背景图" class="headerlink" title="修改网站背景图"></a>修改网站背景图</h3><p>主题配置文件</p><pre><code>background:  enable: true  url: "https://gitee.com/marmalade0/images/blob/master/www.marmalade.vip/24.jpg"</code></pre><h3 id="valine评论模块配置这里还没搞"><a href="#valine评论模块配置这里还没搞" class="headerlink" title="valine评论模块配置这里还没搞"></a>valine评论模块配置这里还没搞</h3><p>主题配置文件找到valine部分，按以下要求配置</p><pre><code>valine:  enable: true  appId: xxxxxxxx # Your leancloud application appid# 将应用key的App ID设置在这里  appKey: xxxxxxx # Your leancloud application appkey# 将应用key的App Key设置在这里  notify: true # Mail notifier邮箱通知 , https://github.com/xCss/Valine/wiki，默认为false  verify: true # Verification code验证码 默认为false  avatar: 'mm' # Gravatar style : mm/identicon/monsterid/wavatar/retro/hide  placeholder: 想说点啥？Just go go ^_^ # Comment box placeholder# 初始化评论显示，根据自己修改，这里默认  background: /medias/comment_bg.png  guest_info: nick,mail,link # Custom comment header# 自定义评论标题  pageSize: 10 # Pagination size# 分页大小，10页就自动分页  language: zh-cn # Language, available values: en, zh-cn  visitor: true # Article reading statistic# 是否允许游客评论 ，进入官网查看设置：https://valine.js.org/visitor.html  comment_count: true # If false, comment count will only be displayed in post page, not in home page  recordIP: false # Whether to record the commenter IP  serverURLs: # When the custom domain name is enabled, fill it in here (it will be detected automatically by default, no need to fill in)  #post_meta_order: 0</code></pre><h3 id="新建文章模板修改"><a href="#新建文章模板修改" class="headerlink" title="新建文章模板修改"></a>新建文章模板修改</h3><p>首先为了新建文章方便，我们可以修改一下文章模板，可以将<code>/scaffolds/post.md</code>修改为如下代码：</p><pre><code>---title: {{ title }}date: {{ date }}author: img: coverImg: top: falsecover: falsetoc: truemathjax: falsepassword:summary:keywords:tags:categories:---</code></pre><p>这样新建文章后 一些<code>Front-matter</code>参数不用你自己补充了，修改对应信息就可以了。</p><h4 id="Front-matter-选项详解"><a href="#Front-matter-选项详解" class="headerlink" title="Front-matter 选项详解"></a>Front-matter 选项详解</h4><p><code>Front-matter</code> 选项中的所有内容均为<strong>非必填</strong>的。但原作者建议至少填写 <code>title</code> 和 <code>date</code> 的值。</p><p><img src="/./images/image-20230723180529891.png" alt="image-20230723180529891"></p><h4 id="最全示例-1"><a href="#最全示例-1" class="headerlink" title="最全示例"></a>最全示例</h4><pre><code>---title: typora-vue-theme主题介绍date: 2018-09-07 09:25:00author: 赵奇img: /source/images/xxx.jpgtop: truecover: truecoverImg: /images/1.jpgpassword: 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92toc: falsemathjax: falsesummary: 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要categories: Markdowntags:  - Typora  - Markdown---</code></pre><h3 id="看板娘模块的安装和使用这个就是右下角有个人物，我没搞"><a href="#看板娘模块的安装和使用这个就是右下角有个人物，我没搞" class="headerlink" title="看板娘模块的安装和使用这个就是右下角有个人物，我没搞"></a>看板娘模块的安装和使用这个就是右下角有个人物，我没搞</h3><p>模块安装：</p><pre><code>cnpm install --save hexo-helper-live2d</code></pre><p>下载完成后，可以在node_modules文件夹中找到自己安装的插件。</p><p>然后下载你想要的看板娘模块（可以自己到网上找哪个合心意的），执行命令：</p><pre><code>cnpm install {packagename}# 例如cnpm install live2d-widget-model-haru</code></pre><p>下载完成后，回到blog根目录下配置_config.yml，添加以下代码（model要根据自己情况设置）：</p><pre><code>live2d:  enable: true  scriptFrom: local  pluginRootPath: live2dw/  pluginJsPath: lib/  pluginModelPath: assets/  tagMode: false  debug: false  model:    use: live2d-widget-model-z16  display:    position: right    width: 200    height: 400  mobile:    show: false</code></pre><p>这样在右下角有看板娘啦！</p><h3 id="添加博客天气插件我没搞"><a href="#添加博客天气插件我没搞" class="headerlink" title="添加博客天气插件我没搞"></a>添加博客天气插件我没搞</h3><p>中国天气网：<a href="https://cj.weather.com.cn/">https://cj.weather.com.cn/</a></p><p>选择自定义插件—&gt;自定义样式——&gt;生成代码，然后会生成这样一段代码</p><pre><code>&lt;!-- Weather Widget --&gt; &lt;script type="text/javascript"&gt; WIDGET = {FID: 'your FID'}&lt;/script&gt; &lt;script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"&gt;&lt;/script&gt;</code></pre><p>在 /themes/matery/source/layout/_widget 新建文件 weather.ejs，把上面生成的代码添加进入,可以设置只有桌面端显示,如下修改:</p><pre><code>&lt;!-- 天气接口--&gt;&lt;script type="text/javascript"&gt;  WIDGET = {FID: '1tFpFZ5Mtj'}&lt;/script&gt;&lt;!-- &lt;script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"&gt;&lt;/script&gt; --&gt;&lt;script type="text/javascript"&gt;  //只在桌面版网页启用特效  var windowWidth = $(window).width();  if (windowWidth &gt; 768) {      document.write('&lt;script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"&gt;&lt;\/script&gt;');  }  &lt;/script&gt;</code></pre><p>然后在 /themes/matery/layout/_partial/layout.ejs 中添加如下代码：</p><pre><code>&lt;!-- 天气接口控件  洪卫 shw2018 add 2019.09.09 --&gt;&lt;% if (theme.weather.enable) { %&gt;  &lt;%- partial('_widget/weather') %&gt;&lt;% } %&gt;</code></pre><p>在主题配置文件 .yml中配置:</p><pre><code># 启用天气接口插件weather:  enable: true</code></pre><p><strong>当然,如果你不想搞这么复杂,可以直接将下面代码插入 /themes/matery/layout/_partial/layout.ejs 中即可使用:</strong></p><pre><code>&lt;script type="text/javascript"&gt;    WIDGET = {FID: '1tFpFZ5Mtj'}&lt;/script&gt;&lt;script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"&gt;&lt;/script&gt;</code></pre><h3 id="添加页面樱花飘落动效个人觉得这个真的好看，但是有问题我没弄出来"><a href="#添加页面樱花飘落动效个人觉得这个真的好看，但是有问题我没弄出来" class="headerlink" title="添加页面樱花飘落动效个人觉得这个真的好看，但是有问题我没弄出来"></a>添加页面樱花飘落动效个人觉得这个真的好看，但是有问题我没弄出来</h3><p>在 <code>/themes/matery/source/js</code> 新建文件 <code>sakura.js</code>，并添加如下代码</p><pre><code>var stop, staticx;var img = new Image();img.src = "data:image/png;base64,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";function Sakura(x, y, s, r, fn) {    this.x = x;    this.y = y;    this.s = s;    this.r = r;    this.fn = fn;}Sakura.prototype.draw = function (cxt) {    cxt.save();    var xc = 40 * this.s / 4;    cxt.translate(this.x, this.y);    cxt.rotate(this.r);    cxt.drawImage(img, 0, 0, 40 * this.s, 40 * this.s)    cxt.restore();}Sakura.prototype.update = function () {    this.x = this.fn.x(this.x, this.y);    this.y = this.fn.y(this.y, this.y);    this.r = this.fn.r(this.r);    if (this.x &gt; window.innerWidth || this.x &lt; 0 || this.y &gt; window.innerHeight || this.y &lt; 0) {        this.r = getRandom('fnr');        if (Math.random() &gt; 0.4) {            this.x = getRandom('x');            this.y = 0;            this.s = getRandom('s');            this.r = getRandom('r');        } else {            this.x = window.innerWidth;            this.y = getRandom('y');            this.s = getRandom('s');            this.r = getRandom('r');        }    }}SakuraList = function () {    this.list = [];}SakuraList.prototype.push = function (sakura) {    this.list.push(sakura);}SakuraList.prototype.update = function () {    for (var i = 0, len = this.list.length; i &lt; len; i++) {        this.list[i].update();    }}SakuraList.prototype.draw = function (cxt) {    for (var i = 0, len = this.list.length; i &lt; len; i++) {        this.list[i].draw(cxt);    }}SakuraList.prototype.get = function (i) {    return this.list[i];}SakuraList.prototype.size = function () {    return this.list.length;}function getRandom(option) {    var ret, random;    switch (option) {        case 'x':            ret = Math.random() * window.innerWidth;            break;        case 'y':            ret = Math.random() * window.innerHeight;            break;        case 's':            ret = Math.random();            break;        case 'r':            ret = Math.random() * 6;            break;        case 'fnx':            random = -0.5 + Math.random() * 1;            ret = function (x, y) {                return x + 0.5 * random - 1.7;            };            break;        case 'fny':            random = 1.5 + Math.random() * 0.7            ret = function (x, y) {                return y + random;            };            break;        case 'fnr':            random = Math.random() * 0.03;            ret = function (r) {                return r + random;            };            break;    }    return ret;}function startSakura() {    requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame || window.msRequestAnimationFrame || window.oRequestAnimationFrame;    var canvas = document.createElement('canvas'),        cxt;    staticx = true;    canvas.height = window.innerHeight;    canvas.width = window.innerWidth;    canvas.setAttribute('style', 'position: fixed;left: 0;top: 0;pointer-events: none;');    canvas.setAttribute('id', 'canvas_sakura');    document.getElementsByTagName('body')[0].appendChild(canvas);    cxt = canvas.getContext('2d');    var sakuraList = new SakuraList();    for (var i = 0; i &lt; 50; i++) {        var sakura, randomX, randomY, randomS, randomR, randomFnx, randomFny;        randomX = getRandom('x');        randomY = getRandom('y');        randomR = getRandom('r');        randomS = getRandom('s');        randomFnx = getRandom('fnx');        randomFny = getRandom('fny');        randomFnR = getRandom('fnr');        sakura = new Sakura(randomX, randomY, randomS, randomR, {            x: randomFnx,            y: randomFny,            r: randomFnR        });        sakura.draw(cxt);        sakuraList.push(sakura);    }    stop = requestAnimationFrame(function () {        cxt.clearRect(0, 0, canvas.width, canvas.height);        sakuraList.update();        sakuraList.draw(cxt);        stop = requestAnimationFrame(arguments.callee);    })}window.onresize = function () {    var canvasSnow = document.getElementById('canvas_snow');}img.onload = function () {    startSakura();}function stopp() {    if (staticx) {        var child = document.getElementById("canvas_sakura");        child.parentNode.removeChild(child);        window.cancelAnimationFrame(stop);        staticx = false;    } else {        startSakura();    }}</code></pre><p>然后在 /themes/matery/layout/_partial/layout.ejs 中添加如下代码：</p><pre><code>&lt;% if (theme.sakura.enable) { %&gt;    &lt;script type="text/javascript"&gt;    //只在桌面版网页启用特效    var windowWidth = $(window).width();    if (windowWidth &gt; 768) {        document.write('&lt;script type="text/javascript" src="/js/sakura.js"&gt;&lt;/script&gt;');    }    &lt;/script&gt;&lt;% } %&gt;</code></pre><p>在matery主题配置文件_config .yml中配置:</p><pre><code># 页面樱花飘落动效sakura:  enable: true</code></pre><h1 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h1><pre><code class="git">hexo clean  #清理public的内容hexo g#重新编译hexo s#本地运行hexo d#上传github</code></pre>]]></content>
      
      
      <categories>
          
          <category> 总结（非技术文） </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/07/22/hello-world/"/>
      <url>/2023/07/22/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new "My New Post"</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>linux安装tomcat（docker）</title>
      <link href="/2023/04/01/linux%E5%AE%89%E8%A3%85tomcat%EF%BC%88docker%EF%BC%89/"/>
      <url>/2023/04/01/linux%E5%AE%89%E8%A3%85tomcat%EF%BC%88docker%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>在终端输入，在docker hub上面查找tomcat镜像</p><pre><code>docker search tomcat</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/4dec3d4273b6f7e828e7ebd8bc786711.png"></p><p>从docker hub上拉取tomcat镜像到本地</p><pre><code>docker pull tomcat</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/90bfcc3d272cab4d53af9525c9c5249f.png"></p><p>查看是否有拉取到的tomcat</p><pre><code>docker images</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/f9d78982e33a3ee4b01ce7af517d4397.png"></p><p>使用tomcat镜像创建容器实例（也叫运行镜像）</p><pre><code>docker run -it -p 8080:8080 tomcat</code></pre><p>运行以8080为端口的tomcat</p><ul><li>-p小写，主机端口：docker容器端口</li></ul><ul><li><p>-P大写，随机分配端口</p></li><li><p>i:交互</p></li><li><p>t:终端</p></li><li><p>d:后台</p></li></ul><p>查看正在运行的容器</p><pre><code>docker ps</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/967ca8b202bcabe732c403cc8f5bdf46.png"></p><p>可以看到tomcat正在运行中。</p><p>但是访问ip地址+8080返回的却是404.</p><p>所以做下面的一些配置：</p><pre><code>docker exec -it 33208d40ca85 /bin/bash</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/2b230d361d840a1ac5b40b1aa61ffdde.png"></p><p>可以看到目录变成了usr下的tomcat</p><p>之后执行</p><pre><code>rm -r webapps</code></pre><pre><code>mv webapps.dist webapps</code></pre><p>此时再访问不出意外cat就出来了。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/01aa1247260f83050fe0a79461bd3d69.png"></p><p>近日总结：最近有些疲惫，大概是夏天将近吧。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker tomcat linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅聊Docker</title>
      <link href="/2023/03/30/%E6%B5%85%E8%81%8ADocker/"/>
      <url>/2023/03/30/%E6%B5%85%E8%81%8ADocker/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>目录</strong></p><p><a href="#zPfMs">文档</a></p><p><a href="#GS1I4">docker简介</a></p><p><a href="#vCEMD">docker的下载与安装</a></p><p><a href="#n8nV7">在自己服务器上查看服务器内核版本信息</a></p><p><a href="#XqzCs">先安装gcc环境</a></p><p><a href="#eLO9g">设置stable镜像仓库</a></p><p><a href="#C1q4M">更新yum软件包索引</a></p><p><a href="#W6fpB">安装docker ce</a></p><p><a href="#uFu7k">查看自己的docker安装地址</a></p><p><a href="#VzVws">测试</a></p><p><a href="#gFmUu">查看docker版本</a></p><p><a href="#ceq5m">卸载docker</a></p><p><a href="#aWkLC">镜像加速器配置</a></p><hr><h1 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h1><p>中午文档：<a href="http://docker.p2hp.com/" title="Docker中文网 官网">Docker中文网 官网</a></p><p><a href="https://docs.docker.com/get-started/#what-is-a-container" title="Overview">Overview</a></p><p>文档上说的已经很好了，下面的就写一些其他的东西。</p><h1 id="docker简介"><a href="#docker简介" class="headerlink" title="docker简介"></a>docker简介</h1><p>docker：解决了运行环境和配置问题的软件容器，方便做持续集成并有助于整体发布的容器虚拟化技术。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/138334cff93260b2605998cd3dc7d86c.png"></p><h1 id="docker的下载与安装"><a href="#docker的下载与安装" class="headerlink" title="docker的下载与安装"></a>docker的下载与安装</h1><ul><li>docker的三个基本组成：镜像，容器，仓库。</li></ul><h2 id="在自己服务器上查看服务器内核版本信息"><a href="#在自己服务器上查看服务器内核版本信息" class="headerlink" title="在自己服务器上查看服务器内核版本信息"></a>在自己服务器上查看服务器内核版本信息</h2><ul><li>目前，centOS仅发行版本中的内核支持docker，docker运行在centOS7（64-bit）上，需要系统为64位，Linux系统内核版本为3.8以上。</li></ul><pre><code>uname -srm</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/862ffc06108ec2749793696829c9fbde.png"></p><h2 id="先安装gcc环境"><a href="#先安装gcc环境" class="headerlink" title="先安装gcc环境"></a>先安装gcc环境</h2><pre><code>yum -y install gcc</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/e6c1f1584c5da131e84390cc0df29e41.png"></p><p>我的是已经安装过了。</p><h2 id="设置stable镜像仓库"><a href="#设置stable镜像仓库" class="headerlink" title="设置stable镜像仓库"></a>设置stable镜像仓库</h2><pre><code>yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/9a78a94dc7549d0d13d312da2b6f4002.png"></p><p>我的是已经安装过了。</p><h2 id="更新yum软件包索引"><a href="#更新yum软件包索引" class="headerlink" title="更新yum软件包索引"></a>更新yum软件包索引</h2><pre><code>yum makecache timer</code></pre><h2 id="安装docker-ce"><a href="#安装docker-ce" class="headerlink" title="安装docker ce"></a>安装docker ce</h2><pre><code>yum -y install docker-ce-cli containerd.io</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/c670bb889f528da7ee61ce89a946f926.png"></p><h2 id="查看自己的docker安装地址"><a href="#查看自己的docker安装地址" class="headerlink" title="查看自己的docker安装地址"></a>查看自己的docker安装地址</h2><pre><code>whereis docker</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/d65d199ff542dc3eb700643b1d0a71aa.png"></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="查看docker版本"><a href="#查看docker版本" class="headerlink" title="查看docker版本"></a>查看docker版本</h3><pre><code>docker version</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/6f515e2805304cf60855dbd24c3316e9.png"></p><p>运行hello-world</p><pre><code>docker run hello-world</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/05165337d21dd8065618855a6d81fb9a.png"></p><h2 id="卸载docker"><a href="#卸载docker" class="headerlink" title="卸载docker"></a>卸载docker</h2><pre><code>systemctl stop docker</code></pre><pre><code>yum remove docker-ce docker-ce-cli containedrd.io</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/6a9e60bdbd0980afa6bd79874d5ba56e.png"></p><p>查看是否删除干净</p><pre><code>docker version</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/9e59c73dad669ef7edea373d4526819e.png"></p><h1 id="镜像加速器配置"><a href="#镜像加速器配置" class="headerlink" title="镜像加速器配置"></a>镜像加速器配置</h1><ul><li>进入阿里云</li></ul><p><a href="https://www.aliyun.com/?utm_content=se_1013083955" title="阿里云-为了无法计算的价值">阿里云-为了无法计算的价值</a></p><p><img src="https://img-blog.csdnimg.cn/img_convert/5ba1d2203e487b045bc4917121baafa2.png"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/1213ed4fe91ac9da8849fc9dd15aa16d.png"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/ed5e5a692becf8a3a89bf4090831968d.png"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/8850f34fda56ce55525ac012e5d8c47c.png"></p><p>可以直接全部粘到控制台上，也可以逐行粘过去。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/9a5b1d27f51f7817184d2ef9a6a1c4c2.png"></p><p>重启</p><pre><code>systemctl daemon-reload</code></pre><pre><code>systemctl restart docker</code></pre><p>到此就配置完成了。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker 运维 linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sentinel持久化规则</title>
      <link href="/2023/03/26/Sentinel%E6%8C%81%E4%B9%85%E5%8C%96%E8%A7%84%E5%88%99/"/>
      <url>/2023/03/26/Sentinel%E6%8C%81%E4%B9%85%E5%8C%96%E8%A7%84%E5%88%99/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>将限流配置规则持久化进nacos保护，只要刷新8401某个rest地址，sentinel控制台的流控规则就能看到，只要nacos里main的配置不能删除，针对8401上sentinel上的流控规则持续有效。</p><p>对8401进行操作:</p><p><img src="https://img-blog.csdnimg.cn/img_convert/bbc7e9c8966c66c45cae6090c3800900.png"></p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt;    &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt;    &lt;version&gt;1.8.6&lt;/version&gt;&lt;/dependency&gt;</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/57c8cb83341e3f9d9b4e6fe87eeb9e15.png"></p><pre><code>server:  port: 8401spring:  application:    name: cloudalibaba-sentinel-service  cloud:    nacos:      discovery:        server-addr: 你的nacos地址 #Nacos服务注册中心地址    sentinel:      transport:        dashboard: localhost:8080 #配置Sentinel dashboard地址        port: 8719      datasource:        ds1:          nacos:            server-addr: 你的nacos地址  #nacos地址            dataId: cloudalibaba-sentinel-service            groupId: DEFAULT_GROUP            data-type: json            rule-type: flowmanagement:  endpoints:    web:      exposure:        include: '*'#feign:#  sentinel:#    enabled: true # 激活Sentinel对Feign的支持</code></pre><p>在nacos中新增一个配置：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/0d3be40eaa19f60f8d7c7797056dc8c6.png"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/f84a10a130dd9a43eb068e24ab239ad4.png"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/23bdc2690ab910a19e74bb894272f220.png"></p><pre><code>[    {        "resource": "/rateLimit/byUrl",        "limitApp": "default",        "grade": 1,        "count": 1,        "strategy": 0,        "countrolBehavior": 0,        "clusterMode": false    }]</code></pre><p>重新启动8401，访问：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/89b0017d4a1b9fa516d5ba042bde9dbd.png"></p><p>可以看到</p><p><img src="https://img-blog.csdnimg.cn/img_convert/c4c5f9e332377f9c48e12319979012c2.png"></p><p>这里是存在的。</p><p>关闭8401服务，这个流控规则就会消失，再重启访问</p><p><img src="https://img-blog.csdnimg.cn/img_convert/a26843214c54ee4df23431feceddcf55.png"></p><p>流控规则就会又出现了。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sentinel java 开发语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聊聊Sentinel</title>
      <link href="/2023/03/23/%E8%81%8A%E8%81%8ASentinel/"/>
      <url>/2023/03/23/%E8%81%8A%E8%81%8ASentinel/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>目录</strong></p><p><a href="#Sentinel%E7%9A%84%E4%B8%8B%E8%BD%BD">Sentinel的下载</a></p><p><a href="#Sentinel%E7%9A%84%E5%90%AF%E5%8A%A8">Sentinel的启动</a></p><p><a href="#Sentinel%E4%BB%8B%E7%BB%8D">Sentinel介绍</a></p><p><a href="#Sentinel%20%E7%9A%84%E5%8E%86%E5%8F%B2">Sentinel 的历史</a></p><p><a href="#Sentinel%20%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5">Sentinel 基本概念</a></p><p><a href="#%E8%B5%84%E6%BA%90">资源</a></p><p><a href="#%E8%A7%84%E5%88%99">规则</a></p><p><a href="#%E6%9B%B4%E6%94%B9sentinel%E5%90%AF%E5%8A%A8%E7%AB%AF%E5%8F%A3">更改sentinel启动端口</a></p><hr><p>Sentinel官网：</p><p><a href="https://github.com/alibaba/Sentinel" title="GitHub - alibaba/Sentinel: A powerful flow control component enabling reliability, resilience and monitoring for microservices. (面向云原生微服务的高可用流控防护组件)">GitHub - alibaba/Sentinel: A powerful flow control component enabling reliability, resilience and monitoring for microservices. (面向云原生微服务的高可用流控防护组件)</a></p><h1 id="Sentinel的下载"><a href="#Sentinel的下载" class="headerlink" title="Sentinel的下载"></a>Sentinel的下载</h1><p>先来到官网（上）：<img src="https://img-blog.csdnimg.cn/565f70217ddb4a43a376787976a71dc6.png"></p><p><img src="https://img-blog.csdnimg.cn/303e0a70bee544aea74b33ede2cc3e7f.png">&nbsp;<img src="https://img-blog.csdnimg.cn/9e492e4616cf4b97b9af612a05ad0b04.png"></p><p><img src="https://img-blog.csdnimg.cn/ded7b8bb56784aecbbb611c6c545dcfe.png"><img src="https://img-blog.csdnimg.cn/e93222059b5f42b381842185a19eefb3.png">&nbsp;</p><p><img src="https://img-blog.csdnimg.cn/df3f1c6c0ef44d00b9ecc52655b4b784.png"></p><p>朝下翻</p><p><img src="https://img-blog.csdnimg.cn/734d46905f2b4d31aa23ebbad440b125.png">&nbsp;&nbsp;</p><p>选择自己想要的版本下载即可。</p><p><img src="https://img-blog.csdnimg.cn/aa43aad0e6fb41d69fbda5822d99a8c7.png"></p><p>启动成功。。。</p><p>在自己浏览器上访问：<a href="http://localhost:8080/#/login">http://localhost:8080/#/login</a>&nbsp;</p><p><img src="https://img-blog.csdnimg.cn/a8170a3a75d24b019a15093e98eeee53.png"></p><p>访问成功。。。</p><p>用户密码都是sentinel</p><p><img src="https://img-blog.csdnimg.cn/567d0da0a95840b8b8a6e3ee1ba47f85.png"></p><h1 id="Sentinel的启动"><a href="#Sentinel的启动" class="headerlink" title="Sentinel的启动"></a>Sentinel的启动</h1><p>在终端上输入</p><pre><code>java -jar 你的jar包地址</code></pre><p>我的是：</p><pre><code>java -jar /Volumes/JAVA_Web/JAVAWeb/springcloud/sentinel-dashboard-1.8.6.jar</code></pre><p>&nbsp;</p><h1 id="Sentinel介绍"><a href="#Sentinel介绍" class="headerlink" title="Sentinel介绍"></a>Sentinel介绍</h1><p>随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 是面向分布式、多语言异构化服务架构的流量治理组件，主要以流量为切入点，从流量路由、流量控制、流量整形、熔断降级、系统自适应过载保护、热点流量防护等多个维度来帮助开发者保障微服务的稳定性。</p><h2 id="Sentinel-的历史"><a href="#Sentinel-的历史" class="headerlink" title="Sentinel 的历史"></a>Sentinel 的历史</h2><ul><li>2012 年，Sentinel 诞生，主要功能为入口流量控制。</li><li>2013-2017 年，Sentinel 在阿里巴巴集团内部迅速发展，成为基础技术模块，覆盖了所有的核心场景。Sentinel 也因此积累了大量的流量归整场景以及生产实践。</li><li>2018 年，Sentinel 开源，并持续演进。</li><li>2019 年，Sentinel 朝着多语言扩展的方向不断探索，推出&nbsp;<a href="https://github.com/alibaba/sentinel-cpp" title="C++ 原生版本">C++ 原生版本</a>，同时针对 Service Mesh 场景也推出了&nbsp;<a href="https://github.com/alibaba/Sentinel/tree/master/sentinel-cluster/sentinel-cluster-server-envoy-rls" title="Envoy 集群流量控制支持">Envoy 集群流量控制支持</a>，以解决 Service Mesh 架构下多语言限流的问题。</li><li>2020 年，推出&nbsp;<a href="https://github.com/alibaba/sentinel-golang" title="Sentinel Go 版本">Sentinel Go 版本</a>，继续朝着云原生方向演进。</li><li>2021 年，Sentinel 正在朝着 2.0 云原生高可用决策中心组件进行演进；同时推出了&nbsp;<a href="https://github.com/sentinel-group/sentinel-rust" title="Sentinel Rust 原生版本">Sentinel Rust 原生版本</a>。同时我们也在 Rust 社区进行了 Envoy WASM extension 及 eBPF extension 等场景探索。</li><li>2022 年，Sentinel 品牌升级为流量治理，领域涵盖流量路由/调度、流量染色、流控降级、过载保护/实例摘除等；同时社区将流量治理相关标准抽出到&nbsp;<a href="https://opensergo.io/zh-cn/" title="OpenSergo 标准">OpenSergo 标准</a>中，Sentinel 作为流量治理标准实现。</li></ul><h1 id="Sentinel-基本概念"><a href="#Sentinel-基本概念" class="headerlink" title="Sentinel 基本概念"></a>Sentinel 基本概念</h1><h3 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h3><p>资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。在接下来的文档中，我们都会用资源来描述代码块。</p><p>只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。</p><h3 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h3><p>围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。</p><p>参考自：<a href="https://sentinelguard.io/zh-cn/docs/introduction.html" title="introduction | Sentinel">introduction | Sentinel</a>&nbsp;</p><p>推荐：<a href="https://blog.csdn.net/truelove12358/article/details/107507455?spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-107507455-blog-108728905.235%5Ev26%5Epc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-107507455-blog-108728905.235%5Ev26%5Epc_relevant_default&amp;utm_relevant_index=1" title="Sentinel 对比 Hystrix（选型与简介）_sentinel hystrix_MayMatrix的博客-CSDN博客">Sentinel 对比 Hystrix（选型与简介）_sentinel hystrix_MayMatrix的博客-CSDN博客</a></p><h1 id="更改sentinel启动端口"><a href="#更改sentinel启动端口" class="headerlink" title="更改sentinel启动端口"></a>更改sentinel启动端口</h1><p>进入你的jar包所在目录，输入：</p><pre><code>java -Dserver.port=8070 -Dcsp.sentinel.dashboard.server=localhost:8070 -Dproject.name=sentinel -jar sentinel.jar</code></pre><p>我的是指定的8070端口启动，我的jar包名字改成了这样，所以大家在用上面的命令指定端口启动sentinel的时候需要更改一下jar包的名字。</p><p><img src="https://img-blog.csdnimg.cn/03c53d0f82b8469a96ebf8db29ec3a1f.png"></p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sentinel 云原生 java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Feign</title>
      <link href="/2023/03/09/Feign/"/>
      <url>/2023/03/09/Feign/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>而Feign则会完全代理HTTP请求，我们只需要像调用方法一样调用它就可以完成服务请求及相关处理。Feign整合了Ribbon和Hystrix，可以让我们不再需要显式地使用这两个组件。</p><h2 id="Feign具有如下特性："><a href="#Feign具有如下特性：" class="headerlink" title="Feign具有如下特性："></a>Feign具有如下特性：</h2><p>支持可插拔的HTTP编码器和解码器;</p><p>支持Hystrix和它的Fallback;</p><p>支持Ribbon的负载均衡;</p><p>支持HTTP请求和响应的压缩。</p><p>有点像我们springmvc模式的Controller层的RequestMapping映射。这Feign是用@FeignClient来映射服务的。</p><h2 id="创建一个项目"><a href="#创建一个项目" class="headerlink" title="创建一个项目"></a>创建一个项目</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/8adc0f1a8fb3c1185c16355f47c90218.png"></p><pre><code>&lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;            &lt;version&gt;2.2.7.RELEASE&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;            &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;            &lt;version&gt;4.0.1&lt;/version&gt;            &lt;scope&gt;provided&lt;/scope&gt;        &lt;/dependency&gt;        &lt;!--eureka-server--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;            &lt;version&gt;2.2.1.RELEASE&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt;            &lt;groupId&gt;com&lt;/groupId&gt;            &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt;            &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;</code></pre><p>总依赖：</p><pre><code class="XML">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;    &lt;/parent&gt;    &lt;groupId&gt;com&lt;/groupId&gt;    &lt;artifactId&gt;springcloud&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;    &lt;name&gt;cloud-consumer-feign-order80&lt;/name&gt;    &lt;description&gt;cloud-consumer-feign-order80&lt;/description&gt;    &lt;properties&gt;        &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;            &lt;version&gt;2.2.7.RELEASE&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;            &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;            &lt;version&gt;4.0.1&lt;/version&gt;            &lt;scope&gt;provided&lt;/scope&gt;        &lt;/dependency&gt;        &lt;!--eureka-server--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;            &lt;version&gt;2.2.1.RELEASE&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt;            &lt;groupId&gt;com&lt;/groupId&gt;            &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt;            &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;            &lt;scope&gt;runtime&lt;/scope&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;version&gt;3.8.1&lt;/version&gt;                &lt;configuration&gt;                    &lt;source&gt;1.8&lt;/source&gt;                    &lt;target&gt;1.8&lt;/target&gt;                    &lt;encoding&gt;UTF-8&lt;/encoding&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><p>application.yml</p><pre><code class="XML">server:  port: 80eureka:  client:    register-with-eureka: false    service-url:      defaultZone: http://localhost:7001/eureka,http://localhost:7002/eureka</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/d865438e932d25f69eccc04d69d39bf9.png"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/c96876060e0483e1953bcca763015c11.png"></p><p><img src="https://img-blog.csdnimg.cn/img_convert/a14611788593922e0ba1ccd2741a133e.png"></p><p>运行项目，可以成功访问到。</p><p>先启动7001与7002，再启动8001，8002，最后再启动80.</p><h2 id="OpenFign日志增强"><a href="#OpenFign日志增强" class="headerlink" title="OpenFign日志增强"></a>OpenFign日志增强</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/bbf0b60ebc67f601bcb6bd9b13f49194.png"></p><p>FeignConfig</p><pre><code class="java">package com.springcloud.config;import feign.Logger;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @auther zzyy * @create 2020-02-20 9:40 */@Configurationpublic class FeignConfig{    @Bean    Logger.Level feignLoggerLevel()    {        return Logger.Level.FULL;    }}</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/ceea6589fa8de132466cd90e88170ada.png"></p><pre><code class="java">server:  port: 80eureka:  client:    register-with-eureka: false    service-url:      defaultZone: http://localhost:7001/eureka,http://localhost:7002/eurekalogging:  level:    # feign日志以什么级别监控哪个接口    com.springcloud.service.PaymentService: debug</code></pre><p>运行项目。</p><p>控制台：</p><p><img src="https://img-blog.csdnimg.cn/img_convert/151e5179b927c8d2e9f10c04148cd4a5.png"></p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> eureka java spring cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>nacos mac</title>
      <link href="/2022/12/30/nacos%20mac/"/>
      <url>/2022/12/30/nacos%20mac/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>目录</strong></p><p><a href="#%E4%B8%80.nacos%E7%9A%84%E4%B8%8B%E8%BD%BD">一.nacos的下载</a></p><p><a href="#%E4%BA%8C.nacos%E7%9A%84%E5%90%AF%E5%8A%A8%E4%B8%8E%E7%BB%88%E6%AD%A2">二.nacos的启动与终止</a></p><p><a href="#%E4%B8%89.%E8%BF%9B%E5%85%A5%E5%8F%AF%E8%A7%86%E5%8C%96%E9%A1%B5%E9%9D%A2">三.进入可视化页面</a></p><hr><h1 id="一-nacos的下载"><a href="#一-nacos的下载" class="headerlink" title="一.nacos的下载"></a>一.nacos的下载</h1><p>进入官网：<a href="https://nacos.io/zh-cn/" title="home">home</a></p><p><img src="https://img-blog.csdnimg.cn/e61a19113116475ea8ae4e67c585eadd.png"></p><p><img src="https://img-blog.csdnimg.cn/d5caaa970825482f8c8f124e63d56409.png"></p><p>朝下翻</p><p><img src="https://img-blog.csdnimg.cn/f12f49c4ec3d48c79426c86fdb954886.png"></p><p><img src="https://img-blog.csdnimg.cn/6e7c9fab345f4615a3ac9d875d35e4d2.png"></p><p><img src="https://img-blog.csdnimg.cn/a33151a8c2c3452488d8e9c0372451e4.png"></p><p>下载一点几版本的，2点几的已经停止更新了。</p><p>将下载好的文件放入一个没有中文名称的目录下</p><p>快捷通道：<a href="https://github.com/alibaba/nacos/releases/tag/1.4.5" title="Release 1.4.5 (Mar 17th, 2023) · alibaba/nacos · GitHub">Release 1.4.5 (Mar 17th, 2023) · alibaba/nacos · GitHub</a></p><p>nacos目录：</p><p><img src="https://img-blog.csdnimg.cn/10da25fba6ff476b83bb50b001d6e28e.png"></p><p>&nbsp;<img src="https://img-blog.csdnimg.cn/185873d8cd494d11a60019022ebb194d.png"></p><h1 id="二-nacos的启动与终止"><a href="#二-nacos的启动与终止" class="headerlink" title="二.nacos的启动与终止"></a>二.nacos的启动与终止</h1><p>**打开终端，进入bin目录下&nbsp;**</p><p>我的是：</p><pre><code>cd /Volumes/JAVA_Web/JAVAWeb/springcloud/nacos/bin</code></pre><p>大家按照自己的目录来就好</p><p>输入</p><pre><code class="java">sh startup.sh -m standalone</code></pre><p><strong>启动</strong>成功</p><p><img src="https://img-blog.csdnimg.cn/a316994744454dd89855004b36661ec8.png"></p><p>关闭nacos</p><pre><code class="java">sh shutdown.sh</code></pre><h1 id="三-进入可视化页面"><a href="#三-进入可视化页面" class="headerlink" title="三.进入可视化页面"></a>三.进入可视化页面</h1><p><a href="http://localhost:8848/nacos/#/login">http://localhost:8848/nacos/#/login</a></p><p><img src="https://img-blog.csdnimg.cn/fcdbc7167fae4dc0a197a360150488e7.png"></p><p><img src="https://img-blog.csdnimg.cn/bb2fdf3108f3436a99ce5ba74accd68d.png"></p><p>近日总结一下：</p><p>最近一直在为期末考试头疼，下周各科考试就展开序幕了。</p><p>最近一段时间过得挺闲的哈。</p><p>前几天老师给我们开了会，经过年度总结我也对自己2023年的规划有了更为清晰的认知。</p><p>哇咔咔，加油加油～</p><p>此博客后续还会继续更新哒～</p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java 开发语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mysql一些小知识点</title>
      <link href="/2022/12/27/mysql%E4%B8%80%E4%BA%9B%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
      <url>/2022/12/27/mysql%E4%B8%80%E4%BA%9B%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1 id="mysql的三值逻辑"><a href="#mysql的三值逻辑" class="headerlink" title="mysql的三值逻辑"></a>mysql的三值逻辑</h1><p>mysql 使用的是三值逻辑：TRUE&nbsp; &nbsp;FALSE&nbsp;&nbsp;&nbsp;UNKNOWN。</p><p>任何与null值进行的比较都会与第三种值 UNKNOWN 做比较。这个“任何值”包括 null 本身。</p><p>所以mysql&nbsp;提供了 is null&nbsp;和 is not null&nbsp;两种操作来对null做特殊判断</p><p>因此，在进行select查询时，如果查询到的值有为空的时候，在where语句中我们就需要再做一</p><p>个额外的条件判断 ，比如：’name is null’;</p><p>举个栗子：</p><p>返回一个用户列表，列表中用户的年龄都不是18.</p><pre><code>select name from user where age &lt;&gt; 18 or  age is null</code></pre><h1 id="not-in"><a href="#not-in" class="headerlink" title="not in"></a>not in</h1><pre><code>select Name 'Customers' from Customers where Id not in(select CustomerId from Orders)</code></pre><p>用来查询不在某个值集的数据</p><p>举个栗子：</p><p>查询user表中年龄不在18，15，20的用户</p><pre><code>select name from user where age not in(18,15,20)</code></pre><p>推荐：<a href="http://c.biancheng.net/mysql/10/" title="数据库入门">数据库入门</a></p><h1 id="mod-a-b"><a href="#mod-a-b" class="headerlink" title="mod(a,b)"></a>mod(a,b)</h1><p>在sql中的意思是 a / b 的余数，如果某个字段需要是偶数或者奇数时就可以使用mod。</p><p>以id为例：</p><p>mod(id,2)=1 是指id是奇数。</p><p>mod(id,2)=0 是指id是偶数。</p><h1 id="left"><a href="#left" class="headerlink" title="left()"></a>left()</h1><p><code>left()</code>函数是一个字符串函数，它返回具有指定长度的字符串的左边部分。</p><p>格式:left(str,length)。</p><h1 id="if-exer-v1-v2"><a href="#if-exer-v1-v2" class="headerlink" title="if(exer,v1,v2)"></a>if(exer,v1,v2)</h1><p>语法结构是if(exer,v1,v2)</p><p>expr为一个表达式,表达式expr结果为ture,返回v1的值,为flase返回v2。</p><pre><code>update salary set sex=if(sex='m','f','m')</code></pre><p>后续会继续完善当前文章。。。</p>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql 数据库 java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mybatis-plus实战项目演示+自定义元数据对象处理器+ws</title>
      <link href="/2022/12/09/Mybatis-plus%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%E6%BC%94%E7%A4%BA+%E8%87%AA%E5%AE%9A%E4%B9%89%E5%85%83%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%E5%A4%84%E7%90%86%E5%99%A8+ws/"/>
      <url>/2022/12/09/Mybatis-plus%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%E6%BC%94%E7%A4%BA+%E8%87%AA%E5%AE%9A%E4%B9%89%E5%85%83%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%E5%A4%84%E7%90%86%E5%99%A8+ws/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>目录</strong></p><p><a href="#%E4%B8%80%EF%BC%8Cmybatis-plus%E5%AE%9E%E6%88%98%E4%B8%80">一，mybatis-plus实战一</a></p><p><a href="#1.%E5%AF%BC%E5%85%A5%E4%BE%9D%E8%B5%96">1.导入依赖</a></p><p><a href="#2.application.yml%E9%85%8D%E7%BD%AE">2.application.yml配置</a></p><p><a href="#3.%E5%AE%9E%E4%BD%93%E7%B1%BB">3.实体类</a></p><p><a href="#4.mapper">4.mapper</a></p><p><a href="#5.service%E5%B1%82">5.service层</a></p><p><a href="#6.%E5%90%AF%E5%8A%A8%E7%B1%BB%E4%B8%8A%E9%85%8D%E7%BD%AE">6.启动类上配置</a></p><p><a href="#%E4%BA%8C%EF%BC%8Cmybatis-plus%E5%AE%9E%E6%88%98%E4%BA%8C">二，mybatis-plus实战二</a></p><p><a href="#1.%E5%AF%BC%E5%85%A5%E4%BE%9D%E8%B5%96">1.导入依赖</a></p><p><a href="#2.application.yml%E9%85%8D%E7%BD%AE">2.application.yml配置</a></p><p><a href="#3.%E5%AE%9E%E4%BD%93%E7%B1%BB">3.实体类</a></p><p><a href="#2.mapper">2.mapper</a></p><p><a href="#3.service">3.service</a></p><p><a href="#4.%E5%88%86%E9%A1%B5%E9%85%8D%E7%BD%AE">4.分页配置</a></p><p><a href="#5.%E6%94%BE%E4%B8%80%E4%B8%AA%E5%9C%A8controller%E5%B1%82%E5%AE%9E%E7%8E%B0%E7%9A%84mybatis-plus%E7%9A%84%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0">5.放一个在controller层实现的mybatis-plus的具体实现</a></p><p><a href="#6.%E5%90%AF%E5%8A%A8%E7%B1%BB%E4%B8%8A%E5%8A%A0%E4%B8%8A%E6%B3%A8%E8%A7%A3">6.启动类上加上注解</a></p><p><a href="#%E4%B8%89%EF%BC%8C%E6%97%B6%E9%97%B4%E6%9B%B4%E6%96%B0%E5%85%A8%E5%B1%80%E9%85%8D%E7%BD%AE%EF%BC%88%E8%87%AA%E5%AE%9A%E4%B9%89%E5%85%83%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%E5%A4%84%E7%90%86%E5%99%A8%EF%BC%89">三，时间更新全局配置（自定义元数据对象处理器）</a></p><p><a href="#1.%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%E5%AD%97%E6%AE%B5%E9%85%8D%E7%BD%AE">1.数据库相关字段配置</a></p><p><a href="#2.%20%E5%AE%9E%E4%BD%93%E7%B1%BB%E9%85%8D%E7%BD%AE">2. 实体类配置</a></p><p><a href="#%E5%9B%9B.WebSocket%E6%89%93%E9%80%A0%E5%9C%A8%E7%BA%BF%E8%81%8A%E5%A4%A9%E5%AE%A4">四.WebSocket打造在线聊天室</a></p><p><a href="#1.%E5%AF%BC%E5%85%A5%E4%BE%9D%E8%B5%96">1.导入依赖</a></p><p><a href="#2.%E9%85%8D%E7%BD%AE%E7%B1%BB">2.配置类</a></p><p><a href="#%C2%A03.%E5%B7%A5%E5%85%B7%E7%B1%BB">&nbsp;3.工具类</a></p><p><a href="#4.controller">4.controller</a></p><p><a href="#5.index.html">5.index.html</a></p><hr><h1 id="一，mybatis-plus实战一"><a href="#一，mybatis-plus实战一" class="headerlink" title="一，mybatis-plus实战一"></a>一，mybatis-plus实战一</h1><h2 id="1-导入依赖"><a href="#1-导入依赖" class="headerlink" title="1.导入依赖"></a>1.导入依赖</h2><pre><code>        &lt;dependency&gt;            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;            &lt;version&gt;3.5.1&lt;/version&gt;        &lt;/dependency&gt;</code></pre><h2 id="2-application-yml配置"><a href="#2-application-yml配置" class="headerlink" title="2.application.yml配置"></a>2.application.yml配置</h2><pre><code>spring:  # 配置数据源信息  datasource:    # 配置数据源类型    type: com.zaxxer.hikari.HikariDataSource    # 配置连接数据库的各个信息    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://localhost:3306/intrest?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTC    username: root    password: 12345678mybatis-plus:  configuration:    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl#  # 设置MyBatis-Plus的全局配置#  global-config:#    db-config:#      # 设置实体类所对应的表的统一前缀#      table-prefix: t_#      # 设置统一的主键生成策略#      id-type: auto#  # 配置类型别名所对应的包  type-aliases-package: com.interest.pojo#  # 扫描通用枚举的 # 包#  type-enums-package: com.interest.enums</code></pre><h2 id="3-实体类"><a href="#3-实体类" class="headerlink" title="3.实体类"></a>3.实体类</h2><pre><code class="java">package com.interest.pojo;import com.baomidou.mybatisplus.annotation.IdType;import com.baomidou.mybatisplus.annotation.TableId;import com.baomidou.mybatisplus.annotation.TableName;import com.fasterxml.jackson.databind.annotation.JsonSerialize;import com.fasterxml.jackson.databind.ser.std.ToStringSerializer;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;/** * @author a1002 */@Data@AllArgsConstructor@NoArgsConstructor@TableName("interest")public class Interest {    @JsonSerialize(using = ToStringSerializer.class)    @TableId(value = "id", type = IdType.ASSIGN_ID)    private Long id;    private String code;    private String name;    private String sex;    private String birthday;    private String phone;    private String type;    private String course;    private String registerTime;    private String remaining;    private String score;    public Interest(String code, String name, String sex, String birthday, String phone, String type, String course, String registerTime, String remaining, String score) {        this.code = code;        this.name = name;        this.sex = sex;        this.birthday = birthday;        this.phone = phone;        this.type = type;        this.course = course;        this.registerTime = registerTime;        this.remaining = remaining;        this.score = score;    }}</code></pre><h2 id="4-mapper"><a href="#4-mapper" class="headerlink" title="4.mapper"></a>4.mapper</h2><pre><code class="java">package com.interest.mapper;import com.baomidou.mybatisplus.core.mapper.BaseMapper;import com.interest.pojo.Interest;import org.springframework.stereotype.Repository;/** * @author a1002 */@Repositorypublic interface InterestMapper extends BaseMapper&lt;Interest&gt; {}</code></pre><h2 id="5-service层"><a href="#5-service层" class="headerlink" title="5.service层"></a>5.service层</h2><pre><code class="java">package com.interest.service;import com.baomidou.mybatisplus.extension.service.IService;import com.interest.config.Response;import com.interest.pojo.Interest;import java.util.List;import java.util.Map;/** * @author a1002 */public interface InterestService extends IService&lt;Interest&gt; {    }</code></pre><pre><code class="java">package com.interest.service.impl;import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;import com.baomidou.mybatisplus.core.conditions.update.UpdateWrapper;import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;import com.interest.config.Response;import com.interest.mapper.InterestMapper;import com.interest.pojo.Interest;import com.interest.service.InterestService;import com.interest.utils.IDutils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.HashMap;import java.util.LinkedList;import java.util.List;import java.util.Map;/** * @author a1002 */@Servicepublic class InterestServiceImpl extends ServiceImpl&lt;InterestMapper,Interest&gt; implements InterestService {}</code></pre><h2 id="6-启动类上配置"><a href="#6-启动类上配置" class="headerlink" title="6.启动类上配置"></a>6.启动类上配置</h2><pre><code class="java">import lombok.extern.slf4j.Slf4j;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cache.annotation.EnableCaching;import org.springframework.transaction.annotation.EnableTransactionManagement;/** * @author a1002 */@Slf4j@SpringBootApplication//@ServletComponentScan@EnableTransactionManagement@EnableCaching@MapperScan("com.blog.mapper")public class BlogApplication {    public static void main(String[] args) {        SpringApplication.run(BlogApplication.class, args);        log.info("项目启动成功...");    }}</code></pre><h1 id="二，mybatis-plus实战二"><a href="#二，mybatis-plus实战二" class="headerlink" title="二，mybatis-plus实战二"></a>二，mybatis-plus实战二</h1><h2 id="1-导入依赖-1"><a href="#1-导入依赖-1" class="headerlink" title="1.导入依赖"></a>1.导入依赖</h2><pre><code class="java">        &lt;!--mybaties-plus--&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;            &lt;version&gt;3.4.2&lt;/version&gt;        &lt;/dependency&gt;</code></pre><h2 id="2-application-yml配置-1"><a href="#2-application-yml配置-1" class="headerlink" title="2.application.yml配置"></a>2.application.yml配置</h2><pre><code class="java">mybatis-plus:  configuration:    #在映射实体或者属性时，将数据库中表名和字段名中的下划线去掉，按照驼峰命名法映射    map-underscore-to-camel-case: true    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl  global-config:    db-config:      id-type: ASSIGN_ID</code></pre><h2 id="3-实体类-1"><a href="#3-实体类-1" class="headerlink" title="3.实体类"></a>3.实体类</h2><pre><code class="java">import lombok.Data;import java.io.Serializable;@Datapublic class Orders implements Serializable {}</code></pre><h2 id="2-mapper"><a href="#2-mapper" class="headerlink" title="2.mapper"></a>2.mapper</h2><pre><code class="java">import com.baomidou.mybatisplus.core.mapper.BaseMapper;import com.yangeat.entity.AddressBook;import org.apache.ibatis.annotations.Mapper;/** * @author a1002 */@Mapperpublic interface AddressBookMapper extends BaseMapper&lt;AddressBook&gt; {}</code></pre><h2 id="3-service"><a href="#3-service" class="headerlink" title="3.service"></a>3.service</h2><pre><code class="java">import com.baomidou.mybatisplus.extension.service.IService;import com.yangeat.entity.AddressBook;/** * @author a1002 */public interface AddressBookService extends IService&lt;AddressBook&gt; {}</code></pre><pre><code class="java">import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;import com.yangeat.entity.AddressBook;import com.yangeat.mapper.AddressBookMapper;import com.yangeat.service.AddressBookService;import org.springframework.stereotype.Service;/** * @author a1002 */@Servicepublic class AddressBookServiceImpl extends ServiceImpl&lt;AddressBookMapper, AddressBook&gt; implements AddressBookService {}</code></pre><h2 id="4-分页配置"><a href="#4-分页配置" class="headerlink" title="4.分页配置"></a>4.分页配置</h2><pre><code class="java">package com.blog.config;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * 配置MP的分页插件 * * @author a1002 */@Configurationpublic class MybatisPlusConfig {    @Bean    public MybatisPlusInterceptor mybatisPlusInterceptor() {        MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor();        mybatisPlusInterceptor.addInnerInterceptor(new PaginationInnerInterceptor());        return mybatisPlusInterceptor;    }}</code></pre><p>分页实际应用：</p><pre><code class="java">@Override    public R list(int page, int size, String name) {        Page&lt;User&gt; pageInfo = new Page&lt;&gt;(page, size);        LambdaQueryWrapper&lt;User&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;();        queryWrapper.like(name != null, User::getUsername, name);        queryWrapper.orderByDesc(User::getUpdateTime);        userService.page(pageInfo, queryWrapper);        return R.success(pageInfo);    }</code></pre><h2 id="5-放一个在controller层实现的mybatis-plus的具体实现"><a href="#5-放一个在controller层实现的mybatis-plus的具体实现" class="headerlink" title="5.放一个在controller层实现的mybatis-plus的具体实现"></a>5.放一个在controller层实现的mybatis-plus的具体实现</h2><pre><code class="java">package com.yangeat.controller;import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;import com.baomidou.mybatisplus.extension.plugins.pagination.Page;import com.yangeat.common.R;import com.yangeat.dto.SetmealDto;import com.yangeat.entity.Category;import com.yangeat.entity.Setmeal;import com.yangeat.service.CategoryService;import com.yangeat.service.SetmealDishService;import com.yangeat.service.SetmealService;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.BeanUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.List;import java.util.stream.Collectors;/** * 套餐管理 */@RestController@RequestMapping("/setmeal")@Slf4jpublic class SetmealController {    @Autowired    private SetmealService setmealService;    @Autowired    private CategoryService categoryService;    @Autowired    private SetmealDishService setmealDishService;    /**     * 新增套餐     *     * @param setmealDto     * @return     */    @PostMapping    public R&lt;String&gt; save(@RequestBody SetmealDto setmealDto) {        log.info("套餐信息：{}", setmealDto);        setmealService.saveWithDish(setmealDto);        return R.success("新增套餐成功");    }    /**     * 套餐分页查询     *     * @param page     * @param pageSize     * @param name     * @return     */    @GetMapping("/page")    public R&lt;Page&gt; page(int page, int pageSize, String name) {        //分页构造器对象        Page&lt;Setmeal&gt; pageInfo = new Page&lt;&gt;(page, pageSize);        Page&lt;SetmealDto&gt; dtoPage = new Page&lt;&gt;();        LambdaQueryWrapper&lt;Setmeal&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;();        //添加查询条件，根据name进行like模糊查询        queryWrapper.like(name != null, Setmeal::getName, name);        //添加排序条件，根据更新时间降序排列        queryWrapper.orderByDesc(Setmeal::getUpdateTime);        setmealService.page(pageInfo, queryWrapper);        //对象拷贝        BeanUtils.copyProperties(pageInfo, dtoPage, "records");        List&lt;Setmeal&gt; records = pageInfo.getRecords();        List&lt;SetmealDto&gt; list = records.stream().map((item) -&gt; {            SetmealDto setmealDto = new SetmealDto();            //对象拷贝            BeanUtils.copyProperties(item, setmealDto);            //分类id            Long categoryId = item.getCategoryId();            //根据分类id查询分类对象            Category category = categoryService.getById(categoryId);            if (category != null) {                //分类名称                String categoryName = category.getName();                setmealDto.setCategoryName(categoryName);            }            return setmealDto;        }).collect(Collectors.toList());        dtoPage.setRecords(list);        return R.success(dtoPage);    }    /**     * 删除套餐     *     * @param ids     * @return     */    @DeleteMapping    public R&lt;String&gt; delete(@RequestParam List&lt;Long&gt; ids) {        log.info("ids:{}", ids);        setmealService.removeWithDish(ids);        return R.success("套餐数据删除成功");    }//    @GetMapping("/list")//    public R&lt;List&lt;Setmeal&gt;&gt; list(Setmeal setmeal) {//        log.info("setmeal:{}", setmeal);//        //条件构造器//        LambdaQueryWrapper&lt;Setmeal&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;();//        queryWrapper.like(StringUtils.isNotEmpty(setmeal.getName()), Setmeal::getName, setmeal.getName());//        queryWrapper.eq(null != setmeal.getCategoryId(), Setmeal::getCategoryId, setmeal.getCategoryId());//        queryWrapper.eq(null != setmeal.getStatus(), Setmeal::getStatus, setmeal.getStatus());//        queryWrapper.orderByDesc(Setmeal::getUpdateTime);////        return R.success(setmealService.list(queryWrapper));//    }    /**     * 根据条件查询套餐数据     *     * @param setmeal     * @return     */    @GetMapping("/list")    public R&lt;List&lt;Setmeal&gt;&gt; list1(@RequestBody Setmeal setmeal) {        LambdaQueryWrapper&lt;Setmeal&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;();        queryWrapper.eq(setmeal.getCategoryId() != null, Setmeal::getCategoryId, setmeal.getCategoryId());        queryWrapper.eq(setmeal.getStatus() != null, Setmeal::getStatus, setmeal.getStatus());        queryWrapper.orderByDesc(Setmeal::getUpdateTime);        List&lt;Setmeal&gt; list = setmealService.list(queryWrapper);        return R.success(list);    }    @PostMapping("/status/{status}")    public R&lt;List&lt;Setmeal&gt;&gt; status(@PathVariable Integer status, @RequestParam List&lt;Long&gt; ids) {        LambdaQueryWrapper&lt;Setmeal&gt; queryWrapper = new LambdaQueryWrapper&lt;&gt;();        queryWrapper.in(Setmeal::getId, ids);        List&lt;Setmeal&gt; list = setmealService.list(queryWrapper);        List&lt;Setmeal&gt; list1 = list.stream().map((item) -&gt; {            item.setStatus(status);            return item;        }).collect(Collectors.toList());        setmealService.updateBatchById(list1);        return R.success(list1);    }}</code></pre><h2 id="6-启动类上加上注解"><a href="#6-启动类上加上注解" class="headerlink" title="6.启动类上加上注解"></a>6.启动类上加上注解</h2><p>主要是@ServletComponentScan这个注解</p><pre><code class="java">import lombok.extern.slf4j.Slf4j;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.web.servlet.ServletComponentScan;import org.springframework.transaction.annotation.EnableTransactionManagement;/** * @author a1002 */@Slf4j@SpringBootApplication@ServletComponentScan@EnableTransactionManagementpublic class YangEatApplication {    public static void main(String[] args) {        SpringApplication.run(YangEatApplication.class, args);        log.info("项目启动成功...");    }}</code></pre><h1 id="三，时间更新全局配置（自定义元数据对象处理器）"><a href="#三，时间更新全局配置（自定义元数据对象处理器）" class="headerlink" title="三，时间更新全局配置（自定义元数据对象处理器）"></a>三，时间更新全局配置（自定义元数据对象处理器）</h1><h2 id="1-数据库相关字段配置"><a href="#1-数据库相关字段配置" class="headerlink" title="1.数据库相关字段配置"></a>1.数据库相关字段配置</h2><p><img src="https://img-blog.csdnimg.cn/b273136714724aeab068e2c6768738a3.png"></p><h2 id="2-实体类配置"><a href="#2-实体类配置" class="headerlink" title="2. 实体类配置"></a>2. 实体类配置</h2><pre><code class="java">package com.blog.pojo;import com.baomidou.mybatisplus.annotation.FieldFill;import com.baomidou.mybatisplus.annotation.IdType;import com.baomidou.mybatisplus.annotation.TableField;import com.baomidou.mybatisplus.annotation.TableId;import lombok.AllArgsConstructor;import lombok.Data;import lombok.EqualsAndHashCode;import lombok.NoArgsConstructor;import lombok.experimental.Accessors;import java.io.Serializable;import java.time.LocalDateTime;/** * @author a1002 */@SuppressWarnings("all")@Data@AllArgsConstructor@NoArgsConstructor@EqualsAndHashCode(callSuper = false)@Accessors(chain = true)public class User implements Serializable {    private static final long serialVersionUID = 1L;    @TableId(value = "id", type = IdType.AUTO)    private Long id;    private String username;    private String password;    /**     * 0是用户     * 1是管理员     */    private Integer status;    private String img;    private String blogPath;    private String grade;    //创建时间    @TableField(fill = FieldFill.INSERT)    private LocalDateTime createTime;    //更新时间    @TableField(fill = FieldFill.INSERT_UPDATE)    private LocalDateTime updateTime;    //创建人    @TableField(fill = FieldFill.INSERT)    private Long createUser;    //修改人    @TableField(fill = FieldFill.INSERT_UPDATE)    private Long updateUser;    public User(String username, String password) {        this.username = username;        this.password = password;    }    public User(Long id, String username, String password, String img, String blogPath, String grade) {        this.id = id;        this.username = username;        this.password = password;        this.img = img;        this.blogPath = blogPath;        this.grade = grade;    }    public User(Long id, String username, String password, String blogPath, String grade) {        this.id = id;        this.username = username;        this.password = password;        this.blogPath = blogPath;        this.grade = grade;    }}</code></pre><p>其中主要是这些字段</p><pre><code class="java">    //创建时间    @TableField(fill = FieldFill.INSERT)    private LocalDateTime createTime;    //更新时间    @TableField(fill = FieldFill.INSERT_UPDATE)    private LocalDateTime updateTime;    //创建人    @TableField(fill = FieldFill.INSERT)    private Long createUser;    //修改人    @TableField(fill = FieldFill.INSERT_UPDATE)    private Long updateUser;</code></pre><p>相关配置：</p><p><img src="https://img-blog.csdnimg.cn/a45646fa69df40ecbce35b32253bcea6.png"></p><p>主要是这三个配置类：</p><pre><code class="java">package com.blog.common;/** * 基于ThreadLocal封装工具类，用户保存和获取当前登录用户id * * @author a1002 */public class BaseContext {    private static ThreadLocal&lt;Long&gt; threadLocal = new ThreadLocal&lt;&gt;();    /**     * 设置值     *     * @param id     */    public static void setCurrentId(Long id) {        threadLocal.set(id);    }    /**     * 获取值     *     * @return     */    public static Long getCurrentId() {        return threadLocal.get();    }}</code></pre><pre><code class="java">package com.blog.common;import com.fasterxml.jackson.databind.DeserializationFeature;import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.module.SimpleModule;import com.fasterxml.jackson.databind.ser.std.ToStringSerializer;import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateDeserializer;import com.fasterxml.jackson.datatype.jsr310.deser.LocalDateTimeDeserializer;import com.fasterxml.jackson.datatype.jsr310.deser.LocalTimeDeserializer;import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateSerializer;import com.fasterxml.jackson.datatype.jsr310.ser.LocalDateTimeSerializer;import com.fasterxml.jackson.datatype.jsr310.ser.LocalTimeSerializer;import java.math.BigInteger;import java.time.LocalDate;import java.time.LocalDateTime;import java.time.LocalTime;import java.time.format.DateTimeFormatter;import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;/** * 对象映射器:基于jackson将Java对象转为json，或者将json转为Java对象 * 将JSON解析为Java对象的过程称为 [从JSON反序列化Java对象] * 从Java对象生成JSON的过程称为 [序列化Java对象到JSON] * * @author a1002 */public class JacksonObjectMapper extends ObjectMapper {    public static final String DEFAULT_DATE_FORMAT = "yyyy-MM-dd";    public static final String DEFAULT_DATE_TIME_FORMAT = "yyyy-MM-dd HH:mm:ss";    public static final String DEFAULT_TIME_FORMAT = "HH:mm:ss";    public JacksonObjectMapper() {        super();        //收到未知属性时不报异常        this.configure(FAIL_ON_UNKNOWN_PROPERTIES, false);        //反序列化时，属性不存在的兼容处理        this.getDeserializationConfig().withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES);        SimpleModule simpleModule = new SimpleModule()                .addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT)))                .addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT)))                .addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT)))                .addSerializer(BigInteger.class, ToStringSerializer.instance)                .addSerializer(Long.class, ToStringSerializer.instance)                .addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT)))                .addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT)))                .addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT)));        //注册功能模块 例如，可以添加自定义序列化器和反序列化器        this.registerModule(simpleModule);    }}</code></pre><pre><code class="java">package com.blog.common;import com.baomidou.mybatisplus.core.handlers.MetaObjectHandler;import lombok.extern.slf4j.Slf4j;import org.apache.ibatis.reflection.MetaObject;import org.springframework.stereotype.Component;import java.time.LocalDateTime;/** * 自定义元数据对象处理器 * * @author a1002 */@Component@Slf4jpublic class MyMetaObjecthandler implements MetaObjectHandler {    /**     * 插入操作，自动填充     *     * @param metaObject     */    @Override    public void insertFill(MetaObject metaObject) {        log.info("公共字段自动填充[insert]...");        log.info(metaObject.toString());        metaObject.setValue("createTime", LocalDateTime.now());        metaObject.setValue("updateTime", LocalDateTime.now());        metaObject.setValue("createUser", BaseContext.getCurrentId());        metaObject.setValue("updateUser", BaseContext.getCurrentId());    }    /**     * 更新操作，自动填充     *     * @param metaObject     */    @Override    public void updateFill(MetaObject metaObject) {        log.info("公共字段自动填充[update]...");        log.info(metaObject.toString());        long id = Thread.currentThread().getId();        log.info("线程id为：{}", id);        metaObject.setValue("updateTime", LocalDateTime.now());        metaObject.setValue("updateUser", BaseContext.getCurrentId());    }}</code></pre><p>GlobalExceptionHandler是针对添加用户时避免用户重复添加的异常处理</p><pre><code class="java">package com.blog.common;import com.blog.utils.R;import lombok.extern.slf4j.Slf4j;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.bind.annotation.RestController;import java.sql.SQLIntegrityConstraintViolationException;/** * 全局异常处理 * * @author a1002 */@ControllerAdvice(annotations = {RestController.class, Controller.class})@ResponseBody@Slf4jpublic class GlobalExceptionHandler {    /**     * 异常处理方法     *     * @return     */    @ExceptionHandler(SQLIntegrityConstraintViolationException.class)    public R&lt;String&gt; exceptionHandler(SQLIntegrityConstraintViolationException ex) {        log.error(ex.getMessage());        if (ex.getMessage().contains("Duplicate entry")) {            String[] split = ex.getMessage().split(" ");            String msg = split[2] + "已存在";            return R.error(msg);        }        return R.error("未知错误");    }//    /**//     * 异常处理方法//     *//     * @return//     *///    @ExceptionHandler(CustomException.class)//    public R&lt;String&gt; exceptionHandler(CustomException ex) {//        log.error(ex.getMessage());////        return R.error(ex.getMessage());//    }}</code></pre><h1 id="四-WebSocket打造在线聊天室"><a href="#四-WebSocket打造在线聊天室" class="headerlink" title="四.WebSocket打造在线聊天室"></a>四.WebSocket打造在线聊天室</h1><p>目录</p><p><img src="https://img-blog.csdnimg.cn/faa39ce75a334bcaadede677c8e90683.png"></p><h2 id="1-导入依赖-2"><a href="#1-导入依赖-2" class="headerlink" title="1.导入依赖"></a>1.导入依赖</h2><pre><code class="java">        &lt;!--websocket--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;            &lt;version&gt;2.7.2&lt;/version&gt;        &lt;/dependency&gt;</code></pre><h2 id="2-配置类"><a href="#2-配置类" class="headerlink" title="2.配置类"></a>2.配置类</h2><pre><code class="java">package com.websockettest.config;import org.springframework.beans.BeansException;import org.springframework.beans.factory.BeanFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import javax.websocket.server.ServerEndpointConfig;/** * @author a1002 */public class MySpringConfigurator extends ServerEndpointConfig.Configurator implements ApplicationContextAware {    private static volatile BeanFactory context;    @Override    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {        MySpringConfigurator.context = applicationContext;    }    @Override    public &lt;T&gt; T getEndpointInstance(Class&lt;T&gt; clazz) throws InstantiationException {        return context.getBean(clazz);    }}</code></pre><pre><code class="java">package com.websockettest.config;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.socket.server.standard.ServerEndpointExporter;/** * @author a1002 */@Configuration@ConditionalOnWebApplicationpublic class WebSocketConfig {    //使用boot内置tomcat时需要注入此bean    @Bean    public ServerEndpointExporter serverEndpointExporter() {        return new ServerEndpointExporter();    }    @Bean    public MySpringConfigurator mySpringConfigurator() {        return new MySpringConfigurator();    }}</code></pre><h2 id="3-工具类"><a href="#3-工具类" class="headerlink" title="3.工具类"></a>3.工具类</h2><pre><code class="java">package com.websockettest.utils;import java.text.SimpleDateFormat;import java.util.Date;/** * @author a1002 */public class DateUtils {    public static String getDate() {        Date date = new Date();        SimpleDateFormat format = new SimpleDateFormat("yyyy-MM-dd hh:mm:ss");        return format.format(date);    }}</code></pre><h2 id="4-controller"><a href="#4-controller" class="headerlink" title="4.controller"></a>4.controller</h2><pre><code class="java">package com.websockettest.controller;import com.websockettest.config.MySpringConfigurator;import com.websockettest.utils.DateUtils;import org.springframework.stereotype.Component;import javax.websocket.*;import javax.websocket.server.ServerEndpoint;import java.util.HashMap;import java.util.Map;/** * @author a1002 * @ServerEndpoint 注解是一个类层次的注解，它的功能主要是将目前的类定义成一个websocket服务器端,注解的值将被用于监听用户连接的终端访问URL地址,客户端可以通过这个URL来连接到WebSocket服务器端 */@ServerEndpoint(value = "/chat/{uid}", configurator = MySpringConfigurator.class)@Componentpublic class WebSocketTest {    private Session session;    private String getUid(Session session) {        this.session = session;        Map parem = session.getPathParameters();        String uid = parem.get("uid").toString();        return uid;    }    /**     * 当前登录人的 session 管理器     */    private static Map&lt;String, Session&gt; sessionMessage = new HashMap&lt;&gt;();    @OnOpen//打开连接执行    public void onOpw(Session session) {        String uid = getUid(session);        sessionMessage.put(uid, session);        System.out.println("[" + uid + "] 进入聊天室");        sendMessage("[" + uid + "]   进入聊天室");    }    @OnMessage//收到消息执行    public void onMessage(String message, Session session) {        String uid = getUid(session);        sendMessage(uid + "  (" + DateUtils.getDate() + ")  说: " + message);    }    @OnClose//关闭连接执行    public void onClose(Session session) {        System.out.println(session.getId() + "关闭连接");    }    @OnError//连接错误的时候执行    public void onError(Throwable error, Session session) {        System.out.println("错误的时候执行");        error.printStackTrace();    }    /**     * 发送消息     *     * @param message     */    public void sendMessage(String message) {        for (String uid : sessionMessage.keySet()) {            try {                sessionMessage.get(uid).getAsyncRemote().sendText(message);            } catch (Exception e) {            }        }    }}</code></pre><h2 id="5-index-html"><a href="#5-index-html" class="headerlink" title="5.index.html"></a>5.index.html</h2><pre><code class="java">&lt;!DOCTYPE html&gt;&lt;html lang="zh"&gt;&lt;head&gt;    &lt;meta charset="UTF-8"&gt;    &lt;title&gt;欢迎来到聊天室&lt;/title&gt;&lt;/head&gt;&lt;body&gt;Welcome&lt;br/&gt; &lt;span id="yhm"&gt;&lt;/span&gt;&lt;div id="div1"&gt;    &lt;input id="account" type="text" placeholder="用户名"/&gt;    &lt;button onclick="init()"&gt;连接聊天室&lt;/button&gt;    &lt;hr/&gt;&lt;/div&gt;&lt;div id="div2" hidden&gt;    &lt;input id="text" type="text"/&gt;    &lt;button onclick="send()"&gt;发送消息&lt;/button&gt;    &lt;hr/&gt;&lt;/div&gt;&lt;div id="message"&gt;&lt;/div&gt;&lt;/body&gt;&lt;script type="text/javascript"&gt;    var websocaket = null;    function init() {        var account = document.getElementById("account").value;        if (account == '') {            setdivInnerHTML("没有输入UID");            return false;        }        if ('WebSocket' in window) {            websocaket = new WebSocket("ws://110.40.210.213:8848/chat/" + account);//用于创建 WebSocket 对象。WebSocketTest对应的是java类的注解值        } else {            setdivInnerHTML("当前浏览器不支持");        }        //连接发生错误的时候回调方法；        websocaket.onerror = function () {            setdivInnerHTML("连接错误");        }        //连接成功时建立回调方法；        websocaket.onopen = function () {            document.getElementById("div2").hidden = false;            document.getElementById("div1").hidden = true;            document.getElementById("yhm").text(account);            setdivInnerHTML("连接成功");        }        //收到消息的回调方法        websocaket.onmessage = function (msg) {            setdivInnerHTML(msg.data);        }        //连接关闭的回调方法        websocaket.onclose = function () {            setdivInnerHTML("关闭成功");        }    }    //关闭websocket    //    function closea() {        websocaket.close();        alert("点击关闭");    }    function setdivInnerHTML(innerHTML) {        document.getElementById('message').innerHTML += innerHTML + '&lt;br/&gt;';    }    function send() {        var message = document.getElementById('text').value;        websocaket.send(message);//给后台发送数据    }&lt;/script&gt;&lt;/html&gt;</code></pre>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mybatis java 数据库 WebSocket 元数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式文件存储系统minio</title>
      <link href="/2022/11/23/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9Fminio/"/>
      <url>/2022/11/23/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9Fminio/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>结构化数据：也称作行数据，是由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。</p><p>特点：高度组织化和格式化，可以用二维表结构来逻辑表达和实现的数据。</p><p>存储形式：关系型数据库</p><p>非结构化数据：非结构化数据是数据结构不规则或不完整，没有预定义的数据模型，不方便用数据库二维逻辑表来表现的数据。包括所有格式的办公文档、文本、图片, HTML、各类报表、图像和音频/视频信息等等。</p><p>特点：格式多样，标准多样。</p><p>形式：文本，图像，图形，音频，视频等。</p><p>存储形式：非关系型数据库。</p><p>半结构化数据：是结构化的数据，但是结构变化很大。因为我们要了解数据的细节所以不能将数据简单的组织成一个文件按照非结构化数据处理，由于结构变化很大也不能够简单的建立一个表和他对应。</p><p>而minio是对应于互联网海量非结构化数据的存储要求</p><p>官网：</p><p>&nbsp; &nbsp; &nbsp; &nbsp; 英文网站：<a href="https://min.io/docs/minio/linux/developers/javascript/API.html#removeObject" title="JavaScript Client API Reference — MinIO Object Storage for Linux">JavaScript Client API Reference — MinIO Object Storage for Linux</a></p><p>&nbsp; &nbsp; &nbsp; &nbsp; 中文网站：<a href="https://www.minio.org.cn/" title="MinIO | 高性能，对Kubernetes友好的对象存储">MinIO | 高性能，对Kubernetes友好的对象存储</a></p><p>推荐英文网站，中文网站更新较慢。</p><p><strong>MinIO 是一个基于Apache License v2.0开源协议的对象存储服务。它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。</strong></p><p><strong>MinIO是一个非常轻量的服务,可以很简单的和其他应用的结合，类似 NodeJS, Redis 或 MySQL。</strong></p><p>使用文档：<a href="https://www.minio.org.cn/" title="MinIO | 高性能，对Kubernetes友好的对象存储">MinIO | 高性能，对Kubernetes友好的对象存储</a></p><h2 id="minio的安装与部署："><a href="#minio的安装与部署：" class="headerlink" title="minio的安装与部署："></a><strong>minio的安装与部署</strong>：</h2><p>无奈，看其他博客遇到好多坑，记录一下自己的安装过程。</p><p>1.连接服务器</p><pre><code>ssh -q -l root -p 22 ip地址</code></pre><p>2.进入home目录，新建一个minio目录</p><pre><code>cd /home</code></pre><pre><code>mkdir minio</code></pre><p>3.进入minio目录下，安装minio</p><pre><code>cd /home/minio</code></pre><pre><code>wget https://dl.min.io/server/minio/release/linux-amd64/minio</code></pre><p>这个是在外网下载，下载的很慢，笔者踩了很多坑，下载了很多次，整了好长时间。。。然后再继续，能fq的孩子还是建议去fq，把minio的二进制文件下载下来，再上传到服务器上去。</p><p><img src="https://img-blog.csdnimg.cn/3f017ab7096f4d8dbbeb7bc5e1d4766f.png"><img src="https://img-blog.csdnimg.cn/3f017ab7096f4d8dbbeb7bc5e1d4766f.png"><img src="https://img-blog.csdnimg.cn/3f017ab7096f4d8dbbeb7bc5e1d4766f.png"><img src="https://img-blog.csdnimg.cn/3f017ab7096f4d8dbbeb7bc5e1d4766f.png"></p><p>笔者在自己电脑终端整的，还是一如既往的，别人用几行命令丝滑的整好了，我的却一直报错。。。</p><p><img src="https://img-blog.csdnimg.cn/3f017ab7096f4d8dbbeb7bc5e1d4766f.png"><img src="https://img-blog.csdnimg.cn/3f017ab7096f4d8dbbeb7bc5e1d4766f.png"><img src="https://img-blog.csdnimg.cn/3f017ab7096f4d8dbbeb7bc5e1d4766f.png"><img src="https://img-blog.csdnimg.cn/3f017ab7096f4d8dbbeb7bc5e1d4766f.png"></p><p>好像真的是我电脑系统的原因，各种命令都没用。。。</p><p>最后的最后在学长的帮助下，俺也有较为稳定的minio啦。</p><p>然后又用了一上午的时间完成springboot对minio的整合，完成了各种方法在swagger上的实现，也成功部署到了数据库上，成功实现的方法有查看桶内某个文件，下载文件，批量删除文件，查看桶内所有文件等等。</p><p>原本想通过看视频整合的，但是看的那些视频嗯。。。怎么说，逻辑不清，各种问题。。。</p><p>于是就只能一边看官方文档，一边参考其他博客，终于把minio完成了。</p><p>当然还是推荐看英文版的minio<a href="https://min.io/docs/minio/linux/developers/javascript/API.html#removeObject" title="JavaScript Client API Reference — MinIO Object Storage for Linux">JavaScript Client API Reference — MinIO Object Storage for Linux</a></p><p>中文版的版本太低，有较多坑。</p><p>总结：最近一段时间跟闹着玩一样，事情太多了，还好完成了minio，又用了一点时间把minio部署到两个项目上，自己在两个项目上的任务也算完成了，也算是清闲了一点，不过还有期末考试等着自己。。。同时也要开始学习cloud了，在cloud上我和其他孩子进度落下太多了，已经有孩子开始二刷了，我还停留在几个月前，才学一小半，现在也要开始把进度赶上去了，以免那个项目不知道老师什么时候安排下去，自己还没学，就非常难受了。</p><p>唉，最近太难了。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 minio java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅聊一下Nginx</title>
      <link href="/2022/11/11/%E6%B5%85%E8%81%8A%E4%B8%80%E4%B8%8BNginx/"/>
      <url>/2022/11/11/%E6%B5%85%E8%81%8A%E4%B8%80%E4%B8%8BNginx/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>目录</strong></p><p><a href="#Nginx%E7%9A%84%E4%B8%8B%E8%BD%BD%E4%B8%8E%E5%AE%89%E8%A3%85">Nginx的下载与安装</a></p><p><a href="#%E5%8E%BBNginx%E5%AE%98%E7%BD%91%E5%AE%89%E8%A3%85%EF%BC%9Anginx%20news">去Nginx官网安装：nginx news</a></p><p><a href="#%E7%9B%B4%E6%8E%A5%E8%BF%9B%E5%85%A5%E4%B8%8B%E8%BD%BD%E9%A1%B5%E9%9D%A2%E8%BF%9B%E8%A1%8C%E5%AE%89%E8%A3%85">直接进入下载页面进行安装</a></p><p><a href="#%E7%9B%B4%E6%8E%A5%E5%AE%89%E8%A3%85%EF%BC%9A">直接安装：</a></p><p><a href="#%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E5%AF%B9nginx%E7%9A%84%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B">在服务器上使用命令对nginx的安装过程</a></p><p><a href="#Nginx%E5%91%BD%E4%BB%A4">Nginx命令</a></p><p><a href="#Nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84">Nginx配置文件结构</a></p><p><a href="#Nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%EF%BC%88conf/nginx.conf%EF%BC%89%E6%AD%A3%E9%A2%98%E5%88%86%E4%B8%BA%E4%B8%89%E4%B8%AA%E9%83%A8%E5%88%86%EF%BC%9A">Nginx配置文件（conf/nginx.conf）正题分为三个部分：</a></p><p><a href="#Nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%EF%BC%88%E6%9C%89%E8%A7%A3%E6%9E%90%EF%BC%89%EF%BC%9A">Nginx配置文件（有解析）：</a></p><p><a href="#Nginx%E5%85%B7%E4%BD%93%E5%BA%94%E7%94%A8">Nginx具体应用</a></p><hr><h1 id="Nginx的下载与安装"><a href="#Nginx的下载与安装" class="headerlink" title="Nginx的下载与安装"></a>Nginx的下载与安装</h1><h3 id="去Nginx官网安装：nginx-news"><a href="#去Nginx官网安装：nginx-news" class="headerlink" title="去Nginx官网安装：nginx news"></a>去Nginx官网安装：<a href="https://nginx.org/" title="nginx news">nginx news</a></h3><p><img src="https://img-blog.csdnimg.cn/f4d6942f6fed40f19eba02d956e69bcc.png">&nbsp;点击download</p><p>进入到这个页面&nbsp;也就是：</p><p><img src="https://img-blog.csdnimg.cn/1c406e6851834214b8ef3b9e636e32a2.png"></p><h3 id="直接进入下载页面进行安装"><a href="#直接进入下载页面进行安装" class="headerlink" title="直接进入下载页面进行安装"></a>直接进入下载页面进行安装</h3><p><a href="https://nginx.org/en/download.html" title="&nbsp; &nbsp;&nbsp;​​​​​​​nginx: download">&nbsp; &nbsp;&nbsp;nginx: download</a></p><h3 id="直接安装："><a href="#直接安装：" class="headerlink" title="直接安装："></a>直接安装：</h3><p>以1.16.1版本为例：</p><p><a href="https://nginx.org/download/nginx-1.16.1.tar.gz">https://nginx.org/download/nginx-1.16.1.tar.gz</a></p><h3 id="在服务器上使用命令对nginx的安装过程"><a href="#在服务器上使用命令对nginx的安装过程" class="headerlink" title="在服务器上使用命令对nginx的安装过程"></a>在服务器上使用命令对nginx的安装过程</h3><p>1.安装依赖包</p><pre><code>yum -y install gcc pcre-devel zlib-devel openssl openssl-devel</code></pre><p>1.下载Nginx安装包</p><pre><code>wget https://nginx.org/download/nginx-1.16.1.tar.gz</code></pre><p>&nbsp;3.解压</p><pre><code>tar -zxvf nginx-1.16.1.tar.gz</code></pre><ol start="4"><li></li></ol><pre><code>cd nginx-1.16.1</code></pre><ol start="5"><li></li></ol><pre><code>./configure --prefix=/usr/local/nginx</code></pre><ol start="6"><li></li></ol><pre><code>make &amp;&amp; make install</code></pre><p>Nginx目录结构</p><p><img src="https://img-blog.csdnimg.cn/9565436ab6384e22a1390b3b6fc2db32.png"></p><p><img src="https://img-blog.csdnimg.cn/c06e209a076b46ecae527e7f93d5b162.png">&nbsp;重点目录/文件：</p><ul><li>conf/nginx.conf&nbsp; &nbsp;nginx配置文件</li><li>html&nbsp; &nbsp; 存放静态文件（html,css,js等）</li><li>logs&nbsp; 日志目录，存放日志文件</li><li>sbin/nginx&nbsp; &nbsp;二进制文件，用于启动，停止ngnix服务</li></ul><p><strong>在目录下展示树的结构</strong></p><p><strong>需要先安装</strong></p><pre><code>yum install tree</code></pre><p><img src="https://img-blog.csdnimg.cn/526a0f3493f544adab6610585b718b20.png">**&nbsp;展示效果：**</p><p><img src="https://img-blog.csdnimg.cn/895700da33c6455d9ce42a88d76495da.png"></p><h1 id="Nginx命令"><a href="#Nginx命令" class="headerlink" title="Nginx命令"></a>Nginx命令</h1><p>&nbsp;<strong>查看版本(这个需要进入nginx目录下sbin下才可以执行)：</strong></p><pre><code>./nginx -v</code></pre><p><img src="https://img-blog.csdnimg.cn/2913c96fa7bc43a1b93248dfb7d6a8c6.png"></p><p><strong>换一个命令：</strong></p><pre><code>nginx -version</code></pre><p>&nbsp;<img src="https://img-blog.csdnimg.cn/809058cf2e7f491da69ba213d79188da.png"></p><p>有一点哇，不要在字目录文件特别多的目录下执行tree命令哇，笔者执行了一下，呜呜呜呜。</p><p><img src="https://img-blog.csdnimg.cn/b02d25991d47480b8cda0c60f0ad1bba.png"></p><p>**&nbsp;进入你的nginx的sbin目录下**</p><p><img src="https://img-blog.csdnimg.cn/4e29bff1a5c7400fb609ee732c066257.png"></p><pre><code>./nginx -v</code></pre><p><strong>检查配置文件正确性</strong></p><p><strong>在启动nginx服务之前，可以先检查一下conf/nginx.conf文件配置的是否有误，命令如下</strong></p><pre><code>./nginx -t</code></pre><p><strong>启动nginx服务</strong></p><pre><code>./nginx</code></pre><p><strong>停止nginx服务</strong></p><pre><code>./nginx -s stop</code></pre><p>**启动完成后可以查看ngnix进程&nbsp;**</p><pre><code>ps ef|grep nginx</code></pre><p><strong>查看进程pid</strong></p><p><img src="https://img-blog.csdnimg.cn/95ca74a47efd49f7aa51811a1d62edf5.png"></p><pre><code>cat nginx.pid</code></pre><p><strong>当修改Nginx配置文件后，需要重新加载才能生效，可以使用下面命令重新加载配置文件</strong></p><pre><code>./nginx -s reload</code></pre><h1 id="Nginx配置文件结构"><a href="#Nginx配置文件结构" class="headerlink" title="Nginx配置文件结构"></a>Nginx配置文件结构</h1><h2 id="Nginx配置文件（conf-nginx-conf）正题分为三个部分："><a href="#Nginx配置文件（conf-nginx-conf）正题分为三个部分：" class="headerlink" title="Nginx配置文件（conf/nginx.conf）正题分为三个部分："></a>Nginx配置文件（conf/nginx.conf）正题分为三个部分：</h2><ul><li>全局块&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 和Nginx运行相关的全局配置</li><li>events块&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;和网络连接相关的配置</li><li>http块&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 代理，缓存，日志记录，虚拟主机配置</li></ul><h2 id="Nginx配置文件（有解析）："><a href="#Nginx配置文件（有解析）：" class="headerlink" title="Nginx配置文件（有解析）："></a>Nginx配置文件（有解析）：</h2><pre><code>#全局块user  www www;worker_processes auto;error_log  /www/wwwlogs/nginx_error.log  crit;pid        /www/server/nginx/logs/nginx.pid;worker_rlimit_nofile 51200;#events块events    {        use epoll;        worker_connections 51200;        multi_accept on;    }#http块（主要配置http块）http    {        #http全局块        include       mime.types;        #include luawaf.conf;        include proxy.conf;        default_type  application/octet-stream;        server_names_hash_bucket_size 512;        client_header_buffer_size 32k;        large_client_header_buffers 4 32k;        client_max_body_size 50m;        sendfile   on;        tcp_nopush on;        keepalive_timeout 60;        tcp_nodelay on;        fastcgi_connect_timeout 300;        fastcgi_send_timeout 300;        fastcgi_read_timeout 300;        fastcgi_buffer_size 64k;        fastcgi_buffers 4 64k;        fastcgi_busy_buffers_size 128k;        fastcgi_temp_file_write_size 256k;        fastcgi_intercept_errors on;        gzip on;        gzip_min_length  1k;        gzip_buffers     4 16k;        gzip_http_version 1.1;        gzip_comp_level 2;        gzip_types     text/plain application/javascript application/x-javascript text/javascript text/css application/xml;        gzip_vary on;        gzip_proxied   expired no-cache no-store private auth;        gzip_disable   "MSIE [1-6]\.";        limit_conn_zone $binary_remote_addr zone=perip:10m;        limit_conn_zone $server_name zone=perserver:10m;        server_tokens off;        access_log off;#http中的server块server    {        #server全局块        #监听端口        listen 888;        #域名 没有域名的话就填localhost         server_name phpmyadmin;        index index.html index.htm index.php;        root  /www/server/phpmyadmin;            location ~ /tmp/ {                return 403;            }        #error_page   404   /404.html;        include enable-php.conf;        #location块        location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$        {            expires      30d;        }        location ~ .*\.(js|css)?$        {            expires      12h;        }        location ~ /\.        {            deny all;        }        access_log  /www/wwwlogs/access.log;    }include /www/server/panel/vhost/nginx/*.conf;}</code></pre><h2 id="Nginx具体应用"><a href="#Nginx具体应用" class="headerlink" title="Nginx具体应用"></a>Nginx具体应用</h2><p>●<strong>正向代理</strong><br>是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容,客户端向代理发送一个请求并指定目标(原始服务器),然后代理向原始服务器转交请求并将获得的内容返回给客户端。<br>正向代理的典型用途是为在防火墙内的局域网客户端提供访问Internet的途径。<br>正向代理一般是在客户端设置代理服务器，通过代理服务器转发请求，最终访问到目标服务器。</p><p>●<strong>反向代理</strong><br>反向代理服务器位于用户与目标服务器之间，但是对于用户而言，反向代理服务器就相当于目标服务器，即用户直接访问反向代理服务器就可以获得目标服务器的资源，反向代理服务器负责将请求转发给目标服务器。<br>用户不需要知道目标服务器的地址,也无须在用户端作任何设定。</p><p>正向代理和反向代理的区别：</p><p>正向代理是设置在客户端的，并且客户端也知道代理服务器的存在，反向代理是用户直接访问代理服务器，反向代理服务器转发请求从目标服务器获取资源返回给用户，客户端并不知道反向代理服务器的存在，</p><p>配置反向代理：</p><pre><code>    server {        listen 888;        server_name localhost;        location / {            proxy_pass http://XXX.XX.XXX.XXX:8080;   #反向代理配置，将请求转发到指定服务        }    }</code></pre><p><strong>负载均衡</strong></p><p>早期的网站流量和业务功能都比较简单，单台服务器就可以满足基本需求，但是随着互联网的发展，业务流量越来越大并且业务逻辑也越来越复杂，单台服务器的性能及单点故障问题就凸显出来了，因此需要多台服务器组成应用集群，进行性能的水平扩展以及避免单点故障出现。</p><ul><li>应用集群:将同一应用部署到多台机器上，组成应用集群，接收负载均衡器分发的请求，进行业务处理并返回响应数据。</li><li>负载均衡器:将用户请求根据对应的负载均衡算法分发到应用集群中的一台服务器进行处理。</li></ul><p>负载均衡也是基于反向代理功能实现的，只是它后面是多台服务器，根据算法将用户请求分发到其中一台服务器中</p><p>配置负载均衡</p><pre><code>    upstream targetserver{        server 192.168.123.122:8080;        server 192.168.324.122:8989;    }    server {        listen  8080;        server_name localhost;        location / {            proxy_pass http://targetserver;        }    }</code></pre><p>请求8080端口，请求就会被分发到两台服务器中的一台中去。</p><p>在被分发的服务器ip地址后加上weight=多少；代表着权重，即此服务器会被分发到的几率。</p><p><strong>负载均衡策略：</strong></p><p>轮询&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 默认方式</p><p>weight&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;权重方式</p><p>ip_hash&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;依据ip分配方式</p><p>least_conn&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;依据最少连接方式</p><p>url_hash&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;依据url分配方式</p><p>fair&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 依据响应时间方式</p><p>推荐博客：<a href="https://blog.csdn.net/weixin_47272508/article/details/125933279" title="瑞吉外卖笔记——第09讲Nginx_萧篱衣的博客-CSDN博客">瑞吉外卖笔记——第09讲Nginx_萧篱衣的博客-CSDN博客</a></p><p>参考：<a href="https://www.bilibili.com/video/BV13a411q753/?is_story_h5=false&amp;p=184&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=decbf72f-d1d2-457f-a198-6132e22ecc91&amp;share_source=COPY&amp;share_tag=s_i&amp;timestamp=1667806475&amp;unique_k=zmxN8DE" title="项目优化Day3-01-本章内容介绍_哔哩哔哩_bilibili">项目优化Day3-01-本章内容介绍_哔哩哔哩_bilibili</a></p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nginx 运维 服务器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis的redis.config文件配置与内容+10.30日之前的总结</title>
      <link href="/2022/10/30/redis%E7%9A%84redis.config%E6%96%87%E4%BB%B6%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%86%85%E5%AE%B9+10.30%E6%97%A5%E4%B9%8B%E5%89%8D%E7%9A%84%E6%80%BB%E7%BB%93/"/>
      <url>/2022/10/30/redis%E7%9A%84redis.config%E6%96%87%E4%BB%B6%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%86%85%E5%AE%B9+10.30%E6%97%A5%E4%B9%8B%E5%89%8D%E7%9A%84%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>参考博客：<a href="https://blog.csdn.net/Hubery_sky/article/details/125345068?spm=1001.2014.3001.5501" title="redis.conf的一些配置+密码的设置（mac）+个人总结_雾喔的博客-CSDN博客_redis密码配置文件">redis.conf的一些配置+密码的设置（mac）+个人总结_雾喔的博客-CSDN博客_redis密码配置文件</a></p><p>这个是初始的redis.config的内容</p><pre><code># Redis configuration file example.requirepass 956766maxclients 10000## Note that in order to read the configuration file, Redis must be# started with the file path as first argument:## ./redis-server /path/to/redis.conf# Note on units: when memory size is needed, it is possible to specify# it in the usual form of 1k 5GB 4M and so forth:## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## units are case insensitive so 1GB 1Gb 1gB are all the same.################################## INCLUDES #################################### Include one or more other config files here.  This is useful if you# have a standard template that goes to all Redis servers but also need# to customize a few per-server settings.  Include files can include# other files, so use this wisely.## Notice option "include" won't be rewritten by command "CONFIG REWRITE"# from admin or Redis Sentinel. Since Redis always uses the last processed# line as value of a configuration directive, you'd better put includes# at the beginning of this file to avoid overwriting config change at runtime.## If instead you are interested in using includes to override configuration# options, it is better to use include as the last line.## include /path/to/local.conf# include /path/to/other.conf################################## MODULES ###################################### Load modules at startup. If the server is not able to load modules# it will abort. It is possible to use multiple loadmodule directives.## loadmodule /path/to/my_module.so# loadmodule /path/to/other_module.so################################## NETWORK ###################################### By default, if no "bind" configuration directive is specified, Redis listens# for connections from all the network interfaces available on the server.# It is possible to listen to just one or multiple selected interfaces using# the "bind" configuration directive, followed by one or more IP addresses.## Examples:## bind 192.168.1.100 10.0.0.1# bind 127.0.0.1 ::1## ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the# internet, binding to all the interfaces is dangerous and will expose the# instance to everybody on the internet. So by default we uncomment the# following bind directive, that will force Redis to listen only into# the IPv4 loopback interface address (this means Redis will be able to# accept connections only from clients running into the same computer it# is running).## IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES# JUST COMMENT THE FOLLOWING LINE.# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~bind 127.0.0.1# Protected mode is a layer of security protection, in order to avoid that# Redis instances left open on the internet are accessed and exploited.## When protected mode is on and if:## 1) The server is not binding explicitly to a set of addresses using the#    "bind" directive.# 2) No password is configured.## The server only accepts connections from clients connecting from the# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain# sockets.## By default protected mode is enabled. You should disable it only if# you are sure you want clients from other hosts to connect to Redis# even if no authentication is configured, nor a specific set of interfaces# are explicitly listed using the "bind" directive.protected-mode yes# Accept connections on the specified port, default is 6379 (IANA #815344).# If port 0 is specified Redis will not listen on a TCP socket.port 6379# TCP listen() backlog.## In high requests-per-second environments you need an high backlog in order# to avoid slow clients connections issues. Note that the Linux kernel# will silently truncate it to the value of /proc/sys/net/core/somaxconn so# make sure to raise both the value of somaxconn and tcp_max_syn_backlog# in order to get the desired effect.tcp-backlog 511# Unix socket.## Specify the path for the Unix socket that will be used to listen for# incoming connections. There is no default, so Redis will not listen# on a unix socket when not specified.## unixsocket /tmp/redis.sock# unixsocketperm 700# Close the connection after a client is idle for N seconds (0 to disable)timeout 0# TCP keepalive.## If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence# of communication. This is useful for two reasons:## 1) Detect dead peers.# 2) Take the connection alive from the point of view of network#    equipment in the middle.## On Linux, the specified value (in seconds) is the period used to send ACKs.# Note that to close the connection the double of the time is needed.# On other kernels the period depends on the kernel configuration.## A reasonable value for this option is 300 seconds, which is the new# Redis default starting with Redis 3.2.1.tcp-keepalive 300################################# GENERAL ###################################### By default Redis does not run as a daemon. Use 'yes' if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.daemonize yes # If you run Redis from upstart or systemd, Redis can interact with your# supervision tree. Options:#   supervised no      - no supervision interaction#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET#   supervised auto    - detect upstart or systemd method based on#                        UPSTART_JOB or NOTIFY_SOCKET environment variables# Note: these supervision methods only signal "process is ready."#       They do not enable continuous liveness pings back to your supervisor.supervised no# If a pid file is specified, Redis writes it where specified at startup# and removes it at exit.## When the server runs non daemonized, no pid file is created if none is# specified in the configuration. When the server is daemonized, the pid file# is used even if not specified, defaulting to "/var/run/redis.pid".## Creating a pid file is best effort: if Redis is not able to create it# nothing bad happens, the server will start and run normally.pidfile /www/server/redis/redis.pid # Specify the server verbosity level.# This can be one of:# debug (a lot of information, useful for development/testing)# verbose (many rarely useful info, but not a mess like the debug level)# notice (moderately verbose, what you want in production probably)# warning (only very important / critical messages are logged)loglevel notice# Specify the log file name. Also the empty string can be used to force# Redis to log on the standard output. Note that if you use standard# output for logging but daemonize, logs will be sent to /dev/nulllogfile "/www/server/redis/redis.log"# To enable logging to the system logger, just set 'syslog-enabled' to yes,# and optionally update the other syslog parameters to suit your needs.# syslog-enabled no# Specify the syslog identity.# syslog-ident redis# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.# syslog-facility local0# Set the number of databases. The default database is DB 0, you can select# a different one on a per-connection basis using SELECT &lt;dbid&gt; where# dbid is a number between 0 and 'databases'-1databases 16# By default Redis shows an ASCII art logo only when started to log to the# standard output and if the standard output is a TTY. Basically this means# that normally a logo is displayed only in interactive sessions.## However it is possible to force the pre-4.0 behavior and always show a# ASCII art logo in startup logs by setting the following option to yes.always-show-logo yes################################ SNAPSHOTTING  ################################## Save the DB on disk:##   save &lt;seconds&gt; &lt;changes&gt;##   Will save the DB if both the given number of seconds and the given#   number of write operations against the DB occurred.##   In the example below the behaviour will be to save:#   after 900 sec (15 min) if at least 1 key changed#   after 300 sec (5 min) if at least 10 keys changed#   after 60 sec if at least 10000 keys changed##   Note: you can disable saving completely by commenting out all "save" lines.##   It is also possible to remove all the previously configured save#   points by adding a save directive with a single empty string argument#   like in the following example:##   save ""save 900 1save 300 10save 60 10000# By default Redis will stop accepting writes if RDB snapshots are enabled# (at least one save point) and the latest background save failed.# This will make the user aware (in a hard way) that data is not persisting# on disk properly, otherwise chances are that no one will notice and some# disaster will happen.## If the background saving process will start working again Redis will# automatically allow writes again.## However if you have setup your proper monitoring of the Redis server# and persistence, you may want to disable this feature so that Redis will# continue to work as usual even if there are problems with disk,# permissions, and so forth.stop-writes-on-bgsave-error yes# Compress string objects using LZF when dump .rdb databases?# For default that's set to 'yes' as it's almost always a win.# If you want to save some CPU in the saving child set it to 'no' but# the dataset will likely be bigger if you have compressible values or keys.rdbcompression yes# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.# This makes the format more resistant to corruption but there is a performance# hit to pay (around 10%) when saving and loading RDB files, so you can disable it# for maximum performances.## RDB files created with checksum disabled have a checksum of zero that will# tell the loading code to skip the check.rdbchecksum yes# The filename where to dump the DBdbfilename dump.rdb# The working directory.## The DB will be written inside this directory, with the filename specified# above using the 'dbfilename' configuration directive.## The Append Only File will also be created inside this directory.## Note that you must specify a directory here, not a file name.dir /www/server/redis/################################# REPLICATION ################################## Master-Replica replication. Use replicaof to make a Redis instance a copy of# another Redis server. A few things to understand ASAP about Redis replication.##   +------------------+      +---------------+#   |      Master      | ---&gt; |    Replica    |#   | (receive writes) |      |  (exact copy) |#   +------------------+      +---------------+## 1) Redis replication is asynchronous, but you can configure a master to#    stop accepting writes if it appears to be not connected with at least#    a given number of replicas.# 2) Redis replicas are able to perform a partial resynchronization with the#    master if the replication link is lost for a relatively small amount of#    time. You may want to configure the replication backlog size (see the next#    sections of this file) with a sensible value depending on your needs.# 3) Replication is automatic and does not need user intervention. After a#    network partition replicas automatically try to reconnect to masters#    and resynchronize with them.## replicaof &lt;masterip&gt; &lt;masterport&gt;# If the master is password protected (using the "requirepass" configuration# directive below) it is possible to tell the replica to authenticate before# starting the replication synchronization process, otherwise the master will# refuse the replica request.## masterauth &lt;master-password&gt;# When a replica loses its connection with the master, or when the replication# is still in progress, the replica can act in two different ways:## 1) if replica-serve-stale-data is set to 'yes' (the default) the replica will#    still reply to client requests, possibly with out of date data, or the#    data set may just be empty if this is the first synchronization.## 2) if replica-serve-stale-data is set to 'no' the replica will reply with#    an error "SYNC with master in progress" to all the kind of commands#    but to INFO, replicaOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG,#    SUBSCRIBE, UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB,#    COMMAND, POST, HOST: and LATENCY.#replica-serve-stale-data yes# You can configure a replica instance to accept writes or not. Writing against# a replica instance may be useful to store some ephemeral data (because data# written on a replica will be easily deleted after resync with the master) but# may also cause problems if clients are writing to it because of a# misconfiguration.## Since Redis 2.6 by default replicas are read-only.## Note: read only replicas are not designed to be exposed to untrusted clients# on the internet. It's just a protection layer against misuse of the instance.# Still a read only replica exports by default all the administrative commands# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve# security of read only replicas using 'rename-command' to shadow all the# administrative / dangerous commands.replica-read-only yes# Replication SYNC strategy: disk or socket.## -------------------------------------------------------# WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY# -------------------------------------------------------## New replicas and reconnecting replicas that are not able to continue the replication# process just receiving differences, need to do what is called a "full# synchronization". An RDB file is transmitted from the master to the replicas.# The transmission can happen in two different ways:## 1) Disk-backed: The Redis master creates a new process that writes the RDB#                 file on disk. Later the file is transferred by the parent#                 process to the replicas incrementally.# 2) Diskless: The Redis master creates a new process that directly writes the#              RDB file to replica sockets, without touching the disk at all.## With disk-backed replication, while the RDB file is generated, more replicas# can be queued and served with the RDB file as soon as the current child producing# the RDB file finishes its work. With diskless replication instead once# the transfer starts, new replicas arriving will be queued and a new transfer# will start when the current one terminates.## When diskless replication is used, the master waits a configurable amount of# time (in seconds) before starting the transfer in the hope that multiple replicas# will arrive and the transfer can be parallelized.## With slow disks and fast (large bandwidth) networks, diskless replication# works better.repl-diskless-sync no# When diskless replication is enabled, it is possible to configure the delay# the server waits in order to spawn the child that transfers the RDB via socket# to the replicas.## This is important since once the transfer starts, it is not possible to serve# new replicas arriving, that will be queued for the next RDB transfer, so the server# waits a delay in order to let more replicas arrive.## The delay is specified in seconds, and by default is 5 seconds. To disable# it entirely just set it to 0 seconds and the transfer will start ASAP.repl-diskless-sync-delay 5# Replicas send PINGs to server in a predefined interval. It's possible to change# this interval with the repl_ping_replica_period option. The default value is 10# seconds.## repl-ping-replica-period 10# The following option sets the replication timeout for:## 1) Bulk transfer I/O during SYNC, from the point of view of replica.# 2) Master timeout from the point of view of replicas (data, pings).# 3) Replica timeout from the point of view of masters (REPLCONF ACK pings).## It is important to make sure that this value is greater than the value# specified for repl-ping-replica-period otherwise a timeout will be detected# every time there is low traffic between the master and the replica.## repl-timeout 60# Disable TCP_NODELAY on the replica socket after SYNC?## If you select "yes" Redis will use a smaller number of TCP packets and# less bandwidth to send data to replicas. But this can add a delay for# the data to appear on the replica side, up to 40 milliseconds with# Linux kernels using a default configuration.## If you select "no" the delay for data to appear on the replica side will# be reduced but more bandwidth will be used for replication.## By default we optimize for low latency, but in very high traffic conditions# or when the master and replicas are many hops away, turning this to "yes" may# be a good idea.repl-disable-tcp-nodelay no# Set the replication backlog size. The backlog is a buffer that accumulates# replica data when replicas are disconnected for some time, so that when a replica# wants to reconnect again, often a full resync is not needed, but a partial# resync is enough, just passing the portion of data the replica missed while# disconnected.## The bigger the replication backlog, the longer the time the replica can be# disconnected and later be able to perform a partial resynchronization.## The backlog is only allocated once there is at least a replica connected.## repl-backlog-size 1mb# After a master has no longer connected replicas for some time, the backlog# will be freed. The following option configures the amount of seconds that# need to elapse, starting from the time the last replica disconnected, for# the backlog buffer to be freed.## Note that replicas never free the backlog for timeout, since they may be# promoted to masters later, and should be able to correctly "partially# resynchronize" with the replicas: hence they should always accumulate backlog.## A value of 0 means to never release the backlog.## repl-backlog-ttl 3600# The replica priority is an integer number published by Redis in the INFO output.# It is used by Redis Sentinel in order to select a replica to promote into a# master if the master is no longer working correctly.## A replica with a low priority number is considered better for promotion, so# for instance if there are three replicas with priority 10, 100, 25 Sentinel will# pick the one with priority 10, that is the lowest.## However a special priority of 0 marks the replica as not able to perform the# role of master, so a replica with priority of 0 will never be selected by# Redis Sentinel for promotion.## By default the priority is 100.replica-priority 100# It is possible for a master to stop accepting writes if there are less than# N replicas connected, having a lag less or equal than M seconds.## The N replicas need to be in "online" state.## The lag in seconds, that must be &lt;= the specified value, is calculated from# the last ping received from the replica, that is usually sent every second.## This option does not GUARANTEE that N replicas will accept the write, but# will limit the window of exposure for lost writes in case not enough replicas# are available, to the specified number of seconds.## For example to require at least 3 replicas with a lag &lt;= 10 seconds use:## min-replicas-to-write 3# min-replicas-max-lag 10## Setting one or the other to 0 disables the feature.## By default min-replicas-to-write is set to 0 (feature disabled) and# min-replicas-max-lag is set to 10.# A Redis master is able to list the address and port of the attached# replicas in different ways. For example the "INFO replication" section# offers this information, which is used, among other tools, by# Redis Sentinel in order to discover replica instances.# Another place where this info is available is in the output of the# "ROLE" command of a master.## The listed IP and address normally reported by a replica is obtained# in the following way:##   IP: The address is auto detected by checking the peer address#   of the socket used by the replica to connect with the master.##   Port: The port is communicated by the replica during the replication#   handshake, and is normally the port that the replica is using to#   listen for connections.## However when port forwarding or Network Address Translation (NAT) is# used, the replica may be actually reachable via different IP and port# pairs. The following two options can be used by a replica in order to# report to its master a specific set of IP and port, so that both INFO# and ROLE will report those values.## There is no need to use both the options if you need to override just# the port or the IP address.## replica-announce-ip 5.5.5.5# replica-announce-port 1234################################## SECURITY #################################### Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other# commands.  This might be useful in environments in which you do not trust# others with access to the host running redis-server.## This should stay commented out for backward compatibility and because most# people do not need auth (e.g. they run their own servers).## Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.## requirepass foobared# Command renaming.## It is possible to change the name of dangerous commands in a shared# environment. For instance the CONFIG command may be renamed into something# hard to guess so that it will still be available for internal-use tools# but not available for general clients.## Example:## rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52## It is also possible to completely kill a command by renaming it into# an empty string:## rename-command CONFIG ""## Please note that changing the name of commands that are logged into the# AOF file or transmitted to replicas may cause problems.################################### CLIENTS ##################################### Set the max number of connected clients at the same time. By default# this limit is set to 10000 clients, however if the Redis server is not# able to configure the process file limit to allow for the specified limit# the max number of allowed clients is set to the current file limit# minus 32 (as Redis reserves a few file descriptors for internal uses).## Once the limit is reached Redis will close all the new connections sending# an error 'max number of clients reached'.## maxclients 10000############################## MEMORY MANAGEMENT ################################# Set a memory usage limit to the specified amount of bytes.# When the memory limit is reached Redis will try to remove keys# according to the eviction policy selected (see maxmemory-policy).## If Redis can't remove keys according to the policy, or if the policy is# set to 'noeviction', Redis will start to reply with errors to commands# that would use more memory, like SET, LPUSH, and so on, and will continue# to reply to read-only commands like GET.## This option is usually useful when using Redis as an LRU or LFU cache, or to# set a hard memory limit for an instance (using the 'noeviction' policy).## WARNING: If you have replicas attached to an instance with maxmemory on,# the size of the output buffers needed to feed the replicas are subtracted# from the used memory count, so that network problems / resyncs will# not trigger a loop where keys are evicted, and in turn the output# buffer of replicas is full with DELs of keys evicted triggering the deletion# of more keys, and so forth until the database is completely emptied.## In short... if you have replicas attached it is suggested that you set a lower# limit for maxmemory so that there is some free RAM on the system for replica# output buffers (but this is not needed if the policy is 'noeviction').## maxmemory &lt;bytes&gt;# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached. You can select among five behaviors:## volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.# allkeys-lru -&gt; Evict any key using approximated LRU.# volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.# allkeys-lfu -&gt; Evict any key using approximated LFU.# volatile-random -&gt; Remove a random key among the ones with an expire set.# allkeys-random -&gt; Remove a random key, any key.# volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)# noeviction -&gt; Don't evict anything, just return an error on write operations.## LRU means Least Recently Used# LFU means Least Frequently Used## Both LRU, LFU and volatile-ttl are implemented using approximated# randomized algorithms.## Note: with any of the above policies, Redis will return an error on write#       operations, when there are no suitable keys for eviction.##       At the date of writing these commands are: set setnx setex append#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby#       getset mset msetnx exec sort## The default is:## maxmemory-policy noeviction# LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated# algorithms (in order to save memory), so you can tune it for speed or# accuracy. For default Redis will check five keys and pick the one that was# used less recently, you can change the sample size using the following# configuration directive.## The default of 5 produces good enough results. 10 Approximates very closely# true LRU but costs more CPU. 3 is faster but not very accurate.## maxmemory-samples 5# Starting from Redis 5, by default a replica will ignore its maxmemory setting# (unless it is promoted to master after a failover or manually). It means# that the eviction of keys will be just handled by the master, sending the# DEL commands to the replica as keys evict in the master side.## This behavior ensures that masters and replicas stay consistent, and is usually# what you want, however if your replica is writable, or you want the replica to have# a different memory setting, and you are sure all the writes performed to the# replica are idempotent, then you may change this default (but be sure to understand# what you are doing).## Note that since the replica by default does not evict, it may end using more# memory than the one set via maxmemory (there are certain buffers that may# be larger on the replica, or data structures may sometimes take more memory and so# forth). So make sure you monitor your replicas and make sure they have enough# memory to never hit a real out-of-memory condition before the master hits# the configured maxmemory setting.## replica-ignore-maxmemory yes############################# LAZY FREEING ##################################### Redis has two primitives to delete keys. One is called DEL and is a blocking# deletion of the object. It means that the server stops processing new commands# in order to reclaim all the memory associated with an object in a synchronous# way. If the key deleted is associated with a small object, the time needed# in order to execute the DEL command is very small and comparable to most other# O(1) or O(log_N) commands in Redis. However if the key is associated with an# aggregated value containing millions of elements, the server can block for# a long time (even seconds) in order to complete the operation.## For the above reasons Redis also offers non blocking deletion primitives# such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and# FLUSHDB commands, in order to reclaim memory in background. Those commands# are executed in constant time. Another thread will incrementally free the# object in the background as fast as possible.## DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.# It's up to the design of the application to understand when it is a good# idea to use one or the other. However the Redis server sometimes has to# delete keys or flush the whole database as a side effect of other operations.# Specifically Redis deletes objects independently of a user call in the# following scenarios:## 1) On eviction, because of the maxmemory and maxmemory policy configurations,#    in order to make room for new data, without going over the specified#    memory limit.# 2) Because of expire: when a key with an associated time to live (see the#    EXPIRE command) must be deleted from memory.# 3) Because of a side effect of a command that stores data on a key that may#    already exist. For example the RENAME command may delete the old key#    content when it is replaced with another one. Similarly SUNIONSTORE#    or SORT with STORE option may delete existing keys. The SET command#    itself removes any old content of the specified key in order to replace#    it with the specified string.# 4) During replication, when a replica performs a full resynchronization with#    its master, the content of the whole database is removed in order to#    load the RDB file just transferred.## In all the above cases the default is to delete objects in a blocking way,# like if DEL was called. However you can configure each case specifically# in order to instead release memory in a non-blocking way like if UNLINK# was called, using the following configuration directives:lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noreplica-lazy-flush no############################## APPEND ONLY MODE ################################ By default Redis asynchronously dumps the dataset on disk. This mode is# good enough in many applications, but an issue with the Redis process or# a power outage may result into a few minutes of writes lost (depending on# the configured save points).## The Append Only File is an alternative persistence mode that provides# much better durability. For instance using the default data fsync policy# (see later in the config file) Redis can lose just one second of writes in a# dramatic event like a server power outage, or a single write if something# wrong with the Redis process itself happens, but the operating system is# still running correctly.## AOF and RDB persistence can be enabled at the same time without problems.# If the AOF is enabled on startup Redis will load the AOF, that is the file# with the better durability guarantees.## Please check http://redis.io/topics/persistence for more information.appendonly no# The name of the append only file (default: "appendonly.aof")appendfilename "appendonly.aof"# The fsync() call tells the Operating System to actually write data on disk# instead of waiting for more data in the output buffer. Some OS will really flush# data on disk, some other OS will just try to do it ASAP.## Redis supports three different modes:## no: don't fsync, just let the OS flush the data when it wants. Faster.# always: fsync after every write to the append only log. Slow, Safest.# everysec: fsync only one time every second. Compromise.## The default is "everysec", as that's usually the right compromise between# speed and data safety. It's up to you to understand if you can relax this to# "no" that will let the operating system flush the output buffer when# it wants, for better performances (but if you can live with the idea of# some data loss consider the default persistence mode that's snapshotting),# or on the contrary, use "always" that's very slow but a bit safer than# everysec.## More details please check the following article:# http://antirez.com/post/redis-persistence-demystified.html## If unsure, use "everysec".# appendfsync alwaysappendfsync everysec# appendfsync no# When the AOF fsync policy is set to always or everysec, and a background# saving process (a background save or AOF log background rewriting) is# performing a lot of I/O against the disk, in some Linux configurations# Redis may block too long on the fsync() call. Note that there is no fix for# this currently, as even performing fsync in a different thread will block# our synchronous write(2) call.## In order to mitigate this problem it's possible to use the following option# that will prevent fsync() from being called in the main process while a# BGSAVE or BGREWRITEAOF is in progress.## This means that while another child is saving, the durability of Redis is# the same as "appendfsync none". In practical terms, this means that it is# possible to lose up to 30 seconds of log in the worst scenario (with the# default Linux settings).## If you have latency problems turn this to "yes". Otherwise leave it as# "no" that is the safest pick from the point of view of durability.no-appendfsync-on-rewrite no# Automatic rewrite of the append only file.# Redis is able to automatically rewrite the log file implicitly calling# BGREWRITEAOF when the AOF log size grows by the specified percentage.## This is how it works: Redis remembers the size of the AOF file after the# latest rewrite (if no rewrite has happened since the restart, the size of# the AOF at startup is used).## This base size is compared to the current size. If the current size is# bigger than the specified percentage, the rewrite is triggered. Also# you need to specify a minimal size for the AOF file to be rewritten, this# is useful to avoid rewriting the AOF file even if the percentage increase# is reached but it is still pretty small.## Specify a percentage of zero in order to disable the automatic AOF# rewrite feature.auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# An AOF file may be found to be truncated at the end during the Redis# startup process, when the AOF data gets loaded back into memory.# This may happen when the system where Redis is running# crashes, especially when an ext4 filesystem is mounted without the# data=ordered option (however this can't happen when Redis itself# crashes or aborts but the operating system still works correctly).## Redis can either exit with an error when this happens, or load as much# data as possible (the default now) and start if the AOF file is found# to be truncated at the end. The following option controls this behavior.## If aof-load-truncated is set to yes, a truncated AOF file is loaded and# the Redis server starts emitting a log to inform the user of the event.# Otherwise if the option is set to no, the server aborts with an error# and refuses to start. When the option is set to no, the user requires# to fix the AOF file using the "redis-check-aof" utility before to restart# the server.## Note that if the AOF file will be found to be corrupted in the middle# the server will still exit with an error. This option only applies when# Redis will try to read more data from the AOF file but not enough bytes# will be found.aof-load-truncated yes# When rewriting the AOF file, Redis is able to use an RDB preamble in the# AOF file for faster rewrites and recoveries. When this option is turned# on the rewritten AOF file is composed of two different stanzas:##   [RDB file][AOF tail]## When loading Redis recognizes that the AOF file starts with the "REDIS"# string and loads the prefixed RDB file, and continues loading the AOF# tail.aof-use-rdb-preamble yes################################ LUA SCRIPTING  ################################ Max execution time of a Lua script in milliseconds.## If the maximum execution time is reached Redis will log that a script is# still in execution after the maximum allowed time and will start to# reply to queries with an error.## When a long running script exceeds the maximum execution time only the# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be# used to stop a script that did not yet called write commands. The second# is the only way to shut down the server in the case a write command was# already issued by the script but the user doesn't want to wait for the natural# termination of the script.## Set it to 0 or a negative value for unlimited execution without warnings.lua-time-limit 5000################################ REDIS CLUSTER  ################################ Normal Redis instances can't be part of a Redis Cluster; only nodes that are# started as cluster nodes can. In order to start a Redis instance as a# cluster node enable the cluster support uncommenting the following:## cluster-enabled yes# Every cluster node has a cluster configuration file. This file is not# intended to be edited by hand. It is created and updated by Redis nodes.# Every Redis Cluster node requires a different cluster configuration file.# Make sure that instances running in the same system do not have# overlapping cluster configuration file names.## cluster-config-file nodes-6379.conf# Cluster node timeout is the amount of milliseconds a node must be unreachable# for it to be considered in failure state.# Most other internal time limits are multiple of the node timeout.## cluster-node-timeout 15000# A replica of a failing master will avoid to start a failover if its data# looks too old.## There is no simple way for a replica to actually have an exact measure of# its "data age", so the following two checks are performed:## 1) If there are multiple replicas able to failover, they exchange messages#    in order to try to give an advantage to the replica with the best#    replication offset (more data from the master processed).#    Replicas will try to get their rank by offset, and apply to the start#    of the failover a delay proportional to their rank.## 2) Every single replica computes the time of the last interaction with#    its master. This can be the last ping or command received (if the master#    is still in the "connected" state), or the time that elapsed since the#    disconnection with the master (if the replication link is currently down).#    If the last interaction is too old, the replica will not try to failover#    at all.## The point "2" can be tuned by user. Specifically a replica will not perform# the failover if, since the last interaction with the master, the time# elapsed is greater than:##   (node-timeout * replica-validity-factor) + repl-ping-replica-period## So for example if node-timeout is 30 seconds, and the replica-validity-factor# is 10, and assuming a default repl-ping-replica-period of 10 seconds, the# replica will not try to failover if it was not able to talk with the master# for longer than 310 seconds.## A large replica-validity-factor may allow replicas with too old data to failover# a master, while a too small value may prevent the cluster from being able to# elect a replica at all.## For maximum availability, it is possible to set the replica-validity-factor# to a value of 0, which means, that replicas will always try to failover the# master regardless of the last time they interacted with the master.# (However they'll always try to apply a delay proportional to their# offset rank).## Zero is the only value able to guarantee that when all the partitions heal# the cluster will always be able to continue.## cluster-replica-validity-factor 10# Cluster replicas are able to migrate to orphaned masters, that are masters# that are left without working replicas. This improves the cluster ability# to resist to failures as otherwise an orphaned master can't be failed over# in case of failure if it has no working replicas.## Replicas migrate to orphaned masters only if there are still at least a# given number of other working replicas for their old master. This number# is the "migration barrier". A migration barrier of 1 means that a replica# will migrate only if there is at least 1 other working replica for its master# and so forth. It usually reflects the number of replicas you want for every# master in your cluster.## Default is 1 (replicas migrate only if their masters remain with at least# one replica). To disable migration just set it to a very large value.# A value of 0 can be set but is useful only for debugging and dangerous# in production.## cluster-migration-barrier 1# By default Redis Cluster nodes stop accepting queries if they detect there# is at least an hash slot uncovered (no available node is serving it).# This way if the cluster is partially down (for example a range of hash slots# are no longer covered) all the cluster becomes, eventually, unavailable.# It automatically returns available as soon as all the slots are covered again.## However sometimes you want the subset of the cluster which is working,# to continue to accept queries for the part of the key space that is still# covered. In order to do so, just set the cluster-require-full-coverage# option to no.## cluster-require-full-coverage yes# This option, when set to yes, prevents replicas from trying to failover its# master during master failures. However the master can still perform a# manual failover, if forced to do so.## This is useful in different scenarios, especially in the case of multiple# data center operations, where we want one side to never be promoted if not# in the case of a total DC failure.## cluster-replica-no-failover no# In order to setup your cluster make sure to read the documentation# available at http://redis.io web site.########################## CLUSTER DOCKER/NAT support  ######################### In certain deployments, Redis Cluster nodes address discovery fails, because# addresses are NAT-ted or because ports are forwarded (the typical case is# Docker and other containers).## In order to make Redis Cluster working in such environments, a static# configuration where each node knows its public address is needed. The# following two options are used for this scope, and are:## * cluster-announce-ip# * cluster-announce-port# * cluster-announce-bus-port## Each instruct the node about its address, client port, and cluster message# bus port. The information is then published in the header of the bus packets# so that other nodes will be able to correctly map the address of the node# publishing the information.## If the above options are not used, the normal Redis Cluster auto-detection# will be used instead.## Note that when remapped, the bus port may not be at the fixed offset of# clients port + 10000, so you can specify any port and bus-port depending# on how they get remapped. If the bus-port is not set, a fixed offset of# 10000 will be used as usually.## Example:## cluster-announce-ip 10.1.1.5# cluster-announce-port 6379# cluster-announce-bus-port 6380################################## SLOW LOG #################################### The Redis Slow Log is a system to log queries that exceeded a specified# execution time. The execution time does not include the I/O operations# like talking with the client, sending the reply and so forth,# but just the time needed to actually execute the command (this is the only# stage of command execution where the thread is blocked and can not serve# other requests in the meantime).## You can configure the slow log with two parameters: one tells Redis# what is the execution time, in microseconds, to exceed in order for the# command to get logged, and the other parameter is the length of the# slow log. When a new command is logged the oldest one is removed from the# queue of logged commands.# The following time is expressed in microseconds, so 1000000 is equivalent# to one second. Note that a negative number disables the slow log, while# a value of zero forces the logging of every command.slowlog-log-slower-than 10000# There is no limit to this length. Just be aware that it will consume memory.# You can reclaim memory used by the slow log with SLOWLOG RESET.slowlog-max-len 128################################ LATENCY MONITOR ############################### The Redis latency monitoring subsystem samples different operations# at runtime in order to collect data related to possible sources of# latency of a Redis instance.## Via the LATENCY command this information is available to the user that can# print graphs and obtain reports.## The system only logs operations that were performed in a time equal or# greater than the amount of milliseconds specified via the# latency-monitor-threshold configuration directive. When its value is set# to zero, the latency monitor is turned off.## By default latency monitoring is disabled since it is mostly not needed# if you don't have latency issues, and collecting data has a performance# impact, that while very small, can be measured under big load. Latency# monitoring can easily be enabled at runtime using the command# "CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;" if needed.latency-monitor-threshold 0############################# EVENT NOTIFICATION ############################### Redis can notify Pub/Sub clients about events happening in the key space.# This feature is documented at http://redis.io/topics/notifications## For instance if keyspace events notification is enabled, and a client# performs a DEL operation on key "foo" stored in the Database 0, two# messages will be published via Pub/Sub:## PUBLISH __keyspace@0__:foo del# PUBLISH __keyevent@0__:del foo## It is possible to select the events that Redis will notify among a set# of classes. Every class is identified by a single character:##  K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.#  E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...#  $     String commands#  l     List commands#  s     Set commands#  h     Hash commands#  z     Sorted set commands#  x     Expired events (events generated every time a key expires)#  e     Evicted events (events generated when a key is evicted for maxmemory)#  A     Alias for g$lshzxe, so that the "AKE" string means all the events.##  The "notify-keyspace-events" takes as argument a string that is composed#  of zero or multiple characters. The empty string means that notifications#  are disabled.##  Example: to enable list and generic events, from the point of view of the#           event name, use:##  notify-keyspace-events Elg##  Example 2: to get the stream of the expired keys subscribing to channel#             name __keyevent@0__:expired use:##  notify-keyspace-events Ex##  By default all notifications are disabled because most users don't need#  this feature and the feature has some overhead. Note that if you don't#  specify at least one of K or E, no events will be delivered.notify-keyspace-events ""############################### ADVANCED CONFIG ################################ Hashes are encoded using a memory efficient data structure when they have a# small number of entries, and the biggest entry does not exceed a given# threshold. These thresholds can be configured using the following directives.hash-max-ziplist-entries 512hash-max-ziplist-value 64# Lists are also encoded in a special way to save a lot of space.# The number of entries allowed per internal list node can be specified# as a fixed maximum size or a maximum number of elements.# For a fixed maximum size, use -5 through -1, meaning:# -5: max size: 64 Kb  &lt;-- not recommended for normal workloads# -4: max size: 32 Kb  &lt;-- not recommended# -3: max size: 16 Kb  &lt;-- probably not recommended# -2: max size: 8 Kb   &lt;-- good# -1: max size: 4 Kb   &lt;-- good# Positive numbers mean store up to _exactly_ that number of elements# per list node.# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),# but if your use case is unique, adjust the settings as necessary.list-max-ziplist-size -2# Lists may also be compressed.# Compress depth is the number of quicklist ziplist nodes from *each* side of# the list to *exclude* from compression.  The head and tail of the list# are always uncompressed for fast push/pop operations.  Settings are:# 0: disable all list compression# 1: depth 1 means "don't start compressing until after 1 node into the list,#    going from either the head or tail"#    So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]#    [head], [tail] will always be uncompressed; inner nodes will compress.# 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]#    2 here means: don't compress head or head-&gt;next or tail-&gt;prev or tail,#    but compress all nodes between them.# 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]# etc.list-compress-depth 0# Sets have a special encoding in just one case: when a set is composed# of just strings that happen to be integers in radix 10 in the range# of 64 bit signed integers.# The following configuration setting sets the limit in the size of the# set in order to use this special memory saving encoding.set-max-intset-entries 512# Similarly to hashes and lists, sorted sets are also specially encoded in# order to save a lot of space. This encoding is only used when the length and# elements of a sorted set are below the following limits:zset-max-ziplist-entries 128zset-max-ziplist-value 64# HyperLogLog sparse representation bytes limit. The limit includes the# 16 bytes header. When an HyperLogLog using the sparse representation crosses# this limit, it is converted into the dense representation.## A value greater than 16000 is totally useless, since at that point the# dense representation is more memory efficient.## The suggested value is ~ 3000 in order to have the benefits of# the space efficient encoding without slowing down too much PFADD,# which is O(N) with the sparse encoding. The value can be raised to# ~ 10000 when CPU is not a concern, but space is, and the data set is# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.hll-sparse-max-bytes 3000# Streams macro node max size / items. The stream data structure is a radix# tree of big nodes that encode multiple items inside. Using this configuration# it is possible to configure how big a single node can be in bytes, and the# maximum number of items it may contain before switching to a new node when# appending new stream entries. If any of the following settings are set to# zero, the limit is ignored, so for instance it is possible to set just a# max entires limit by setting max-bytes to 0 and max-entries to the desired# value.stream-node-max-bytes 4096stream-node-max-entries 100# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in# order to help rehashing the main Redis hash table (the one mapping top-level# keys to values). The hash table implementation Redis uses (see dict.c)# performs a lazy rehashing: the more operation you run into a hash table# that is rehashing, the more rehashing "steps" are performed, so if the# server is idle the rehashing is never complete and some more memory is used# by the hash table.## The default is to use this millisecond 10 times every second in order to# actively rehash the main dictionaries, freeing memory when possible.## If unsure:# use "activerehashing no" if you have hard latency requirements and it is# not a good thing in your environment that Redis can reply from time to time# to queries with 2 milliseconds delay.## use "activerehashing yes" if you don't have such hard requirements but# want to free memory asap when possible.activerehashing yes# The client output buffer limits can be used to force disconnection of clients# that are not reading data from the server fast enough for some reason (a# common reason is that a Pub/Sub client can't consume messages as fast as the# publisher can produce them).## The limit can be set differently for the three different classes of clients:## normal -&gt; normal clients including MONITOR clients# replica  -&gt; replica clients# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern## The syntax of every client-output-buffer-limit directive is the following:## client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;## A client is immediately disconnected once the hard limit is reached, or if# the soft limit is reached and remains reached for the specified number of# seconds (continuously).# So for instance if the hard limit is 32 megabytes and the soft limit is# 16 megabytes / 10 seconds, the client will get disconnected immediately# if the size of the output buffers reach 32 megabytes, but will also get# disconnected if the client reaches 16 megabytes and continuously overcomes# the limit for 10 seconds.## By default normal clients are not limited because they don't receive data# without asking (in a push way), but just after a request, so only# asynchronous clients may create a scenario where data is requested faster# than it can read.## Instead there is a default limit for pubsub and replica clients, since# subscribers and replicas receive data in a push fashion.## Both the hard or the soft limit can be disabled by setting them to zero.client-output-buffer-limit normal 0 0 0client-output-buffer-limit replica 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# Client query buffers accumulate new commands. They are limited to a fixed# amount by default in order to avoid that a protocol desynchronization (for# instance due to a bug in the client) will lead to unbound memory usage in# the query buffer. However you can configure it here if you have very special# needs, such us huge multi/exec requests or alike.## client-query-buffer-limit 1gb# In the Redis protocol, bulk requests, that are, elements representing single# strings, are normally limited ot 512 mb. However you can change this limit# here.## proto-max-bulk-len 512mb# Redis calls an internal function to perform many background tasks, like# closing connections of clients in timeout, purging expired keys that are# never requested, and so forth.## Not all tasks are performed with the same frequency, but Redis checks for# tasks to perform according to the specified "hz" value.## By default "hz" is set to 10. Raising the value will use more CPU when# Redis is idle, but at the same time will make Redis more responsive when# there are many keys expiring at the same time, and timeouts may be# handled with more precision.## The range is between 1 and 500, however a value over 100 is usually not# a good idea. Most users should use the default of 10 and raise this up to# 100 only in environments where very low latency is required.hz 10# Normally it is useful to have an HZ value which is proportional to the# number of clients connected. This is useful in order, for instance, to# avoid too many clients are processed for each background task invocation# in order to avoid latency spikes.## Since the default HZ value by default is conservatively set to 10, Redis# offers, and enables by default, the ability to use an adaptive HZ value# which will temporary raise when there are many connected clients.## When dynamic HZ is enabled, the actual configured HZ will be used as# as a baseline, but multiples of the configured HZ value will be actually# used as needed once more clients are connected. In this way an idle# instance will use very little CPU time while a busy instance will be# more responsive.dynamic-hz yes# When a child rewrites the AOF file, if the following option is enabled# the file will be fsync-ed every 32 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.aof-rewrite-incremental-fsync yes# When redis saves RDB file, if the following option is enabled# the file will be fsync-ed every 32 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.rdb-save-incremental-fsync yes# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good# idea to start with the default settings and only change them after investigating# how to improve the performances and how the keys LFU change over time, which# is possible to inspect via the OBJECT FREQ command.## There are two tunable parameters in the Redis LFU implementation: the# counter logarithm factor and the counter decay time. It is important to# understand what the two parameters mean before changing them.## The LFU counter is just 8 bits per key, it's maximum value is 255, so Redis# uses a probabilistic increment with logarithmic behavior. Given the value# of the old counter, when a key is accessed, the counter is incremented in# this way:## 1. A random number R between 0 and 1 is extracted.# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).# 3. The counter is incremented only if R &lt; P.## The default lfu-log-factor is 10. This is a table of how the frequency# counter changes with a different number of accesses with different# logarithmic factors:## +--------+------------+------------+------------+------------+------------+# | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |# +--------+------------+------------+------------+------------+------------+# | 0      | 104        | 255        | 255        | 255        | 255        |# +--------+------------+------------+------------+------------+------------+# | 1      | 18         | 49         | 255        | 255        | 255        |# +--------+------------+------------+------------+------------+------------+# | 10     | 10         | 18         | 142        | 255        | 255        |# +--------+------------+------------+------------+------------+------------+# | 100    | 8          | 11         | 49         | 143        | 255        |# +--------+------------+------------+------------+------------+------------+## NOTE: The above table was obtained by running the following commands:##   redis-benchmark -n 1000000 incr foo#   redis-cli object freq foo## NOTE 2: The counter initial value is 5 in order to give new objects a chance# to accumulate hits.## The counter decay time is the time, in minutes, that must elapse in order# for the key counter to be divided by two (or decremented if it has a value# less &lt;= 10).## The default value for the lfu-decay-time is 1. A Special value of 0 means to# decay the counter every time it happens to be scanned.## lfu-log-factor 10# lfu-decay-time 1########################### ACTIVE DEFRAGMENTATION ######################### WARNING THIS FEATURE IS EXPERIMENTAL. However it was stress tested# even in production and manually tested by multiple engineers for some# time.## What is active defragmentation?# -------------------------------## Active (online) defragmentation allows a Redis server to compact the# spaces left between small allocations and deallocations of data in memory,# thus allowing to reclaim back memory.## Fragmentation is a natural process that happens with every allocator (but# less so with Jemalloc, fortunately) and certain workloads. Normally a server# restart is needed in order to lower the fragmentation, or at least to flush# away all the data and create it again. However thanks to this feature# implemented by Oran Agra for Redis 4.0 this process can happen at runtime# in an "hot" way, while the server is running.## Basically when the fragmentation is over a certain level (see the# configuration options below) Redis will start to create new copies of the# values in contiguous memory regions by exploiting certain specific Jemalloc# features (in order to understand if an allocation is causing fragmentation# and to allocate it in a better place), and at the same time, will release the# old copies of the data. This process, repeated incrementally for all the keys# will cause the fragmentation to drop back to normal values.## Important things to understand:## 1. This feature is disabled by default, and only works if you compiled Redis#    to use the copy of Jemalloc we ship with the source code of Redis.#    This is the default with Linux builds.## 2. You never need to enable this feature if you don't have fragmentation#    issues.## 3. Once you experience fragmentation, you can enable this feature when#    needed with the command "CONFIG SET activedefrag yes".## The configuration parameters are able to fine tune the behavior of the# defragmentation process. If you are not sure about what they mean it is# a good idea to leave the defaults untouched.# Enabled active defragmentation# activedefrag yes# Minimum amount of fragmentation waste to start active defrag# active-defrag-ignore-bytes 100mb# Minimum percentage of fragmentation to start active defrag# active-defrag-threshold-lower 10# Maximum percentage of fragmentation at which we use maximum effort# active-defrag-threshold-upper 100# Minimal effort for defrag in CPU percentage# active-defrag-cycle-min 5# Maximal effort for defrag in CPU percentage# active-defrag-cycle-max 75# Maximum number of set/hash/zset/list fields that will be processed from# the main dictionary scan# active-defrag-max-scan-fields 1000</code></pre><p>这个是redis.config的文件配置与内容：</p><pre><code># Redis configuration file example.## Note that in order to read the configuration file, Redis must be# started with the file path as first argument:## ./redis-server /path/to/redis.conf# Note on units: when memory size is needed, it is possible to specify# it in the usual form of 1k 5GB 4M and so forth:## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## units are case insensitive so 1GB 1Gb 1gB are all the same.################################## INCLUDES #################################### Include one or more other config files here.  This is useful if you# have a standard template that goes to all Redis servers but also need# to customize a few per-server settings.  Include files can include# other files, so use this wisely.## Note that option "include" won't be rewritten by command "CONFIG REWRITE"# from admin or Redis Sentinel. Since Redis always uses the last processed# line as value of a configuration directive, you'd better put includes# at the beginning of this file to avoid overwriting config change at runtime.## If instead you are interested in using includes to override configuration# options, it is better to use include as the last line.## include /path/to/local.conf# include /path/to/other.conf################################## MODULES ###################################### Load modules at startup. If the server is not able to load modules# it will abort. It is possible to use multiple loadmodule directives.## loadmodule /path/to/my_module.so# loadmodule /path/to/other_module.so################################## NETWORK ###################################### By default, if no "bind" configuration directive is specified, Redis listens# for connections from all available network interfaces on the host machine.# It is possible to listen to just one or multiple selected interfaces using# the "bind" configuration directive, followed by one or more IP addresses.# Each address can be prefixed by "-", which means that redis will not fail to# start if the address is not available. Being not available only refers to# addresses that does not correspond to any network interfece. Addresses that# are already in use will always fail, and unsupported protocols will always BE# silently skipped.## Examples:## bind 192.168.1.100 10.0.0.1     # listens on two specific IPv4 addresses# bind 127.0.0.1 ::1              # listens on loopback IPv4 and IPv6# bind * -::*                     # like the default, all available interfaces## ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the# internet, binding to all the interfaces is dangerous and will expose the# instance to everybody on the internet. So by default we uncomment the# following bind directive, that will force Redis to listen only on the# IPv4 and IPv6 (if available) loopback interface addresses (this means Redis# will only be able to accept client connections from the same host that it is# running on).## IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES# JUST COMMENT OUT THE FOLLOWING LINE.# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#bind 127.0.0.1 -::1# Protected mode is a layer of security protection, in order to avoid that# Redis instances left open on the internet are accessed and exploited.## When protected mode is on and if:## 1) The server is not binding explicitly to a set of addresses using the#    "bind" directive.# 2) No password is configured.## The server only accepts connections from clients connecting from the# IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain# sockets.## By default protected mode is enabled. You should disable it only if# you are sure you want clients from other hosts to connect to Redis# even if no authentication is configured, nor a specific set of interfaces# are explicitly listed using the "bind" directive.protected-mode no# Accept connections on the specified port, default is 6379 (IANA #815344).# If port 0 is specified Redis will not listen on a TCP socket.port 6379# TCP listen() backlog.## In high requests-per-second environments you need a high backlog in order# to avoid slow clients connection issues. Note that the Linux kernel# will silently truncate it to the value of /proc/sys/net/core/somaxconn so# make sure to raise both the value of somaxconn and tcp_max_syn_backlog# in order to get the desired effect.tcp-backlog 511# Unix socket.## Specify the path for the Unix socket that will be used to listen for# incoming connections. There is no default, so Redis will not listen# on a unix socket when not specified.## unixsocket /run/redis.sock# unixsocketperm 700# Close the connection after a client is idle for N seconds (0 to disable)timeout 0# TCP keepalive.## If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence# of communication. This is useful for two reasons:## 1) Detect dead peers.# 2) Force network equipment in the middle to consider the connection to be#    alive.## On Linux, the specified value (in seconds) is the period used to send ACKs.# Note that to close the connection the double of the time is needed.# On other kernels the period depends on the kernel configuration.## A reasonable value for this option is 300 seconds, which is the new# Redis default starting with Redis 3.2.1.tcp-keepalive 300################################# TLS/SSL ###################################### By default, TLS/SSL is disabled. To enable it, the "tls-port" configuration# directive can be used to define TLS-listening ports. To enable TLS on the# default port, use:## port 0# tls-port 6379# Configure a X.509 certificate and private key to use for authenticating the# server to connected clients, masters or cluster peers.  These files should be# PEM formatted.## tls-cert-file redis.crt # tls-key-file redis.key## If the key file is encrypted using a passphrase, it can be included here# as well.## tls-key-file-pass secret# Normally Redis uses the same certificate for both server functions (accepting# connections) and client functions (replicating from a master, establishing# cluster bus connections, etc.).## Sometimes certificates are issued with attributes that designate them as# client-only or server-only certificates. In that case it may be desired to use# different certificates for incoming (server) and outgoing (client)# connections. To do that, use the following directives:## tls-client-cert-file client.crt# tls-client-key-file client.key## If the key file is encrypted using a passphrase, it can be included here# as well.## tls-client-key-file-pass secret# Configure a DH parameters file to enable Diffie-Hellman (DH) key exchange:## tls-dh-params-file redis.dh# Configure a CA certificate(s) bundle or directory to authenticate TLS/SSL# clients and peers.  Redis requires an explicit configuration of at least one# of these, and will not implicitly use the system wide configuration.## tls-ca-cert-file ca.crt# tls-ca-cert-dir /etc/ssl/certs# By default, clients (including replica servers) on a TLS port are required# to authenticate using valid client side certificates.## If "no" is specified, client certificates are not required and not accepted.# If "optional" is specified, client certificates are accepted and must be# valid if provided, but are not required.## tls-auth-clients no# tls-auth-clients optional# By default, a Redis replica does not attempt to establish a TLS connection# with its master.## Use the following directive to enable TLS on replication links.## tls-replication yes# By default, the Redis Cluster bus uses a plain TCP connection. To enable# TLS for the bus protocol, use the following directive:## tls-cluster yes# By default, only TLSv1.2 and TLSv1.3 are enabled and it is highly recommended# that older formally deprecated versions are kept disabled to reduce the attack surface.# You can explicitly specify TLS versions to support.# Allowed values are case insensitive and include "TLSv1", "TLSv1.1", "TLSv1.2",# "TLSv1.3" (OpenSSL &gt;= 1.1.1) or any combination.# To enable only TLSv1.2 and TLSv1.3, use:## tls-protocols "TLSv1.2 TLSv1.3"# Configure allowed ciphers.  See the ciphers(1ssl) manpage for more information# about the syntax of this string.## Note: this configuration applies only to &lt;= TLSv1.2.## tls-ciphers DEFAULT:!MEDIUM# Configure allowed TLSv1.3 ciphersuites.  See the ciphers(1ssl) manpage for more# information about the syntax of this string, and specifically for TLSv1.3# ciphersuites.## tls-ciphersuites TLS_CHACHA20_POLY1305_SHA256# When choosing a cipher, use the server's preference instead of the client# preference. By default, the server follows the client's preference.## tls-prefer-server-ciphers yes# By default, TLS session caching is enabled to allow faster and less expensive# reconnections by clients that support it. Use the following directive to disable# caching.## tls-session-caching no# Change the default number of TLS sessions cached. A zero value sets the cache# to unlimited size. The default size is 20480.## tls-session-cache-size 5000# Change the default timeout of cached TLS sessions. The default timeout is 300# seconds.## tls-session-cache-timeout 60################################# GENERAL ###################################### By default Redis does not run as a daemon. Use 'yes' if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.# When Redis is supervised by upstart or systemd, this parameter has no impact.daemonize yes# If you run Redis from upstart or systemd, Redis can interact with your# supervision tree. Options:#   supervised no      - no supervision interaction#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode#                        requires "expect stop" in your upstart job config#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET#                        on startup, and updating Redis status on a regular#                        basis.#   supervised auto    - detect upstart or systemd method based on#                        UPSTART_JOB or NOTIFY_SOCKET environment variables# Note: these supervision methods only signal "process is ready."#       They do not enable continuous pings back to your supervisor.## The default is "no". To run under upstart/systemd, you can simply uncomment# the line below:## supervised auto# If a pid file is specified, Redis writes it where specified at startup# and removes it at exit.## When the server runs non daemonized, no pid file is created if none is# specified in the configuration. When the server is daemonized, the pid file# is used even if not specified, defaulting to "/var/run/redis.pid".## Creating a pid file is best effort: if Redis is not able to create it# nothing bad happens, the server will start and run normally.## Note that on modern Linux systems "/run/redis.pid" is more conforming# and should be used instead.pidfile /var/run/redis_6379.pid# Specify the server verbosity level.# This can be one of:# debug (a lot of information, useful for development/testing)# verbose (many rarely useful info, but not a mess like the debug level)# notice (moderately verbose, what you want in production probably)# warning (only very important / critical messages are logged)loglevel notice# Specify the log file name. Also the empty string can be used to force# Redis to log on the standard output. Note that if you use standard# output for logging but daemonize, logs will be sent to /dev/nulllogfile ""# To enable logging to the system logger, just set 'syslog-enabled' to yes,# and optionally update the other syslog parameters to suit your needs.# syslog-enabled no# Specify the syslog identity.# syslog-ident redis# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.# syslog-facility local0# To disable the built in crash log, which will possibly produce cleaner core# dumps when they are needed, uncomment the following:## crash-log-enabled no# To disable the fast memory check that's run as part of the crash log, which# will possibly let redis terminate sooner, uncomment the following:## crash-memcheck-enabled no# Set the number of databases. The default database is DB 0, you can select# a different one on a per-connection basis using SELECT &lt;dbid&gt; where# dbid is a number between 0 and 'databases'-1databases 16# By default Redis shows an ASCII art logo only when started to log to the# standard output and if the standard output is a TTY and syslog logging is# disabled. Basically this means that normally a logo is displayed only in# interactive sessions.## However it is possible to force the pre-4.0 behavior and always show a# ASCII art logo in startup logs by setting the following option to yes.always-show-logo no# By default, Redis modifies the process title (as seen in 'top' and 'ps') to# provide some runtime information. It is possible to disable this and leave# the process name as executed by setting the following to no.set-proc-title yes# When changing the process title, Redis uses the following template to construct# the modified title.## Template variables are specified in curly brackets. The following variables are# supported:## {title}           Name of process as executed if parent, or type of child process.# {listen-addr}     Bind address or '*' followed by TCP or TLS port listening on, or#                   Unix socket if only that's available.# {server-mode}     Special mode, i.e. "[sentinel]" or "[cluster]".# {port}            TCP port listening on, or 0.# {tls-port}        TLS port listening on, or 0.# {unixsocket}      Unix domain socket listening on, or "".# {config-file}     Name of configuration file used.#proc-title-template "{title} {listen-addr} {server-mode}"################################ SNAPSHOTTING  ################################# Save the DB to disk.## save &lt;seconds&gt; &lt;changes&gt;## Redis will save the DB if both the given number of seconds and the given# number of write operations against the DB occurred.## Snapshotting can be completely disabled with a single empty string argument# as in following example:## save ""## Unless specified otherwise, by default Redis will save the DB:#   * After 3600 seconds (an hour) if at least 1 key changed#   * After 300 seconds (5 minutes) if at least 100 keys changed#   * After 60 seconds if at least 10000 keys changed## You can set these explicitly by uncommenting the three following lines.## save 3600 1# save 300 100# save 60 10000# By default Redis will stop accepting writes if RDB snapshots are enabled# (at least one save point) and the latest background save failed.# This will make the user aware (in a hard way) that data is not persisting# on disk properly, otherwise chances are that no one will notice and some# disaster will happen.## If the background saving process will start working again Redis will# automatically allow writes again.## However if you have setup your proper monitoring of the Redis server# and persistence, you may want to disable this feature so that Redis will# continue to work as usual even if there are problems with disk,# permissions, and so forth.stop-writes-on-bgsave-error yes# Compress string objects using LZF when dump .rdb databases?# By default compression is enabled as it's almost always a win.# If you want to save some CPU in the saving child set it to 'no' but# the dataset will likely be bigger if you have compressible values or keys.rdbcompression yes# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.# This makes the format more resistant to corruption but there is a performance# hit to pay (around 10%) when saving and loading RDB files, so you can disable it# for maximum performances.## RDB files created with checksum disabled have a checksum of zero that will# tell the loading code to skip the check.rdbchecksum yes# Enables or disables full sanitation checks for ziplist and listpack etc when# loading an RDB or RESTORE payload. This reduces the chances of a assertion or# crash later on while processing commands.# Options:#   no         - Never perform full sanitation#   yes        - Always perform full sanitation#   clients    - Perform full sanitation only for user connections.#                Excludes: RDB files, RESTORE commands received from the master#                connection, and client connections which have the#                skip-sanitize-payload ACL flag.# The default should be 'clients' but since it currently affects cluster# resharding via MIGRATE, it is temporarily set to 'no' by default.## sanitize-dump-payload no# The filename where to dump the DBdbfilename dump.rdb# Remove RDB files used by replication in instances without persistence# enabled. By default this option is disabled, however there are environments# where for regulations or other security concerns, RDB files persisted on# disk by masters in order to feed replicas, or stored on disk by replicas# in order to load them for the initial synchronization, should be deleted# ASAP. Note that this option ONLY WORKS in instances that have both AOF# and RDB persistence disabled, otherwise is completely ignored.## An alternative (and sometimes better) way to obtain the same effect is# to use diskless replication on both master and replicas instances. However# in the case of replicas, diskless is not always an option.rdb-del-sync-files no# The working directory.## The DB will be written inside this directory, with the filename specified# above using the 'dbfilename' configuration directive.## The Append Only File will also be created inside this directory.## Note that you must specify a directory here, not a file name.dir ./################################# REPLICATION ################################## Master-Replica replication. Use replicaof to make a Redis instance a copy of# another Redis server. A few things to understand ASAP about Redis replication.##   +------------------+      +---------------+#   |      Master      | ---&gt; |    Replica    |#   | (receive writes) |      |  (exact copy) |#   +------------------+      +---------------+## 1) Redis replication is asynchronous, but you can configure a master to#    stop accepting writes if it appears to be not connected with at least#    a given number of replicas.# 2) Redis replicas are able to perform a partial resynchronization with the#    master if the replication link is lost for a relatively small amount of#    time. You may want to configure the replication backlog size (see the next#    sections of this file) with a sensible value depending on your needs.# 3) Replication is automatic and does not need user intervention. After a#    network partition replicas automatically try to reconnect to masters#    and resynchronize with them.## replicaof &lt;masterip&gt; &lt;masterport&gt;# If the master is password protected (using the "requirepass" configuration# directive below) it is possible to tell the replica to authenticate before# starting the replication synchronization process, otherwise the master will# refuse the replica request.## masterauth &lt;master-password&gt;## However this is not enough if you are using Redis ACLs (for Redis version# 6 or greater), and the default user is not capable of running the PSYNC# command and/or other commands needed for replication. In this case it's# better to configure a special user to use with replication, and specify the# masteruser configuration as such:## masteruser &lt;username&gt;## When masteruser is specified, the replica will authenticate against its# master using the new AUTH form: AUTH &lt;username&gt; &lt;password&gt;.# When a replica loses its connection with the master, or when the replication# is still in progress, the replica can act in two different ways:## 1) if replica-serve-stale-data is set to 'yes' (the default) the replica will#    still reply to client requests, possibly with out of date data, or the#    data set may just be empty if this is the first synchronization.## 2) If replica-serve-stale-data is set to 'no' the replica will reply with#    an error "SYNC with master in progress" to all commands except:#    INFO, REPLICAOF, AUTH, PING, SHUTDOWN, REPLCONF, ROLE, CONFIG, SUBSCRIBE,#    UNSUBSCRIBE, PSUBSCRIBE, PUNSUBSCRIBE, PUBLISH, PUBSUB, COMMAND, POST,#    HOST and LATENCY.#replica-serve-stale-data yes# You can configure a replica instance to accept writes or not. Writing against# a replica instance may be useful to store some ephemeral data (because data# written on a replica will be easily deleted after resync with the master) but# may also cause problems if clients are writing to it because of a# misconfiguration.## Since Redis 2.6 by default replicas are read-only.## Note: read only replicas are not designed to be exposed to untrusted clients# on the internet. It's just a protection layer against misuse of the instance.# Still a read only replica exports by default all the administrative commands# such as CONFIG, DEBUG, and so forth. To a limited extent you can improve# security of read only replicas using 'rename-command' to shadow all the# administrative / dangerous commands.replica-read-only yes# Replication SYNC strategy: disk or socket.## New replicas and reconnecting replicas that are not able to continue the# replication process just receiving differences, need to do what is called a# "full synchronization". An RDB file is transmitted from the master to the# replicas.## The transmission can happen in two different ways:## 1) Disk-backed: The Redis master creates a new process that writes the RDB#                 file on disk. Later the file is transferred by the parent#                 process to the replicas incrementally.# 2) Diskless: The Redis master creates a new process that directly writes the#              RDB file to replica sockets, without touching the disk at all.## With disk-backed replication, while the RDB file is generated, more replicas# can be queued and served with the RDB file as soon as the current child# producing the RDB file finishes its work. With diskless replication instead# once the transfer starts, new replicas arriving will be queued and a new# transfer will start when the current one terminates.## When diskless replication is used, the master waits a configurable amount of# time (in seconds) before starting the transfer in the hope that multiple# replicas will arrive and the transfer can be parallelized.## With slow disks and fast (large bandwidth) networks, diskless replication# works better.repl-diskless-sync no# When diskless replication is enabled, it is possible to configure the delay# the server waits in order to spawn the child that transfers the RDB via socket# to the replicas.## This is important since once the transfer starts, it is not possible to serve# new replicas arriving, that will be queued for the next RDB transfer, so the# server waits a delay in order to let more replicas arrive.## The delay is specified in seconds, and by default is 5 seconds. To disable# it entirely just set it to 0 seconds and the transfer will start ASAP.repl-diskless-sync-delay 5# -----------------------------------------------------------------------------# WARNING: RDB diskless load is experimental. Since in this setup the replica# does not immediately store an RDB on disk, it may cause data loss during# failovers. RDB diskless load + Redis modules not handling I/O reads may also# cause Redis to abort in case of I/O errors during the initial synchronization# stage with the master. Use only if you know what you are doing.# -----------------------------------------------------------------------------## Replica can load the RDB it reads from the replication link directly from the# socket, or store the RDB to a file and read that file after it was completely# received from the master.## In many cases the disk is slower than the network, and storing and loading# the RDB file may increase replication time (and even increase the master's# Copy on Write memory and salve buffers).# However, parsing the RDB file directly from the socket may mean that we have# to flush the contents of the current database before the full rdb was# received. For this reason we have the following options:## "disabled"    - Don't use diskless load (store the rdb file to the disk first)# "on-empty-db" - Use diskless load only when it is completely safe.# "swapdb"      - Keep a copy of the current db contents in RAM while parsing#                 the data directly from the socket. note that this requires#                 sufficient memory, if you don't have it, you risk an OOM kill.repl-diskless-load disabled# Replicas send PINGs to server in a predefined interval. It's possible to# change this interval with the repl_ping_replica_period option. The default# value is 10 seconds.## repl-ping-replica-period 10# The following option sets the replication timeout for:## 1) Bulk transfer I/O during SYNC, from the point of view of replica.# 2) Master timeout from the point of view of replicas (data, pings).# 3) Replica timeout from the point of view of masters (REPLCONF ACK pings).## It is important to make sure that this value is greater than the value# specified for repl-ping-replica-period otherwise a timeout will be detected# every time there is low traffic between the master and the replica. The default# value is 60 seconds.## repl-timeout 60# Disable TCP_NODELAY on the replica socket after SYNC?## If you select "yes" Redis will use a smaller number of TCP packets and# less bandwidth to send data to replicas. But this can add a delay for# the data to appear on the replica side, up to 40 milliseconds with# Linux kernels using a default configuration.## If you select "no" the delay for data to appear on the replica side will# be reduced but more bandwidth will be used for replication.## By default we optimize for low latency, but in very high traffic conditions# or when the master and replicas are many hops away, turning this to "yes" may# be a good idea.repl-disable-tcp-nodelay no# Set the replication backlog size. The backlog is a buffer that accumulates# replica data when replicas are disconnected for some time, so that when a# replica wants to reconnect again, often a full resync is not needed, but a# partial resync is enough, just passing the portion of data the replica# missed while disconnected.## The bigger the replication backlog, the longer the replica can endure the# disconnect and later be able to perform a partial resynchronization.## The backlog is only allocated if there is at least one replica connected.## repl-backlog-size 1mb# After a master has no connected replicas for some time, the backlog will be# freed. The following option configures the amount of seconds that need to# elapse, starting from the time the last replica disconnected, for the backlog# buffer to be freed.## Note that replicas never free the backlog for timeout, since they may be# promoted to masters later, and should be able to correctly "partially# resynchronize" with other replicas: hence they should always accumulate backlog.## A value of 0 means to never release the backlog.## repl-backlog-ttl 3600# The replica priority is an integer number published by Redis in the INFO# output. It is used by Redis Sentinel in order to select a replica to promote# into a master if the master is no longer working correctly.## A replica with a low priority number is considered better for promotion, so# for instance if there are three replicas with priority 10, 100, 25 Sentinel# will pick the one with priority 10, that is the lowest.## However a special priority of 0 marks the replica as not able to perform the# role of master, so a replica with priority of 0 will never be selected by# Redis Sentinel for promotion.## By default the priority is 100.replica-priority 100# -----------------------------------------------------------------------------# By default, Redis Sentinel includes all replicas in its reports. A replica# can be excluded from Redis Sentinel's announcements. An unannounced replica# will be ignored by the 'sentinel replicas &lt;master&gt;' command and won't be# exposed to Redis Sentinel's clients.## This option does not change the behavior of replica-priority. Even with# replica-announced set to 'no', the replica can be promoted to master. To# prevent this behavior, set replica-priority to 0.## replica-announced yes# It is possible for a master to stop accepting writes if there are less than# N replicas connected, having a lag less or equal than M seconds.## The N replicas need to be in "online" state.## The lag in seconds, that must be &lt;= the specified value, is calculated from# the last ping received from the replica, that is usually sent every second.## This option does not GUARANTEE that N replicas will accept the write, but# will limit the window of exposure for lost writes in case not enough replicas# are available, to the specified number of seconds.## For example to require at least 3 replicas with a lag &lt;= 10 seconds use:## min-replicas-to-write 3# min-replicas-max-lag 10## Setting one or the other to 0 disables the feature.## By default min-replicas-to-write is set to 0 (feature disabled) and# min-replicas-max-lag is set to 10.# A Redis master is able to list the address and port of the attached# replicas in different ways. For example the "INFO replication" section# offers this information, which is used, among other tools, by# Redis Sentinel in order to discover replica instances.# Another place where this info is available is in the output of the# "ROLE" command of a master.## The listed IP address and port normally reported by a replica is# obtained in the following way:##   IP: The address is auto detected by checking the peer address#   of the socket used by the replica to connect with the master.##   Port: The port is communicated by the replica during the replication#   handshake, and is normally the port that the replica is using to#   listen for connections.## However when port forwarding or Network Address Translation (NAT) is# used, the replica may actually be reachable via different IP and port# pairs. The following two options can be used by a replica in order to# report to its master a specific set of IP and port, so that both INFO# and ROLE will report those values.## There is no need to use both the options if you need to override just# the port or the IP address.## replica-announce-ip 5.5.5.5# replica-announce-port 1234############################### KEYS TRACKING ################################## Redis implements server assisted support for client side caching of values.# This is implemented using an invalidation table that remembers, using# a radix key indexed by key name, what clients have which keys. In turn# this is used in order to send invalidation messages to clients. Please# check this page to understand more about the feature:##   https://redis.io/topics/client-side-caching## When tracking is enabled for a client, all the read only queries are assumed# to be cached: this will force Redis to store information in the invalidation# table. When keys are modified, such information is flushed away, and# invalidation messages are sent to the clients. However if the workload is# heavily dominated by reads, Redis could use more and more memory in order# to track the keys fetched by many clients.## For this reason it is possible to configure a maximum fill value for the# invalidation table. By default it is set to 1M of keys, and once this limit# is reached, Redis will start to evict keys in the invalidation table# even if they were not modified, just to reclaim memory: this will in turn# force the clients to invalidate the cached values. Basically the table# maximum size is a trade off between the memory you want to spend server# side to track information about who cached what, and the ability of clients# to retain cached objects in memory.## If you set the value to 0, it means there are no limits, and Redis will# retain as many keys as needed in the invalidation table.# In the "stats" INFO section, you can find information about the number of# keys in the invalidation table at every given moment.## Note: when key tracking is used in broadcasting mode, no memory is used# in the server side so this setting is useless.## tracking-table-max-keys 1000000################################## SECURITY #################################### Warning: since Redis is pretty fast, an outside user can try up to# 1 million passwords per second against a modern box. This means that you# should use very strong passwords, otherwise they will be very easy to break.# Note that because the password is really a shared secret between the client# and the server, and should not be memorized by any human, the password# can be easily a long string from /dev/urandom or whatever, so by using a# long and unguessable password no brute force attack will be possible.# Redis ACL users are defined in the following format:##   user &lt;username&gt; ... acl rules ...## For example:##   user worker +@list +@connection ~jobs:* on &gt;ffa9203c493aa99## The special username "default" is used for new connections. If this user# has the "nopass" rule, then new connections will be immediately authenticated# as the "default" user without the need of any password provided via the# AUTH command. Otherwise if the "default" user is not flagged with "nopass"# the connections will start in not authenticated state, and will require# AUTH (or the HELLO command AUTH option) in order to be authenticated and# start to work.## The ACL rules that describe what a user can do are the following:##  on           Enable the user: it is possible to authenticate as this user.#  off          Disable the user: it's no longer possible to authenticate#               with this user, however the already authenticated connections#               will still work.#  skip-sanitize-payload    RESTORE dump-payload sanitation is skipped.#  sanitize-payload         RESTORE dump-payload is sanitized (default).#  +&lt;command&gt;   Allow the execution of that command#  -&lt;command&gt;   Disallow the execution of that command#  +@&lt;category&gt; Allow the execution of all the commands in such category#               with valid categories are like @admin, @set, @sortedset, ...#               and so forth, see the full list in the server.c file where#               the Redis command table is described and defined.#               The special category @all means all the commands, but currently#               present in the server, and that will be loaded in the future#               via modules.#  +&lt;command&gt;|subcommand    Allow a specific subcommand of an otherwise#                           disabled command. Note that this form is not#                           allowed as negative like -DEBUG|SEGFAULT, but#                           only additive starting with "+".#  allcommands  Alias for +@all. Note that it implies the ability to execute#               all the future commands loaded via the modules system.#  nocommands   Alias for -@all.#  ~&lt;pattern&gt;   Add a pattern of keys that can be mentioned as part of#               commands. For instance ~* allows all the keys. The pattern#               is a glob-style pattern like the one of KEYS.#               It is possible to specify multiple patterns.#  allkeys      Alias for ~*#  resetkeys    Flush the list of allowed keys patterns.#  &amp;&lt;pattern&gt;   Add a glob-style pattern of Pub/Sub channels that can be#               accessed by the user. It is possible to specify multiple channel#               patterns.#  allchannels  Alias for &amp;*#  resetchannels            Flush the list of allowed channel patterns.#  &gt;&lt;password&gt;  Add this password to the list of valid password for the user.#               For example &gt;mypass will add "mypass" to the list.#               This directive clears the "nopass" flag (see later).#  &lt;&lt;password&gt;  Remove this password from the list of valid passwords.#  nopass       All the set passwords of the user are removed, and the user#               is flagged as requiring no password: it means that every#               password will work against this user. If this directive is#               used for the default user, every new connection will be#               immediately authenticated with the default user without#               any explicit AUTH command required. Note that the "resetpass"#               directive will clear this condition.#  resetpass    Flush the list of allowed passwords. Moreover removes the#               "nopass" status. After "resetpass" the user has no associated#               passwords and there is no way to authenticate without adding#               some password (or setting it as "nopass" later).#  reset        Performs the following actions: resetpass, resetkeys, off,#               -@all. The user returns to the same state it has immediately#               after its creation.## ACL rules can be specified in any order: for instance you can start with# passwords, then flags, or key patterns. However note that the additive# and subtractive rules will CHANGE MEANING depending on the ordering.# For instance see the following example:##   user alice on +@all -DEBUG ~* &gt;somepassword## This will allow "alice" to use all the commands with the exception of the# DEBUG command, since +@all added all the commands to the set of the commands# alice can use, and later DEBUG was removed. However if we invert the order# of two ACL rules the result will be different:##   user alice on -DEBUG +@all ~* &gt;somepassword## Now DEBUG was removed when alice had yet no commands in the set of allowed# commands, later all the commands are added, so the user will be able to# execute everything.## Basically ACL rules are processed left-to-right.## For more information about ACL configuration please refer to# the Redis web site at https://redis.io/topics/acl# ACL LOG## The ACL Log tracks failed commands and authentication events associated# with ACLs. The ACL Log is useful to troubleshoot failed commands blocked # by ACLs. The ACL Log is stored in memory. You can reclaim memory with # ACL LOG RESET. Define the maximum entry length of the ACL Log below.acllog-max-len 128# Using an external ACL file## Instead of configuring users here in this file, it is possible to use# a stand-alone file just listing users. The two methods cannot be mixed:# if you configure users here and at the same time you activate the external# ACL file, the server will refuse to start.## The format of the external ACL user file is exactly the same as the# format that is used inside redis.conf to describe users.## aclfile /etc/redis/users.acl# IMPORTANT NOTE: starting with Redis 6 "requirepass" is just a compatibility# layer on top of the new ACL system. The option effect will be just setting# the password for the default user. Clients will still authenticate using# AUTH &lt;password&gt; as usually, or more explicitly with AUTH default &lt;password&gt;# if they follow the new protocol: both will work.## The requirepass is not compatable with aclfile option and the ACL LOAD# command, these will cause requirepass to be ignored.#requirepass 956766# New users are initialized with restrictive permissions by default, via the# equivalent of this ACL rule 'off resetkeys -@all'. Starting with Redis 6.2, it# is possible to manage access to Pub/Sub channels with ACL rules as well. The# default Pub/Sub channels permission if new users is controlled by the # acl-pubsub-default configuration directive, which accepts one of these values:## allchannels: grants access to all Pub/Sub channels# resetchannels: revokes access to all Pub/Sub channels## To ensure backward compatibility while upgrading Redis 6.0, acl-pubsub-default# defaults to the 'allchannels' permission.## Future compatibility note: it is very likely that in a future version of Redis# the directive's default of 'allchannels' will be changed to 'resetchannels' in# order to provide better out-of-the-box Pub/Sub security. Therefore, it is# recommended that you explicitly define Pub/Sub permissions for all users# rather then rely on implicit default values. Once you've set explicit# Pub/Sub for all existing users, you should uncomment the following line.## acl-pubsub-default resetchannels# Command renaming (DEPRECATED).## ------------------------------------------------------------------------# WARNING: avoid using this option if possible. Instead use ACLs to remove# commands from the default user, and put them only in some admin user you# create for administrative purposes.# ------------------------------------------------------------------------## It is possible to change the name of dangerous commands in a shared# environment. For instance the CONFIG command may be renamed into something# hard to guess so that it will still be available for internal-use tools# but not available for general clients.## Example:## rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52## It is also possible to completely kill a command by renaming it into# an empty string:## rename-command CONFIG ""## Please note that changing the name of commands that are logged into the# AOF file or transmitted to replicas may cause problems.################################### CLIENTS ##################################### Set the max number of connected clients at the same time. By default# this limit is set to 10000 clients, however if the Redis server is not# able to configure the process file limit to allow for the specified limit# the max number of allowed clients is set to the current file limit# minus 32 (as Redis reserves a few file descriptors for internal uses).## Once the limit is reached Redis will close all the new connections sending# an error 'max number of clients reached'.## IMPORTANT: When Redis Cluster is used, the max number of connections is also# shared with the cluster bus: every node in the cluster will use two# connections, one incoming and another outgoing. It is important to size the# limit accordingly in case of very large clusters.## maxclients 10000############################## MEMORY MANAGEMENT ################################# Set a memory usage limit to the specified amount of bytes.# When the memory limit is reached Redis will try to remove keys# according to the eviction policy selected (see maxmemory-policy).## If Redis can't remove keys according to the policy, or if the policy is# set to 'noeviction', Redis will start to reply with errors to commands# that would use more memory, like SET, LPUSH, and so on, and will continue# to reply to read-only commands like GET.## This option is usually useful when using Redis as an LRU or LFU cache, or to# set a hard memory limit for an instance (using the 'noeviction' policy).## WARNING: If you have replicas attached to an instance with maxmemory on,# the size of the output buffers needed to feed the replicas are subtracted# from the used memory count, so that network problems / resyncs will# not trigger a loop where keys are evicted, and in turn the output# buffer of replicas is full with DELs of keys evicted triggering the deletion# of more keys, and so forth until the database is completely emptied.## In short... if you have replicas attached it is suggested that you set a lower# limit for maxmemory so that there is some free RAM on the system for replica# output buffers (but this is not needed if the policy is 'noeviction').## maxmemory &lt;bytes&gt;# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached. You can select one from the following behaviors:## volatile-lru -&gt; Evict using approximated LRU, only keys with an expire set.# allkeys-lru -&gt; Evict any key using approximated LRU.# volatile-lfu -&gt; Evict using approximated LFU, only keys with an expire set.# allkeys-lfu -&gt; Evict any key using approximated LFU.# volatile-random -&gt; Remove a random key having an expire set.# allkeys-random -&gt; Remove a random key, any key.# volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)# noeviction -&gt; Don't evict anything, just return an error on write operations.## LRU means Least Recently Used# LFU means Least Frequently Used## Both LRU, LFU and volatile-ttl are implemented using approximated# randomized algorithms.## Note: with any of the above policies, when there are no suitable keys for# eviction, Redis will return an error on write operations that require# more memory. These are usually commands that create new keys, add data or# modify existing keys. A few examples are: SET, INCR, HSET, LPUSH, SUNIONSTORE,# SORT (due to the STORE argument), and EXEC (if the transaction includes any# command that requires memory).## The default is:## maxmemory-policy noeviction# LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated# algorithms (in order to save memory), so you can tune it for speed or# accuracy. By default Redis will check five keys and pick the one that was# used least recently, you can change the sample size using the following# configuration directive.## The default of 5 produces good enough results. 10 Approximates very closely# true LRU but costs more CPU. 3 is faster but not very accurate.## maxmemory-samples 5# Eviction processing is designed to function well with the default setting.# If there is an unusually large amount of write traffic, this value may need to# be increased.  Decreasing this value may reduce latency at the risk of # eviction processing effectiveness#   0 = minimum latency, 10 = default, 100 = process without regard to latency## maxmemory-eviction-tenacity 10# Starting from Redis 5, by default a replica will ignore its maxmemory setting# (unless it is promoted to master after a failover or manually). It means# that the eviction of keys will be just handled by the master, sending the# DEL commands to the replica as keys evict in the master side.## This behavior ensures that masters and replicas stay consistent, and is usually# what you want, however if your replica is writable, or you want the replica# to have a different memory setting, and you are sure all the writes performed# to the replica are idempotent, then you may change this default (but be sure# to understand what you are doing).## Note that since the replica by default does not evict, it may end using more# memory than the one set via maxmemory (there are certain buffers that may# be larger on the replica, or data structures may sometimes take more memory# and so forth). So make sure you monitor your replicas and make sure they# have enough memory to never hit a real out-of-memory condition before the# master hits the configured maxmemory setting.## replica-ignore-maxmemory yes# Redis reclaims expired keys in two ways: upon access when those keys are# found to be expired, and also in background, in what is called the# "active expire key". The key space is slowly and interactively scanned# looking for expired keys to reclaim, so that it is possible to free memory# of keys that are expired and will never be accessed again in a short time.## The default effort of the expire cycle will try to avoid having more than# ten percent of expired keys still in memory, and will try to avoid consuming# more than 25% of total memory and to add latency to the system. However# it is possible to increase the expire "effort" that is normally set to# "1", to a greater value, up to the value "10". At its maximum value the# system will use more CPU, longer cycles (and technically may introduce# more latency), and will tolerate less already expired keys still present# in the system. It's a tradeoff between memory, CPU and latency.## active-expire-effort 1############################# LAZY FREEING ##################################### Redis has two primitives to delete keys. One is called DEL and is a blocking# deletion of the object. It means that the server stops processing new commands# in order to reclaim all the memory associated with an object in a synchronous# way. If the key deleted is associated with a small object, the time needed# in order to execute the DEL command is very small and comparable to most other# O(1) or O(log_N) commands in Redis. However if the key is associated with an# aggregated value containing millions of elements, the server can block for# a long time (even seconds) in order to complete the operation.## For the above reasons Redis also offers non blocking deletion primitives# such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and# FLUSHDB commands, in order to reclaim memory in background. Those commands# are executed in constant time. Another thread will incrementally free the# object in the background as fast as possible.## DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.# It's up to the design of the application to understand when it is a good# idea to use one or the other. However the Redis server sometimes has to# delete keys or flush the whole database as a side effect of other operations.# Specifically Redis deletes objects independently of a user call in the# following scenarios:## 1) On eviction, because of the maxmemory and maxmemory policy configurations,#    in order to make room for new data, without going over the specified#    memory limit.# 2) Because of expire: when a key with an associated time to live (see the#    EXPIRE command) must be deleted from memory.# 3) Because of a side effect of a command that stores data on a key that may#    already exist. For example the RENAME command may delete the old key#    content when it is replaced with another one. Similarly SUNIONSTORE#    or SORT with STORE option may delete existing keys. The SET command#    itself removes any old content of the specified key in order to replace#    it with the specified string.# 4) During replication, when a replica performs a full resynchronization with#    its master, the content of the whole database is removed in order to#    load the RDB file just transferred.## In all the above cases the default is to delete objects in a blocking way,# like if DEL was called. However you can configure each case specifically# in order to instead release memory in a non-blocking way like if UNLINK# was called, using the following configuration directives.lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noreplica-lazy-flush no# It is also possible, for the case when to replace the user code DEL calls# with UNLINK calls is not easy, to modify the default behavior of the DEL# command to act exactly like UNLINK, using the following configuration# directive:lazyfree-lazy-user-del no# FLUSHDB, FLUSHALL, and SCRIPT FLUSH support both asynchronous and synchronous# deletion, which can be controlled by passing the [SYNC|ASYNC] flags into the# commands. When neither flag is passed, this directive will be used to determine# if the data should be deleted asynchronously.lazyfree-lazy-user-flush no################################ THREADED I/O ################################## Redis is mostly single threaded, however there are certain threaded# operations such as UNLINK, slow I/O accesses and other things that are# performed on side threads.## Now it is also possible to handle Redis clients socket reads and writes# in different I/O threads. Since especially writing is so slow, normally# Redis users use pipelining in order to speed up the Redis performances per# core, and spawn multiple instances in order to scale more. Using I/O# threads it is possible to easily speedup two times Redis without resorting# to pipelining nor sharding of the instance.## By default threading is disabled, we suggest enabling it only in machines# that have at least 4 or more cores, leaving at least one spare core.# Using more than 8 threads is unlikely to help much. We also recommend using# threaded I/O only if you actually have performance problems, with Redis# instances being able to use a quite big percentage of CPU time, otherwise# there is no point in using this feature.## So for instance if you have a four cores boxes, try to use 2 or 3 I/O# threads, if you have a 8 cores, try to use 6 threads. In order to# enable I/O threads use the following configuration directive:## io-threads 4## Setting io-threads to 1 will just use the main thread as usual.# When I/O threads are enabled, we only use threads for writes, that is# to thread the write(2) syscall and transfer the client buffers to the# socket. However it is also possible to enable threading of reads and# protocol parsing using the following configuration directive, by setting# it to yes:## io-threads-do-reads no## Usually threading reads doesn't help much.## NOTE 1: This configuration directive cannot be changed at runtime via# CONFIG SET. Aso this feature currently does not work when SSL is# enabled.## NOTE 2: If you want to test the Redis speedup using redis-benchmark, make# sure you also run the benchmark itself in threaded mode, using the# --threads option to match the number of Redis threads, otherwise you'll not# be able to notice the improvements.############################ KERNEL OOM CONTROL ############################### On Linux, it is possible to hint the kernel OOM killer on what processes# should be killed first when out of memory.## Enabling this feature makes Redis actively control the oom_score_adj value# for all its processes, depending on their role. The default scores will# attempt to have background child processes killed before all others, and# replicas killed before masters.## Redis supports three options:## no:       Don't make changes to oom-score-adj (default).# yes:      Alias to "relative" see below.# absolute: Values in oom-score-adj-values are written as is to the kernel.# relative: Values are used relative to the initial value of oom_score_adj when#           the server starts and are then clamped to a range of -1000 to 1000.#           Because typically the initial value is 0, they will often match the#           absolute values.oom-score-adj no# When oom-score-adj is used, this directive controls the specific values used# for master, replica and background child processes. Values range -2000 to# 2000 (higher means more likely to be killed).## Unprivileged processes (not root, and without CAP_SYS_RESOURCE capabilities)# can freely increase their value, but not decrease it below its initial# settings. This means that setting oom-score-adj to "relative" and setting the# oom-score-adj-values to positive values will always succeed.oom-score-adj-values 0 200 800#################### KERNEL transparent hugepage CONTROL ####################### Usually the kernel Transparent Huge Pages control is set to "madvise" or# or "never" by default (/sys/kernel/mm/transparent_hugepage/enabled), in which# case this config has no effect. On systems in which it is set to "always",# redis will attempt to disable it specifically for the redis process in order# to avoid latency problems specifically with fork(2) and CoW.# If for some reason you prefer to keep it enabled, you can set this config to# "no" and the kernel global to "always".disable-thp yes############################## APPEND ONLY MODE ################################ By default Redis asynchronously dumps the dataset on disk. This mode is# good enough in many applications, but an issue with the Redis process or# a power outage may result into a few minutes of writes lost (depending on# the configured save points).## The Append Only File is an alternative persistence mode that provides# much better durability. For instance using the default data fsync policy# (see later in the config file) Redis can lose just one second of writes in a# dramatic event like a server power outage, or a single write if something# wrong with the Redis process itself happens, but the operating system is# still running correctly.## AOF and RDB persistence can be enabled at the same time without problems.# If the AOF is enabled on startup Redis will load the AOF, that is the file# with the better durability guarantees.## Please check https://redis.io/topics/persistence for more information.appendonly no# The name of the append only file (default: "appendonly.aof")appendfilename "appendonly.aof"# The fsync() call tells the Operating System to actually write data on disk# instead of waiting for more data in the output buffer. Some OS will really flush# data on disk, some other OS will just try to do it ASAP.## Redis supports three different modes:## no: don't fsync, just let the OS flush the data when it wants. Faster.# always: fsync after every write to the append only log. Slow, Safest.# everysec: fsync only one time every second. Compromise.## The default is "everysec", as that's usually the right compromise between# speed and data safety. It's up to you to understand if you can relax this to# "no" that will let the operating system flush the output buffer when# it wants, for better performances (but if you can live with the idea of# some data loss consider the default persistence mode that's snapshotting),# or on the contrary, use "always" that's very slow but a bit safer than# everysec.## More details please check the following article:# http://antirez.com/post/redis-persistence-demystified.html## If unsure, use "everysec".# appendfsync alwaysappendfsync everysec# appendfsync no# When the AOF fsync policy is set to always or everysec, and a background# saving process (a background save or AOF log background rewriting) is# performing a lot of I/O against the disk, in some Linux configurations# Redis may block too long on the fsync() call. Note that there is no fix for# this currently, as even performing fsync in a different thread will block# our synchronous write(2) call.## In order to mitigate this problem it's possible to use the following option# that will prevent fsync() from being called in the main process while a# BGSAVE or BGREWRITEAOF is in progress.## This means that while another child is saving, the durability of Redis is# the same as "appendfsync none". In practical terms, this means that it is# possible to lose up to 30 seconds of log in the worst scenario (with the# default Linux settings).## If you have latency problems turn this to "yes". Otherwise leave it as# "no" that is the safest pick from the point of view of durability.no-appendfsync-on-rewrite no# Automatic rewrite of the append only file.# Redis is able to automatically rewrite the log file implicitly calling# BGREWRITEAOF when the AOF log size grows by the specified percentage.## This is how it works: Redis remembers the size of the AOF file after the# latest rewrite (if no rewrite has happened since the restart, the size of# the AOF at startup is used).## This base size is compared to the current size. If the current size is# bigger than the specified percentage, the rewrite is triggered. Also# you need to specify a minimal size for the AOF file to be rewritten, this# is useful to avoid rewriting the AOF file even if the percentage increase# is reached but it is still pretty small.## Specify a percentage of zero in order to disable the automatic AOF# rewrite feature.auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# An AOF file may be found to be truncated at the end during the Redis# startup process, when the AOF data gets loaded back into memory.# This may happen when the system where Redis is running# crashes, especially when an ext4 filesystem is mounted without the# data=ordered option (however this can't happen when Redis itself# crashes or aborts but the operating system still works correctly).## Redis can either exit with an error when this happens, or load as much# data as possible (the default now) and start if the AOF file is found# to be truncated at the end. The following option controls this behavior.## If aof-load-truncated is set to yes, a truncated AOF file is loaded and# the Redis server starts emitting a log to inform the user of the event.# Otherwise if the option is set to no, the server aborts with an error# and refuses to start. When the option is set to no, the user requires# to fix the AOF file using the "redis-check-aof" utility before to restart# the server.## Note that if the AOF file will be found to be corrupted in the middle# the server will still exit with an error. This option only applies when# Redis will try to read more data from the AOF file but not enough bytes# will be found.aof-load-truncated yes# When rewriting the AOF file, Redis is able to use an RDB preamble in the# AOF file for faster rewrites and recoveries. When this option is turned# on the rewritten AOF file is composed of two different stanzas:##   [RDB file][AOF tail]## When loading, Redis recognizes that the AOF file starts with the "REDIS"# string and loads the prefixed RDB file, then continues loading the AOF# tail.aof-use-rdb-preamble yes################################ LUA SCRIPTING  ################################ Max execution time of a Lua script in milliseconds.## If the maximum execution time is reached Redis will log that a script is# still in execution after the maximum allowed time and will start to# reply to queries with an error.## When a long running script exceeds the maximum execution time only the# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be# used to stop a script that did not yet call any write commands. The second# is the only way to shut down the server in the case a write command was# already issued by the script but the user doesn't want to wait for the natural# termination of the script.## Set it to 0 or a negative value for unlimited execution without warnings.lua-time-limit 5000################################ REDIS CLUSTER  ################################ Normal Redis instances can't be part of a Redis Cluster; only nodes that are# started as cluster nodes can. In order to start a Redis instance as a# cluster node enable the cluster support uncommenting the following:## cluster-enabled yes# Every cluster node has a cluster configuration file. This file is not# intended to be edited by hand. It is created and updated by Redis nodes.# Every Redis Cluster node requires a different cluster configuration file.# Make sure that instances running in the same system do not have# overlapping cluster configuration file names.## cluster-config-file nodes-6379.conf# Cluster node timeout is the amount of milliseconds a node must be unreachable# for it to be considered in failure state.# Most other internal time limits are a multiple of the node timeout.## cluster-node-timeout 15000# A replica of a failing master will avoid to start a failover if its data# looks too old.## There is no simple way for a replica to actually have an exact measure of# its "data age", so the following two checks are performed:## 1) If there are multiple replicas able to failover, they exchange messages#    in order to try to give an advantage to the replica with the best#    replication offset (more data from the master processed).#    Replicas will try to get their rank by offset, and apply to the start#    of the failover a delay proportional to their rank.## 2) Every single replica computes the time of the last interaction with#    its master. This can be the last ping or command received (if the master#    is still in the "connected" state), or the time that elapsed since the#    disconnection with the master (if the replication link is currently down).#    If the last interaction is too old, the replica will not try to failover#    at all.## The point "2" can be tuned by user. Specifically a replica will not perform# the failover if, since the last interaction with the master, the time# elapsed is greater than:##   (node-timeout * cluster-replica-validity-factor) + repl-ping-replica-period## So for example if node-timeout is 30 seconds, and the cluster-replica-validity-factor# is 10, and assuming a default repl-ping-replica-period of 10 seconds, the# replica will not try to failover if it was not able to talk with the master# for longer than 310 seconds.## A large cluster-replica-validity-factor may allow replicas with too old data to failover# a master, while a too small value may prevent the cluster from being able to# elect a replica at all.## For maximum availability, it is possible to set the cluster-replica-validity-factor# to a value of 0, which means, that replicas will always try to failover the# master regardless of the last time they interacted with the master.# (However they'll always try to apply a delay proportional to their# offset rank).## Zero is the only value able to guarantee that when all the partitions heal# the cluster will always be able to continue.## cluster-replica-validity-factor 10# Cluster replicas are able to migrate to orphaned masters, that are masters# that are left without working replicas. This improves the cluster ability# to resist to failures as otherwise an orphaned master can't be failed over# in case of failure if it has no working replicas.## Replicas migrate to orphaned masters only if there are still at least a# given number of other working replicas for their old master. This number# is the "migration barrier". A migration barrier of 1 means that a replica# will migrate only if there is at least 1 other working replica for its master# and so forth. It usually reflects the number of replicas you want for every# master in your cluster.## Default is 1 (replicas migrate only if their masters remain with at least# one replica). To disable migration just set it to a very large value or# set cluster-allow-replica-migration to 'no'.# A value of 0 can be set but is useful only for debugging and dangerous# in production.## cluster-migration-barrier 1# Turning off this option allows to use less automatic cluster configuration.# It both disables migration to orphaned masters and migration from masters# that became empty.## Default is 'yes' (allow automatic migrations).## cluster-allow-replica-migration yes# By default Redis Cluster nodes stop accepting queries if they detect there# is at least a hash slot uncovered (no available node is serving it).# This way if the cluster is partially down (for example a range of hash slots# are no longer covered) all the cluster becomes, eventually, unavailable.# It automatically returns available as soon as all the slots are covered again.## However sometimes you want the subset of the cluster which is working,# to continue to accept queries for the part of the key space that is still# covered. In order to do so, just set the cluster-require-full-coverage# option to no.## cluster-require-full-coverage yes# This option, when set to yes, prevents replicas from trying to failover its# master during master failures. However the replica can still perform a# manual failover, if forced to do so.## This is useful in different scenarios, especially in the case of multiple# data center operations, where we want one side to never be promoted if not# in the case of a total DC failure.## cluster-replica-no-failover no# This option, when set to yes, allows nodes to serve read traffic while the# the cluster is in a down state, as long as it believes it owns the slots. ## This is useful for two cases.  The first case is for when an application # doesn't require consistency of data during node failures or network partitions.# One example of this is a cache, where as long as the node has the data it# should be able to serve it. ## The second use case is for configurations that don't meet the recommended  # three shards but want to enable cluster mode and scale later. A # master outage in a 1 or 2 shard configuration causes a read/write outage to the# entire cluster without this option set, with it set there is only a write outage.# Without a quorum of masters, slot ownership will not change automatically. ## cluster-allow-reads-when-down no# In order to setup your cluster make sure to read the documentation# available at https://redis.io web site.########################## CLUSTER DOCKER/NAT support  ######################### In certain deployments, Redis Cluster nodes address discovery fails, because# addresses are NAT-ted or because ports are forwarded (the typical case is# Docker and other containers).## In order to make Redis Cluster working in such environments, a static# configuration where each node knows its public address is needed. The# following four options are used for this scope, and are:## * cluster-announce-ip# * cluster-announce-port# * cluster-announce-tls-port# * cluster-announce-bus-port## Each instructs the node about its address, client ports (for connections# without and with TLS) and cluster message bus port. The information is then# published in the header of the bus packets so that other nodes will be able to# correctly map the address of the node publishing the information.## If cluster-tls is set to yes and cluster-announce-tls-port is omitted or set# to zero, then cluster-announce-port refers to the TLS port. Note also that# cluster-announce-tls-port has no effect if cluster-tls is set to no.## If the above options are not used, the normal Redis Cluster auto-detection# will be used instead.## Note that when remapped, the bus port may not be at the fixed offset of# clients port + 10000, so you can specify any port and bus-port depending# on how they get remapped. If the bus-port is not set, a fixed offset of# 10000 will be used as usual.## Example:## cluster-announce-ip 10.1.1.5# cluster-announce-tls-port 6379# cluster-announce-port 0# cluster-announce-bus-port 6380################################## SLOW LOG #################################### The Redis Slow Log is a system to log queries that exceeded a specified# execution time. The execution time does not include the I/O operations# like talking with the client, sending the reply and so forth,# but just the time needed to actually execute the command (this is the only# stage of command execution where the thread is blocked and can not serve# other requests in the meantime).## You can configure the slow log with two parameters: one tells Redis# what is the execution time, in microseconds, to exceed in order for the# command to get logged, and the other parameter is the length of the# slow log. When a new command is logged the oldest one is removed from the# queue of logged commands.# The following time is expressed in microseconds, so 1000000 is equivalent# to one second. Note that a negative number disables the slow log, while# a value of zero forces the logging of every command.slowlog-log-slower-than 10000# There is no limit to this length. Just be aware that it will consume memory.# You can reclaim memory used by the slow log with SLOWLOG RESET.slowlog-max-len 128################################ LATENCY MONITOR ############################### The Redis latency monitoring subsystem samples different operations# at runtime in order to collect data related to possible sources of# latency of a Redis instance.## Via the LATENCY command this information is available to the user that can# print graphs and obtain reports.## The system only logs operations that were performed in a time equal or# greater than the amount of milliseconds specified via the# latency-monitor-threshold configuration directive. When its value is set# to zero, the latency monitor is turned off.## By default latency monitoring is disabled since it is mostly not needed# if you don't have latency issues, and collecting data has a performance# impact, that while very small, can be measured under big load. Latency# monitoring can easily be enabled at runtime using the command# "CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;" if needed.latency-monitor-threshold 0############################# EVENT NOTIFICATION ############################### Redis can notify Pub/Sub clients about events happening in the key space.# This feature is documented at https://redis.io/topics/notifications## For instance if keyspace events notification is enabled, and a client# performs a DEL operation on key "foo" stored in the Database 0, two# messages will be published via Pub/Sub:## PUBLISH __keyspace@0__:foo del# PUBLISH __keyevent@0__:del foo## It is possible to select the events that Redis will notify among a set# of classes. Every class is identified by a single character:##  K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.#  E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...#  $     String commands#  l     List commands#  s     Set commands#  h     Hash commands#  z     Sorted set commands#  x     Expired events (events generated every time a key expires)#  e     Evicted events (events generated when a key is evicted for maxmemory)#  t     Stream commands#  d     Module key type events#  m     Key-miss events (Note: It is not included in the 'A' class)#  A     Alias for g$lshzxetd, so that the "AKE" string means all the events#        (Except key-miss events which are excluded from 'A' due to their#         unique nature).##  The "notify-keyspace-events" takes as argument a string that is composed#  of zero or multiple characters. The empty string means that notifications#  are disabled.##  Example: to enable list and generic events, from the point of view of the#           event name, use:##  notify-keyspace-events Elg##  Example 2: to get the stream of the expired keys subscribing to channel#             name __keyevent@0__:expired use:##  notify-keyspace-events Ex##  By default all notifications are disabled because most users don't need#  this feature and the feature has some overhead. Note that if you don't#  specify at least one of K or E, no events will be delivered.notify-keyspace-events ""############################### GOPHER SERVER ################################## Redis contains an implementation of the Gopher protocol, as specified in# the RFC 1436 (https://www.ietf.org/rfc/rfc1436.txt).## The Gopher protocol was very popular in the late '90s. It is an alternative# to the web, and the implementation both server and client side is so simple# that the Redis server has just 100 lines of code in order to implement this# support.## What do you do with Gopher nowadays? Well Gopher never *really* died, and# lately there is a movement in order for the Gopher more hierarchical content# composed of just plain text documents to be resurrected. Some want a simpler# internet, others believe that the mainstream internet became too much# controlled, and it's cool to create an alternative space for people that# want a bit of fresh air.## Anyway for the 10nth birthday of the Redis, we gave it the Gopher protocol# as a gift.## --- HOW IT WORKS? ---## The Redis Gopher support uses the inline protocol of Redis, and specifically# two kind of inline requests that were anyway illegal: an empty request# or any request that starts with "/" (there are no Redis commands starting# with such a slash). Normal RESP2/RESP3 requests are completely out of the# path of the Gopher protocol implementation and are served as usual as well.## If you open a connection to Redis when Gopher is enabled and send it# a string like "/foo", if there is a key named "/foo" it is served via the# Gopher protocol.## In order to create a real Gopher "hole" (the name of a Gopher site in Gopher# talking), you likely need a script like the following:##   https://github.com/antirez/gopher2redis## --- SECURITY WARNING ---## If you plan to put Redis on the internet in a publicly accessible address# to server Gopher pages MAKE SURE TO SET A PASSWORD to the instance.# Once a password is set:##   1. The Gopher server (when enabled, not by default) will still serve#      content via Gopher.#   2. However other commands cannot be called before the client will#      authenticate.## So use the 'requirepass' option to protect your instance.## Note that Gopher is not currently supported when 'io-threads-do-reads'# is enabled.## To enable Gopher support, uncomment the following line and set the option# from no (the default) to yes.## gopher-enabled no############################### ADVANCED CONFIG ################################ Hashes are encoded using a memory efficient data structure when they have a# small number of entries, and the biggest entry does not exceed a given# threshold. These thresholds can be configured using the following directives.hash-max-ziplist-entries 512hash-max-ziplist-value 64# Lists are also encoded in a special way to save a lot of space.# The number of entries allowed per internal list node can be specified# as a fixed maximum size or a maximum number of elements.# For a fixed maximum size, use -5 through -1, meaning:# -5: max size: 64 Kb  &lt;-- not recommended for normal workloads# -4: max size: 32 Kb  &lt;-- not recommended# -3: max size: 16 Kb  &lt;-- probably not recommended# -2: max size: 8 Kb   &lt;-- good# -1: max size: 4 Kb   &lt;-- good# Positive numbers mean store up to _exactly_ that number of elements# per list node.# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),# but if your use case is unique, adjust the settings as necessary.list-max-ziplist-size -2# Lists may also be compressed.# Compress depth is the number of quicklist ziplist nodes from *each* side of# the list to *exclude* from compression.  The head and tail of the list# are always uncompressed for fast push/pop operations.  Settings are:# 0: disable all list compression# 1: depth 1 means "don't start compressing until after 1 node into the list,#    going from either the head or tail"#    So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]#    [head], [tail] will always be uncompressed; inner nodes will compress.# 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]#    2 here means: don't compress head or head-&gt;next or tail-&gt;prev or tail,#    but compress all nodes between them.# 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]# etc.list-compress-depth 0# Sets have a special encoding in just one case: when a set is composed# of just strings that happen to be integers in radix 10 in the range# of 64 bit signed integers.# The following configuration setting sets the limit in the size of the# set in order to use this special memory saving encoding.set-max-intset-entries 512# Similarly to hashes and lists, sorted sets are also specially encoded in# order to save a lot of space. This encoding is only used when the length and# elements of a sorted set are below the following limits:zset-max-ziplist-entries 128zset-max-ziplist-value 64# HyperLogLog sparse representation bytes limit. The limit includes the# 16 bytes header. When an HyperLogLog using the sparse representation crosses# this limit, it is converted into the dense representation.## A value greater than 16000 is totally useless, since at that point the# dense representation is more memory efficient.## The suggested value is ~ 3000 in order to have the benefits of# the space efficient encoding without slowing down too much PFADD,# which is O(N) with the sparse encoding. The value can be raised to# ~ 10000 when CPU is not a concern, but space is, and the data set is# composed of many HyperLogLogs with cardinality in the 0 - 15000 range.hll-sparse-max-bytes 3000# Streams macro node max size / items. The stream data structure is a radix# tree of big nodes that encode multiple items inside. Using this configuration# it is possible to configure how big a single node can be in bytes, and the# maximum number of items it may contain before switching to a new node when# appending new stream entries. If any of the following settings are set to# zero, the limit is ignored, so for instance it is possible to set just a# max entries limit by setting max-bytes to 0 and max-entries to the desired# value.stream-node-max-bytes 4096stream-node-max-entries 100# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in# order to help rehashing the main Redis hash table (the one mapping top-level# keys to values). The hash table implementation Redis uses (see dict.c)# performs a lazy rehashing: the more operation you run into a hash table# that is rehashing, the more rehashing "steps" are performed, so if the# server is idle the rehashing is never complete and some more memory is used# by the hash table.## The default is to use this millisecond 10 times every second in order to# actively rehash the main dictionaries, freeing memory when possible.## If unsure:# use "activerehashing no" if you have hard latency requirements and it is# not a good thing in your environment that Redis can reply from time to time# to queries with 2 milliseconds delay.## use "activerehashing yes" if you don't have such hard requirements but# want to free memory asap when possible.activerehashing yes# The client output buffer limits can be used to force disconnection of clients# that are not reading data from the server fast enough for some reason (a# common reason is that a Pub/Sub client can't consume messages as fast as the# publisher can produce them).## The limit can be set differently for the three different classes of clients:## normal -&gt; normal clients including MONITOR clients# replica  -&gt; replica clients# pubsub -&gt; clients subscribed to at least one pubsub channel or pattern## The syntax of every client-output-buffer-limit directive is the following:## client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;## A client is immediately disconnected once the hard limit is reached, or if# the soft limit is reached and remains reached for the specified number of# seconds (continuously).# So for instance if the hard limit is 32 megabytes and the soft limit is# 16 megabytes / 10 seconds, the client will get disconnected immediately# if the size of the output buffers reach 32 megabytes, but will also get# disconnected if the client reaches 16 megabytes and continuously overcomes# the limit for 10 seconds.## By default normal clients are not limited because they don't receive data# without asking (in a push way), but just after a request, so only# asynchronous clients may create a scenario where data is requested faster# than it can read.## Instead there is a default limit for pubsub and replica clients, since# subscribers and replicas receive data in a push fashion.## Both the hard or the soft limit can be disabled by setting them to zero.client-output-buffer-limit normal 0 0 0client-output-buffer-limit replica 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# Client query buffers accumulate new commands. They are limited to a fixed# amount by default in order to avoid that a protocol desynchronization (for# instance due to a bug in the client) will lead to unbound memory usage in# the query buffer. However you can configure it here if you have very special# needs, such us huge multi/exec requests or alike.## client-query-buffer-limit 1gb# In the Redis protocol, bulk requests, that are, elements representing single# strings, are normally limited to 512 mb. However you can change this limit# here, but must be 1mb or greater## proto-max-bulk-len 512mb# Redis calls an internal function to perform many background tasks, like# closing connections of clients in timeout, purging expired keys that are# never requested, and so forth.## Not all tasks are performed with the same frequency, but Redis checks for# tasks to perform according to the specified "hz" value.## By default "hz" is set to 10. Raising the value will use more CPU when# Redis is idle, but at the same time will make Redis more responsive when# there are many keys expiring at the same time, and timeouts may be# handled with more precision.## The range is between 1 and 500, however a value over 100 is usually not# a good idea. Most users should use the default of 10 and raise this up to# 100 only in environments where very low latency is required.hz 10# Normally it is useful to have an HZ value which is proportional to the# number of clients connected. This is useful in order, for instance, to# avoid too many clients are processed for each background task invocation# in order to avoid latency spikes.## Since the default HZ value by default is conservatively set to 10, Redis# offers, and enables by default, the ability to use an adaptive HZ value# which will temporarily raise when there are many connected clients.## When dynamic HZ is enabled, the actual configured HZ will be used# as a baseline, but multiples of the configured HZ value will be actually# used as needed once more clients are connected. In this way an idle# instance will use very little CPU time while a busy instance will be# more responsive.dynamic-hz yes# When a child rewrites the AOF file, if the following option is enabled# the file will be fsync-ed every 32 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.aof-rewrite-incremental-fsync yes# When redis saves RDB file, if the following option is enabled# the file will be fsync-ed every 32 MB of data generated. This is useful# in order to commit the file to the disk more incrementally and avoid# big latency spikes.rdb-save-incremental-fsync yes# Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good# idea to start with the default settings and only change them after investigating# how to improve the performances and how the keys LFU change over time, which# is possible to inspect via the OBJECT FREQ command.## There are two tunable parameters in the Redis LFU implementation: the# counter logarithm factor and the counter decay time. It is important to# understand what the two parameters mean before changing them.## The LFU counter is just 8 bits per key, it's maximum value is 255, so Redis# uses a probabilistic increment with logarithmic behavior. Given the value# of the old counter, when a key is accessed, the counter is incremented in# this way:## 1. A random number R between 0 and 1 is extracted.# 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).# 3. The counter is incremented only if R &lt; P.## The default lfu-log-factor is 10. This is a table of how the frequency# counter changes with a different number of accesses with different# logarithmic factors:## +--------+------------+------------+------------+------------+------------+# | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |# +--------+------------+------------+------------+------------+------------+# | 0      | 104        | 255        | 255        | 255        | 255        |# +--------+------------+------------+------------+------------+------------+# | 1      | 18         | 49         | 255        | 255        | 255        |# +--------+------------+------------+------------+------------+------------+# | 10     | 10         | 18         | 142        | 255        | 255        |# +--------+------------+------------+------------+------------+------------+# | 100    | 8          | 11         | 49         | 143        | 255        |# +--------+------------+------------+------------+------------+------------+## NOTE: The above table was obtained by running the following commands:##   redis-benchmark -n 1000000 incr foo#   redis-cli object freq foo## NOTE 2: The counter initial value is 5 in order to give new objects a chance# to accumulate hits.## The counter decay time is the time, in minutes, that must elapse in order# for the key counter to be divided by two (or decremented if it has a value# less &lt;= 10).## The default value for the lfu-decay-time is 1. A special value of 0 means to# decay the counter every time it happens to be scanned.## lfu-log-factor 10# lfu-decay-time 1########################### ACTIVE DEFRAGMENTATION ######################### What is active defragmentation?# -------------------------------## Active (online) defragmentation allows a Redis server to compact the# spaces left between small allocations and deallocations of data in memory,# thus allowing to reclaim back memory.## Fragmentation is a natural process that happens with every allocator (but# less so with Jemalloc, fortunately) and certain workloads. Normally a server# restart is needed in order to lower the fragmentation, or at least to flush# away all the data and create it again. However thanks to this feature# implemented by Oran Agra for Redis 4.0 this process can happen at runtime# in a "hot" way, while the server is running.## Basically when the fragmentation is over a certain level (see the# configuration options below) Redis will start to create new copies of the# values in contiguous memory regions by exploiting certain specific Jemalloc# features (in order to understand if an allocation is causing fragmentation# and to allocate it in a better place), and at the same time, will release the# old copies of the data. This process, repeated incrementally for all the keys# will cause the fragmentation to drop back to normal values.## Important things to understand:## 1. This feature is disabled by default, and only works if you compiled Redis#    to use the copy of Jemalloc we ship with the source code of Redis.#    This is the default with Linux builds.## 2. You never need to enable this feature if you don't have fragmentation#    issues.## 3. Once you experience fragmentation, you can enable this feature when#    needed with the command "CONFIG SET activedefrag yes".## The configuration parameters are able to fine tune the behavior of the# defragmentation process. If you are not sure about what they mean it is# a good idea to leave the defaults untouched.# Enabled active defragmentation# activedefrag no# Minimum amount of fragmentation waste to start active defrag# active-defrag-ignore-bytes 100mb# Minimum percentage of fragmentation to start active defrag# active-defrag-threshold-lower 10# Maximum percentage of fragmentation at which we use maximum effort# active-defrag-threshold-upper 100# Minimal effort for defrag in CPU percentage, to be used when the lower# threshold is reached# active-defrag-cycle-min 1# Maximal effort for defrag in CPU percentage, to be used when the upper# threshold is reached# active-defrag-cycle-max 25# Maximum number of set/hash/zset/list fields that will be processed from# the main dictionary scan# active-defrag-max-scan-fields 1000# Jemalloc background thread for purging will be enabled by defaultjemalloc-bg-thread yes# It is possible to pin different threads and processes of Redis to specific# CPUs in your system, in order to maximize the performances of the server.# This is useful both in order to pin different Redis threads in different# CPUs, but also in order to make sure that multiple Redis instances running# in the same host will be pinned to different CPUs.## Normally you can do this using the "taskset" command, however it is also# possible to this via Redis configuration directly, both in Linux and FreeBSD.## You can pin the server/IO threads, bio threads, aof rewrite child process, and# the bgsave child process. The syntax to specify the cpu list is the same as# the taskset command:## Set redis server/io threads to cpu affinity 0,2,4,6:# server_cpulist 0-7:2## Set bio threads to cpu affinity 1,3:# bio_cpulist 1,3## Set aof rewrite child process to cpu affinity 8,9,10,11:# aof_rewrite_cpulist 8-11## Set bgsave child process to cpu affinity 1,10,11# bgsave_cpulist 1,10-11# In some cases redis will emit warnings and even refuse to start if it detects# that the system is in bad state, it is possible to suppress these warnings# by setting the following config which takes a space delimited list of warnings# to suppress#</code></pre><p>今天先不写技术文了，水一下博客。</p><p>说说最近发生的事情吧，还是疫情原因，前段时间被封在宿舍，现在虽然能出去宿舍，但也是线上上课，快递和外卖也都不能拿，唉。</p><p>说一下我为什么会想要水博客吧，原因之一，最近一直在宿舍，补专业课，后端学习方面有些许搁置，再加上学了几天四级，最后却没报上四级，这个属实是有点让人难受。</p><p>还有就是我今早上没吃饭，提不起精力来写技术文了，现在只想去干饭，但还不到吃饭的时间，也还没下班，唉。</p><p>啊，好难受。</p><p>呜呜呜呜，再补一点，昨天中午（也就是10.30日中午），我被骗走了三十元巨款，没想到我有生之年还会被诈骗，可恶的骗子，呜呜呜呜呜呜，我的三十元巨款啊，呜呜呜呜呜呜呜。</p><p>呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜。</p><p>这几天过的好难受啊呜呜呜呜呜呜，快递也不能拿，还想再买点东西，都被告知快递不支持所在地区呜呜呜呜呜呜呜，我的生活啊，呜呜呜呜呜呜，被疫情搞得一团糟呜呜呜呜呜呜呜呜，可恶的疫情，赶紧见鬼去吧！</p><p>呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜呜。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 经验分享 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git在idea中的使用+终止端口进程mac</title>
      <link href="/2022/10/21/git%E5%9C%A8idea%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8+%E7%BB%88%E6%AD%A2%E7%AB%AF%E5%8F%A3%E8%BF%9B%E7%A8%8Bmac/"/>
      <url>/2022/10/21/git%E5%9C%A8idea%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8+%E7%BB%88%E6%AD%A2%E7%AB%AF%E5%8F%A3%E8%BF%9B%E7%A8%8Bmac/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1 id="git在idea中的使用"><a href="#git在idea中的使用" class="headerlink" title="git在idea中的使用"></a>git在idea中的使用</h1><p>推荐博客：</p><p><a href="https://blog.csdn.net/Hubery_sky/article/details/124370803?spm=1001.2014.3001.5502" title="提交到远程仓库_雾喔的博客-CSDN博客_提交到远程仓库">提交到远程仓库_雾喔的博客-CSDN博客_提交到远程仓库</a></p><p><a href="https://blog.csdn.net/weixin_43252521/article/details/123959391?spm=1001.2014.3001.5506" title="在 IDEA 中使用 Git 图文教程_华仔仔coding的博客-CSDN博客_idea git">在 IDEA 中使用 Git 图文教程_华仔仔coding的博客-CSDN博客_idea git</a></p><p><strong>获取git仓库：</strong></p><p>方式一：</p><p>在终端输入</p><pre><code>git clone 你的仓库地址</code></pre><p>方式二：</p><p><img src="https://img-blog.csdnimg.cn/4869b518f85c40aab30b82e251840fdb.png"></p><p><img src="https://img-blog.csdnimg.cn/7a28af674a5c467f8d2060c584241eac.png"></p><p>方式三：</p><p>在项目里面打开</p><p><img src="https://img-blog.csdnimg.cn/b4cedc21ff914645ad04a6628bda19b7.png"></p><p>&nbsp;<img src="https://img-blog.csdnimg.cn/7a28af674a5c467f8d2060c584241eac.png"></p><p>查看历史版本：</p><p><img src="https://img-blog.csdnimg.cn/d1432a3a888b485b9213a10f01ee51f7.png"></p><h1 id="mac终止端口进程（以8080为例）"><a href="#mac终止端口进程（以8080为例）" class="headerlink" title="mac终止端口进程（以8080为例）"></a>mac终止端口进程（以8080为例）</h1><pre><code>lsof -i:8080</code></pre><p>关闭端口进程：</p><pre><code>kill -9 记录下的pid值</code></pre><h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>目前个人博客搭建中，这两天在学习linux，顺便给个人博客搭建了一小部分，看到其他孩子的个人博客，我狠狠的羡慕了，哇呜呜呜呜呜呜。</p><p>再加上我只是一个后端，只能各种网站找模板，唉，狠狠的羡慕了别人的模板了。</p><p>还有就是，我真闲。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> macos 1024程序员节 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅聊一下Stream流</title>
      <link href="/2022/10/13/%E6%B5%85%E8%81%8A%E4%B8%80%E4%B8%8BStream%E6%B5%81/"/>
      <url>/2022/10/13/%E6%B5%85%E8%81%8A%E4%B8%80%E4%B8%8BStream%E6%B5%81/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>目录</strong></p><p><a href="#%E9%80%9A%E8%BF%87stream%E8%8E%B7%E5%8F%96%E9%9B%86%E5%90%88%E4%B8%AD%E6%8C%87%E5%AE%9A%E6%95%B0%E6%8D%AE%EF%BC%9A">通过stream获取集合中指定数据：</a></p><p><a href="#%E8%8E%B7%E5%8F%96%E6%B5%81%EF%BC%9A">获取流：</a></p><p><a href="#stream%E6%B5%81%E4%B8%AD%E7%9A%84foreach%E6%96%B9%E6%B3%95%EF%BC%9A">stream流中的foreach方法：</a></p><p><a href="#stream%E6%B5%81%E4%B8%AD%E7%9A%84filter%E6%96%B9%E6%B3%95%EF%BC%9A">stream流中的filter方法：</a></p><p><a href="#stream%E6%B5%81%E4%B8%AD%E7%9A%84limit%E6%96%B9%E6%B3%95%EF%BC%9A">stream流中的limit方法：</a></p><p><a href="#stream%E6%B5%81%E4%B8%AD%E7%9A%84skip%E6%96%B9%E6%B3%95%EF%BC%9A">stream流中的skip方法：</a></p><p><a href="#%C2%A0Stream%E6%B5%81%E4%B8%AD%E7%9A%84map%E6%96%B9%E6%B3%95%EF%BC%9A">&nbsp;Stream流中的map方法：</a></p><p><a href="#stream%E6%B5%81%E4%B8%AD%E7%9A%84sorted%E6%96%B9%E6%B3%95%EF%BC%9A">stream流中的sorted方法：</a></p><p><a href="#Stream%E6%B5%81%E4%B8%AD%E7%9A%84distinct%E6%96%B9%E6%B3%95%EF%BC%9A">Stream流中的distinct方法：</a></p><p><a href="#Stream%E6%B5%81%E7%9A%84match%E6%96%B9%E6%B3%95%EF%BC%9A">Stream流的match方法：</a></p><p><a href="#Stream%E6%B5%81%E7%9A%84find%E6%96%B9%E6%B3%95%EF%BC%9A">Stream流的find方法：</a></p><p><a href="#Stream%E6%B5%81%E4%B8%AD%E7%9A%84max%E5%92%8Cmin%E6%96%B9%E6%B3%95%EF%BC%9A">Stream流中的max和min方法：</a></p><p><a href="#%C2%A0Stream%E6%B5%81%E7%9A%84reduce%E6%96%B9%E6%B3%95%EF%BC%9A">&nbsp;Stream流的reduce方法：</a></p><p><a href="#Stream%E7%9A%84concat%E6%96%B9%E6%B3%95%EF%BC%9A">Stream的concat方法：</a></p><p><a href="#Stream%E5%B0%8F%E7%BB%83%E4%B9%A0%EF%BC%9A">Stream小练习：</a></p><p><a href="#%E5%B0%86%E6%B5%81%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%B0%E9%9B%86%E5%90%88%E4%B8%AD%EF%BC%9A">将流中的数据收集到集合中：</a></p><p><a href="#%E5%B0%86%E6%B5%81%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%88%B0%E6%95%B0%E7%BB%84%E4%B8%AD%EF%BC%9A">将流中的数据收集到数组中：</a></p><p><a href="#%E5%AF%B9%E6%B5%81%E4%B8%AD%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E8%81%9A%E5%90%88%E8%BF%90%E7%AE%97%EF%BC%9A">对流中数据进行聚合运算：</a></p><p><a href="#%E5%AF%B9%E6%B5%81%E4%B8%AD%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E5%88%86%E7%BB%84%EF%BC%9A">对流中数据进行分组：</a></p><p><a href="#%C2%A0%E5%A4%9A%E7%BA%A7%E5%88%86%E7%BB%84%EF%BC%9A">&nbsp;多级分组：</a></p><p><a href="#%E5%AF%B9%E6%B5%81%E4%B8%AD%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E6%8B%BC%E6%8E%A5%EF%BC%9A">对流中数据进行拼接：</a></p><p><a href="#Optional%E7%B1%BB%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%EF%BC%9A">Optional类的基本使用：</a></p><hr><p>参考：<a href="https://www.bilibili.com/video/BV1zJ411R7uQ/?vd_source=c75e68fd099206ad9761f2134ce79ce2">https://www.bilibili.com/video/BV1zJ411R7uQ/?vd_source=c75e68fd099206ad9761f2134ce79ce2</a></p><p>推荐博客：<a href="https://blog.csdn.net/Msxd_/article/details/107805372?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~OPENSEARCH~Rate-1-107805372-blog-127167041.pc_relevant_multi_platform_whitelistv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~OPENSEARCH~Rate-1-107805372-blog-127167041.pc_relevant_multi_platform_whitelistv3&amp;utm_relevant_index=2" title="恕我直言，我怀疑你没怎么用过Stream流">恕我直言，我怀疑你没怎么用过Stream流</a></p><p>我的是直接实战演示，大家想要知道概念什么的话可以参考一下上面的博客。</p><p><strong>下面的内容写的可能比较混乱</strong></p><p><img src="https://img-blog.csdnimg.cn/dae6e485671746a39a8413302480f6a4.png"></p><h3 id="通过stream获取集合中指定数据："><a href="#通过stream获取集合中指定数据：" class="headerlink" title="通过stream获取集合中指定数据："></a><strong>通过stream获取集合中指定数据：</strong></h3><pre><code class="java">package com.jdktest01.day02;import java.util.ArrayList;import java.util.Collections;/** * @author a1002 */public class StreamTest01 {    public static void main(String[] args) {        ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;();        Collections.addAll(list, "张无忌", "周芷若", "赵敏", "张三丰", "师太", "韦小宝", "康熙");        ArrayList&lt;String&gt; zhangList = new ArrayList&lt;&gt;();        list.stream()                .filter((s) -&gt; {                    return s.startsWith("张");                })                .filter((s) -&gt; {                    return s.length() == 3;                })                //遍历                .forEach((s) -&gt; {                    System.out.println(s);                    System.out.println(s.length());                    //添加到集合中                    zhangList.add(s);                });        System.out.println("=========================");        //拿到所有姓张的且长度为3的        //集合遍历        System.out.println(zhangList);        System.out.println("---------------------------");        list.forEach(System.out::println);    }}</code></pre><h3 id="获取流："><a href="#获取流：" class="headerlink" title="获取流："></a><strong>获取流：</strong></h3><pre><code class="java">package com.jdktest01.day02;import java.util.*;import java.util.stream.Stream;/** * @author a1002 */public class StreamTest03 {    public static void main(String[] args) {        // 方式1 : 根据Collection获取流        // Collection接口中有一个默认的方法: default Stream&lt;E&gt; stream()        List&lt;String&gt; list = new ArrayList&lt;&gt;();        Stream&lt;String&gt; stream1 = list.stream();        Set&lt;String&gt; set = new HashSet&lt;&gt;();        Stream&lt;String&gt; stream2 = set.stream();        Map&lt;String, String&gt; map = new HashMap&lt;&gt;();        Stream&lt;String&gt; stream3 = map.keySet().stream();        Stream&lt;String&gt; stream4 = map.values().stream();        Stream&lt;Map.Entry&lt;String, String&gt;&gt; stream5 = map.entrySet().stream();        // 方式2 : Stream中的静态方法of获取流        // static&lt;T&gt; Stream&lt;T&gt; of(T... values)        Stream&lt;String&gt; stream6 = Stream.of("aa", "bb", "cc");        String[] strs = {"aa", "bb", "cc"};        Stream&lt;String&gt; stream7 = Stream.of(strs);        // 基本数据类型的数组行不行?不行的,会将整个数组看做一个元素进行操作.        int[] arr = {11, 22, 33};        Stream&lt;int[]&gt; stream8 = Stream.of(arr);    }}</code></pre><h3 id="stream流中的foreach方法："><a href="#stream流中的foreach方法：" class="headerlink" title="stream流中的foreach方法："></a><strong>stream流中的foreach方法：</strong></h3><pre><code class="java">package com.jdktest01.day02;import java.util.ArrayList;import java.util.Collections;import java.util.List;/** * @author a1002 */public class StreamTest04 {    public static void main(String[] args) {        List&lt;String&gt; one = new ArrayList&lt;&gt;();        Collections.addAll(one, "迪丽热巴", "周雨彤", "马思纯", "肖战", "老子", "庄子");        one.stream().forEach((String str) -&gt; {            System.out.println(str);        });        System.out.println("-------------------------");        one.stream().forEach(System.out::println);        System.out.println("-------------------------");        one.forEach(System.out::println);    }}</code></pre><h3 id="stream流中的filter方法："><a href="#stream流中的filter方法：" class="headerlink" title="stream流中的filter方法："></a><strong>stream流中的filter方法：</strong></h3><p>//过滤</p><pre><code class="java">List&lt;String&gt; one = new ArrayList&lt;&gt;();        Collections.addAll(one, "迪丽热巴", "周雨彤", "马思纯", "肖战", "老子", "庄子");        one.stream().filter((String s) -&gt; {            return s.length() == 3;        }).forEach(System.out::println);        System.out.println("---------------------");        //简化        one.stream().filter(s -&gt; s.length() == 3).forEach(System.out::println);        System.out.println("---------------------");</code></pre><h3 id="stream流中的limit方法："><a href="#stream流中的limit方法：" class="headerlink" title="stream流中的limit方法："></a><strong>stream流中的limit方法：</strong></h3><p>//限制输出数据数量</p><pre><code class="java">            one.stream()                .limit(3)                .forEach(System.out::println);</code></pre><h3 id="stream流中的skip方法："><a href="#stream流中的skip方法：" class="headerlink" title="stream流中的skip方法："></a><strong>stream流中的skip方法：</strong></h3><pre><code class="java">List&lt;String&gt; one = new ArrayList&lt;&gt;();        Collections.addAll(one, "迪丽热巴", "周雨彤", "马思纯", "肖战", "老子", "庄子");        //跳过指定的前两个数据        one.stream()                .skip(2)                .forEach(System.out::println);</code></pre><p>从下面可以看到skip指定类型是long，所以不能指定跳过某一个String。&nbsp;</p><p><img src="https://img-blog.csdnimg.cn/1361fe5872a744b9ac29690999c80672.png"></p><h3 id="Stream流中的map方法："><a href="#Stream流中的map方法：" class="headerlink" title="**&nbsp;Stream流中的map方法：**"></a>**&nbsp;Stream流中的map方法：**</h3><pre><code class="java">@Test    public void testMap() {        //Map可以将一种类型的流转为另一种类型的流        Stream&lt;String&gt; original = Stream.of("11", "22", "33");        //将stream流中的字符串转为Integer        //参数就是你原本的类型//        original.map((String s) -&gt; {//            return Integer.parseInt(s);//        });        System.out.println("---------------------");        //简化        //      original.map(s -&gt; Integer.parseInt(s)).forEach(System.out::println);        //再简化        original.map(Integer::parseInt).forEach(System.out::println);    }</code></pre><h3 id="stream流中的sorted方法："><a href="#stream流中的sorted方法：" class="headerlink" title="stream流中的sorted方法："></a><strong>stream流中的sorted方法：</strong></h3><p>//排序</p><pre><code class="java">@Test    public void testSorted() {        // sorted(): 根据元素的自然顺序排序        // sorted(Comparator&lt;? super T&gt; comparator): 根据比较器指定的规则排序        Stream&lt;Integer&gt; stream = Stream.of(33, 22, 11, 55);        //升序        stream.sorted().forEach(System.out::println);        System.out.println("------------------------");        //降序        stream.sorted((Integer i1, Integer i2) -&gt; {            return i2 - i1;        }).forEach(System.out::println);        System.out.println("------------------------");        //降序简化        stream.sorted((i1, i2) -&gt; i2 - i1).forEach(System.out::println);    }</code></pre><h3 id="Stream流中的distinct方法："><a href="#Stream流中的distinct方法：" class="headerlink" title="Stream流中的distinct方法："></a><strong>Stream流中的distinct方法：</strong></h3><pre><code class="java">// distinct对自定义对象去除重复    @Test    public void testDistinct() {        Stream&lt;Integer&gt; stream = Stream.of(33, 22, 11, 55, 88, 33, 22, 22, 88, 34, 23);        stream.distinct().forEach(System.out::println);        Stream&lt;String&gt; stream1 = Stream.of("a", "b", "c", "a", "b");        stream1.distinct().forEach(System.out::println);    }</code></pre><p>对Person类中的equals和hashcode方法进行重写，stream中的数据再运行时就会被去重</p><pre><code class="java">@Test    public void testDistinct01() {        Stream&lt;Person&gt; stream = Stream.of(                new Person("貂蝉", 18),                new Person("杨玉环", 20),                new Person("杨玉环", 20),                new Person("西施", 16),                new Person("西施", 16),                new Person("王昭君", 25)        );        stream.distinct().forEach(System.out::println);    }</code></pre><p>重写Person类中的equals和hashcode方法：</p><p><img src="https://img-blog.csdnimg.cn/1c1f7a88696c44e4b4c1863e73452ce7.png"></p><p>运行结果：</p><p><img src="https://img-blog.csdnimg.cn/a4dafe7d9f2a49048b12a7c33a4221c4.png"></p><h3 id="Stream流的match方法："><a href="#Stream流的match方法：" class="headerlink" title="Stream流的match方法："></a>Stream流的match方法：</h3><pre><code class="java">@Test    public void testMatch() {        Stream&lt;Integer&gt; stream = Stream.of(33, 22, 11, 55, 88, 33, 22, 22, 88, 34, 23);        //allMatch需要所有的元素都满足才返回true        //allMatch：匹配所有元素，所有的元素都需要满足条件        boolean b = stream.allMatch((Integer i) -&gt; {            return i &gt; 22;        });        System.out.println(b);        Stream&lt;Integer&gt; stream1 = Stream.of(11, 2, 4, 5);        //allMatch需要所有的元素都满足才返回true        boolean b1 = stream1.allMatch((Integer i) -&gt; {            return i &gt; 0;        });        System.out.println(b1);        //anyMatch: 匹配某个元素,只要有其中一个元素满足条件即可        Stream&lt;Integer&gt; stream3 = Stream.of(33, 22, 11, 55, 88, 33, 22, 22, 88, 34, 23);        boolean b2 = stream3.anyMatch((Integer i) -&gt; {            return i &gt; 22;        });        System.out.println(b2);        //noneMatch: 匹配所有元素,所有元素都不满足条件        Stream&lt;Integer&gt; stream4 = Stream.of(33, 22, 11, 55, 88, 33, 22, 22, 88, 34, 23);        boolean b3 = stream4.noneMatch(i -&gt; i &gt; 0);        System.out.println(b3);    }</code></pre><h3 id="Stream流的find方法："><a href="#Stream流的find方法：" class="headerlink" title="Stream流的find方法："></a><strong>Stream流的find方法：</strong></h3><pre><code class="java">@Test    public void testFind() {        Stream&lt;Integer&gt; stream = Stream.of(33, 22, 11, 55, 88, 33, 22, 22, 88, 34, 23);        Optional&lt;Integer&gt; optional = stream.findFirst();        System.out.println(optional.get());    }</code></pre><h3 id="Stream流中的max和min方法："><a href="#Stream流中的max和min方法：" class="headerlink" title="Stream流中的max和min方法："></a><strong>Stream流中的max和min方法：</strong></h3><pre><code class="java">@Test    public void testMax() {        //获取最大值        Stream&lt;Integer&gt; stream = Stream.of(33, 22, 11, 55, 88, 33, 22, 22, 88, 34, 23);        Optional&lt;Integer&gt; max = stream.max((o1, o2) -&gt; o1 - o2);        System.out.println(max.get());        //获取最小值        Optional&lt;Integer&gt; min = Stream.of(5, 6, 3, 1).min((o1, o2) -&gt; o1 - o2);        System.out.println(min.get());    }</code></pre><p>输出：&nbsp;</p><p><img src="https://img-blog.csdnimg.cn/e201aa6684fc4715a898fb8b46c3f151.png"></p><h3 id="Stream流的reduce方法："><a href="#Stream流的reduce方法：" class="headerlink" title="Stream流的reduce方法："></a><strong>Stream流的reduce方法：</strong></h3><pre><code class="java">        // T reduce(T identity, BinaryOperator&lt;T&gt; accumulator);        // T identity: 默认值        // BinaryOperator&lt;T&gt; accumulator: 对数据进行处理的方式        // reduce如何执行?        // 第一次, 将默认值赋值给x, 取出集合第一元素赋值给y        // 第二次, 将上一次返回的结果赋值x, 取出集合第二元素赋值给y        // 第三次, 将上一次返回的结果赋值x, 取出集合第三元素赋值给y        // 第四次, 将上一次返回的结果赋值x, 取出集合第四元素赋值给y        //以此类推@Test    public void testReduce() {        int reduce = Stream.of(4, 5, 7, 2, 9).reduce(0, (x, y) -&gt; {            System.out.println("x = " + x + " y = " + y);            return x + y;        });        System.out.println(reduce);    }</code></pre><p><img src="https://img-blog.csdnimg.cn/198aa4b4a9814f25acc26a127b440287.png"></p><p>有点类似于js的特性。</p><p>27即为数据和。</p><p>找出最大值：</p><pre><code class="java">int max = Stream.of(4, 5, 7, 2, 9).reduce(0, (x, y) -&gt; {            return x &gt; y ? x : y;        });        System.out.println(max);</code></pre><p>对stream里面封装对象里的某一个数据进行求和：</p><pre><code class="java">@Test    public void testReduce01() {        Integer totalAge = Stream.of(                new Person("刘德华", 58),                new Person("张学友", 56),                new Person("郭富城", 54),                new Person("黎明", 52))                .map((p) -&gt; {                    return p.getAge();                }).reduce(0, (x, y) -&gt; {                    return x + y;                });        System.out.println("totalAge= " + totalAge);    }</code></pre><p>&nbsp;求stream内封装对象某一个属性最大值</p><pre><code class="java">Integer maxAge = Stream.of(                new Person("刘德华", 58),                new Person("张学友", 56),                new Person("郭富城", 54),                new Person("黎明", 52))                .map(p -&gt; p.getAge())                .reduce(0, Math::max);        System.out.println("maxAge=" + maxAge);</code></pre><p>统计某一个元素出现的次数：</p><pre><code class="java">//统计a出现的次数        Integer count = Stream.of("a", "b", "a", "d", "a")                .map(s -&gt; {                    if (s == "a") {                        return 1;                    } else {                        return 0;                    }                })                .reduce(0, Integer::sum);        System.out.println("count=" + count);</code></pre><h3 id="Stream的concat方法："><a href="#Stream的concat方法：" class="headerlink" title="Stream的concat方法："></a>Stream的concat方法：</h3><pre><code class="java">@Test    public void testContact() {        Stream&lt;String&gt; streamA = Stream.of("张三");        Stream&lt;String&gt; streamB = Stream.of("李四");        //合并成一个流        Stream&lt;String&gt; newStream = Stream.concat(streamA, streamB);        // 注意:合并流之后,不能操作之前的流啦.        // streamA.forEach(System.out::println);        newStream.forEach(System.out::println);    }</code></pre><h3 id="Stream小练习："><a href="#Stream小练习：" class="headerlink" title="Stream小练习："></a>Stream小练习：</h3><pre><code class="java">public static void main(String[] args) {        // 第一个队伍        List&lt;String&gt; one = new ArrayList&lt;&gt;();        Collections.addAll(one, "迪丽热巴", "宋远桥", "苏星河", "老子", "庄子", "孙子", "洪七公");        // 第二个队伍        List&lt;String&gt; two = new ArrayList&lt;&gt;();        Collections.addAll(two, "古力娜扎", "张无忌", "张三丰", "赵丽颖", "张二狗", "张天爱", "张三");        // 1.第一个队伍只要名字为3个字的成员姓名;        System.out.println("1.第一个队伍只要名字为3个字的成员姓名-----------------------");        one.stream().filter(s -&gt; s.length() == 3).forEach(System.out::println);        // 2.第一个队伍筛选之后只要前3个人;        System.out.println("2.第一个队伍筛选之后只要前3个人-----------------------");        one.stream().limit(3).forEach(System.out::println);        // 3.第二个队伍只要姓张的成员姓名;        System.out.println("3.第二个队伍只要姓张的成员姓名-----------------------");        two.stream().filter(s -&gt; s.startsWith("张")).forEach(System.out::println);        // 4.第二个队伍筛选之后不要前2个人;        System.out.println("4.第二个队伍筛选之后不要前2个人-----------------------");        two.stream().skip(2).forEach(System.out::println);        // 5.将两个队伍合并为一个队伍;        System.out.println("5.将两个队伍合并为一个队伍-----------------------");        Stream&lt;String&gt; newStream = Stream.concat(one.stream(), two.stream());        newStream.forEach(System.out::println);        // 6.根据姓名创建`Person`对象;        // 7.打印整个队伍的Person对象信息。        System.out.println("6.根据姓名创建`Person`对象-----------------------");        System.out.println("7.打印整个队伍的Person对象信息-----------------------");        Stream&lt;String&gt; StreamAB = Stream.concat(one.stream(), two.stream());        StreamAB.map(Person::new).forEach(System.out::println);    }</code></pre><p>输出：</p><p><img src="https://img-blog.csdnimg.cn/b08c940ecb80483eab5504e2dce2e5fd.png"></p><p><img src="https://img-blog.csdnimg.cn/bc92324da33d4173b273dd145127746a.png"></p><h3 id="将流中的数据收集到集合中："><a href="#将流中的数据收集到集合中：" class="headerlink" title="将流中的数据收集到集合中："></a>将流中的数据收集到集合中：</h3><pre><code class="java">//将流中的数据收集到集合中    @Test    public void testStreamToCollection() {        Stream&lt;String&gt; stream = Stream.of("aa", "bb", "cc", "aa");        //将流中的数据收集到集合中        //collection收集流中的数据到集合中//        List&lt;String&gt; list = stream.collect(Collectors.toList());//        System.out.println("list = " + list);//        Set&lt;String&gt; set = stream.collect(Collectors.toSet());//        System.out.println("set = " + set);        HashSet&lt;String&gt; hashSet = stream.collect(Collectors.toCollection(HashSet::new));        System.out.println("hashset = " + hashSet);    }</code></pre><h3 id="将流中的数据收集到数组中："><a href="#将流中的数据收集到数组中：" class="headerlink" title="将流中的数据收集到数组中："></a>将流中的数据收集到数组中：</h3><pre><code class="java">@Test    public void testStreamToArray() {        // 转成Object数组不方便        // Object[] objects = stream.toArray();        // for (Object o : objects) {        //     System.out.println("o = " + o);        // }        // String[]        Stream&lt;String&gt; stream = Stream.of("aa", "bb", "cc", "aa");        String[] strings = stream.toArray(String[]::new);        System.out.println("strings = " + Arrays.toString(strings) + ", 长度：" + strings.length);    }</code></pre><h3 id="对流中数据进行聚合运算："><a href="#对流中数据进行聚合运算：" class="headerlink" title="对流中数据进行聚合运算："></a>对流中数据进行聚合运算：</h3><pre><code class="java">@Test    public void testStreamToOther() {        Stream&lt;Student&gt; studentStream = Stream.of(                new Student("赵丽颖", 58, 95),                new Student("杨颖", 56, 88),                new Student("迪丽热巴", 56, 99),                new Student("柳岩", 52, 77));        //获取最大值        Optional&lt;Student&gt; max = studentStream.collect(Collectors.maxBy((s1, s2) -&gt; s1.getSocre() - s2.getSocre()));        System.out.println(max.get());        List&lt;Student&gt; max1 = new ArrayList&lt;&gt;();        Collections.addAll(max1, new Student("赵丽颖", 58, 95),                new Student("杨颖", 56, 88),                new Student("迪丽热巴", 56, 99),                new Student("柳岩", 52, 77));        Optional&lt;Student&gt; collect = max1.stream().collect(Collectors.maxBy((s1, s2) -&gt; s1.getSocre() - s2.getSocre()));        System.out.println(collect.get());        //获取最小值        Stream&lt;Student&gt; studentStream1 = Stream.of(                new Student("赵丽颖", 58, 95),                new Student("杨颖", 56, 88),                new Student("迪丽热巴", 56, 99),                new Student("柳岩", 52, 77));        Optional&lt;Student&gt; min = studentStream1.collect(Collectors.maxBy((s1, s2) -&gt; s2.getSocre() - s1.getSocre()));        System.out.println(min.get());        //求总和        Stream&lt;Student&gt; studentStream2 = Stream.of(                new Student("赵丽颖", 58, 95),                new Student("杨颖", 56, 88),                new Student("迪丽热巴", 56, 99),                new Student("柳岩", 52, 77));        Integer sum = studentStream2.collect(Collectors.summingInt(s -&gt; s.getAge()));        System.out.println("sum = " + sum);        // 平均值        Stream&lt;Student&gt; studentStream3 = Stream.of(                new Student("赵丽颖", 58, 95),                new Student("杨颖", 56, 88),                new Student("迪丽热巴", 56, 99),                new Student("柳岩", 52, 77));        //       Double avg = studentStream3.collect(Collectors.averagingInt(s -&gt; s.getSocre()));        Double avg = studentStream3.collect(Collectors.averagingInt(Student::getSocre));        System.out.println("平均值: " + avg);        // 统计数量        Stream&lt;Student&gt; studentStream4 = Stream.of(                new Student("赵丽颖", 58, 95),                new Student("杨颖", 56, 88),                new Student("迪丽热巴", 56, 99),                new Student("柳岩", 52, 77));        Long count = studentStream4.collect(Collectors.counting());        System.out.println("统计数量: " + count);    }</code></pre><p>输出：</p><p><img src="https://img-blog.csdnimg.cn/d8e1c5268d18425bb82c3ebd1e97483e.png"></p><h3 id="对流中数据进行分组："><a href="#对流中数据进行分组：" class="headerlink" title="对流中数据进行分组："></a>对流中数据进行分组：</h3><pre><code class="java">@Test    public void testCollectors() {        Stream&lt;Student&gt; studentStream5 = Stream.of(                new Student("赵丽颖", 58, 95),                new Student("杨颖", 56, 88),                new Student("迪丽热巴", 56, 99),                new Student("柳岩", 52, 77));        Map&lt;Integer, List&lt;Student&gt;&gt; map = studentStream5.collect(Collectors.groupingBy((s) -&gt; s.getAge()));        map.forEach((k, v) -&gt; {            System.out.println(k + "::" + v);        });    }</code></pre><p>输出：</p><p><img src="https://img-blog.csdnimg.cn/cb4d0c54478c41d1a60bd4e1c7995774.png"></p><pre><code class="java">@Test    public void testCollectors01() {        Stream&lt;Student&gt; studentStream5 = Stream.of(                new Student("赵丽颖", 58, 95),                new Student("杨颖", 56, 88),                new Student("迪丽热巴", 56, 99),                new Student("柳岩", 52, 56));        Map&lt;String, List&lt;Student&gt;&gt; map = studentStream5.collect(Collectors.groupingBy((s) -&gt; {            if (s.getSocre() &gt; 60) {                return "及格";            } else {                return "不及格";            }        }));        map.forEach((k, v) -&gt; {            System.out.println(k + "::" + v);        });    }</code></pre><p>&nbsp;输出：</p><p><img src="https://img-blog.csdnimg.cn/3c13c24d0d0e4fcabe6944e37e9ca748.png"></p><h3 id="多级分组："><a href="#多级分组：" class="headerlink" title="多级分组："></a>多级分组：</h3><pre><code class="java">// 多级分组    @Test    public void testCustomGroup() {        Stream&lt;Student&gt; studentStream = Stream.of(                new Student("赵丽颖", 52, 95),                new Student("杨颖", 56, 88),                new Student("迪丽热巴", 56, 55),                new Student("柳岩", 52, 33));        // 先根据年龄分组,每组中在根据成绩分组        // groupingBy(Function&lt;? super T, ? extends K&gt; classifier, Collector&lt;? super T, A, D&gt; downstream)        Map&lt;Integer, Map&lt;String, List&lt;Student&gt;&gt;&gt; map = studentStream.collect(Collectors.groupingBy(Student::getAge, Collectors.groupingBy((s) -&gt; {            if (s.getSocre() &gt; 60) {                return "及格";            } else {                return "不及格";            }        })));        // 遍历        map.forEach((k, v) -&gt; {            System.out.println(k);            // v还是一个map,再次遍历            v.forEach((k2, v2) -&gt; {                System.out.println("\t" + k2 + " == " + v2);            });        });    }</code></pre><p>输出：</p><p><img src="https://img-blog.csdnimg.cn/c44e47b02aa442eabd940c14dd6b842f.png"></p><h3 id="对流中数据进行拼接："><a href="#对流中数据进行拼接：" class="headerlink" title="对流中数据进行拼接："></a>对流中数据进行拼接：</h3><pre><code class="java">@Test    public void testCollection01() {        Stream&lt;Student&gt; studentStream = Stream.of(                new Student("赵丽颖", 52, 95),                new Student("杨颖", 56, 88),                new Student("迪丽热巴", 56, 55),                new Student("柳岩", 52, 33));        // 根据一个字符串拼接: 赵丽颖__杨颖__迪丽热巴__柳岩        //    String names = studentStream.map(Student::getName).collect(Collectors.joining("__"));        String names = studentStream.map(Student::getName).collect(Collectors.joining("___", "+", "-"));        System.out.println(names);    }</code></pre><p>输出：</p><p><img src="https://img-blog.csdnimg.cn/7083e6095fbf44149b776cfb13cd39fe.png"></p><h3 id="Optional类的基本使用："><a href="#Optional类的基本使用：" class="headerlink" title="Optional类的基本使用："></a>Optional类的基本使用：</h3><pre><code class="java">@Test    public void test01() {        // 1.创建Optional对象        // of:只能传入一个具体值,不能传入null        // ofNullable: 既可以传入具体值,也可以传入null        // empty: 存入的是null        Optional&lt;String&gt; op1 = Optional.of("凤姐");        // Optional&lt;String&gt; op1 = Optional.of(null);        // Optional&lt;String&gt; op2 = Optional.ofNullable("如花");        // Optional&lt;String&gt; op2 = Optional.ofNullable("如花");        Optional&lt;Object&gt; op3 = Optional.empty();        // 2.isPresent: 判断Optional中是否有具体值, 有值返回true,没有值返回false        // boolean present = op1.isPresent();        // System.out.println("present = " + present);        // 3.get: 获取Optional中的值,如果有值就返回值具体值,没有值就报错        // System.out.println(op3.get());        if (op1.isPresent()) {            System.out.println(op1.get());        } else {            System.out.println("没有值");        }    }</code></pre><pre><code class="java">@Test    public void test02() {        // Optional&lt;String&gt; userNameO = Optional.of("凤姐");        Optional&lt;String&gt; userNameO = Optional.empty();//name = 如花吗?        //       Optional&lt;String&gt; userNameO = Optional.of(" ");//name =        // orElse: 如果Optional中有值,就取出这个值,如果没有值就使用参数指定的值        String name = userNameO.orElse("如花吗?");        System.out.println("name = " + name);    }</code></pre><pre><code class="java">@Test    public void test04() {        Optional&lt;String&gt; userNameO = Optional.of("凤姐");        // Optional&lt;String&gt; userNameO = Optional.empty();        // 存在做的什么        // ifPresent: 如果有值就调用参数        /*userNameO.ifPresent(s -&gt; {            System.out.println("有值: " + s);        });*/        // ifPresentOrElse: 存在做的什么,不存在做点什么        userNameO.ifPresentOrElse(s -&gt; {            System.out.println("有值: " + s);        }, () -&gt; {            System.out.println("没有值");        });    }</code></pre><p>就这些吧。</p><p>🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉</p><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><p>总结：啊，最近好烦，我的爱车坏掉了，一直没找到时间去修，还有2个事情眼看时间期限临近，再加上上课时无缘无故的老是神游，呜呜呜呜呜呜呜呜，我是真的会谢，还有这学习计划，还有别人在前面跑，我在后面追，还追不上，呜呜呜呜呜呜呜呜，我还在用一个实战项目练手，正项目耽误了不少时间了，呜呜呜呜呜我真的谢了。。。。</p><p>还有就是最近迷上了各种算法加密。</p><p>还有一些人际关系是真的令我好烦，暂时还找不到好的解决方法，不过有一些是肯定无疑的。唉，跟着自己的感觉走吧，也不赖。</p><p><img src="https://img-blog.csdnimg.cn/3e710c784d814b43a4b075726ecdde90.png"></p>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java jvm Stream jdk </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅聊一下Lambda表达式</title>
      <link href="/2022/10/06/%E6%B5%85%E8%81%8A%E4%B8%80%E4%B8%8BLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
      <url>/2022/10/06/%E6%B5%85%E8%81%8A%E4%B8%80%E4%B8%8BLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>概念</strong>：Lambda表达式是JDK8的一个新特性,可以取代大部分的匿名内部类写出更优雅的Java代码，尤其在集合的遍历和其他集合操作中,可以极大地优化代码结构。</p><p><strong>Lambda表达式的前提条件：</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.方法的参数或变量的类型是接口。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.这个接口中只能有一个抽象方法。</p><p><strong>Lambda的格式：</strong></p><pre><code class="java">(参数类型 参数名称) -&gt; {     代码体; }</code></pre><p><strong>先上代码：</strong></p><pre><code class="java">package com.jdktest01.day01;import java.util.ArrayList;import java.util.Collections;/** * @author a1002 */public class LambdaTest02 {    public static void main(String[] args) {        ArrayList&lt;Person&gt; persons = new ArrayList&lt;&gt;();        persons.add(new Person("张三", 58, 174));        persons.add(new Person("李四", 58, 176));        persons.add(new Person("王五", 54, 171));        persons.add(new Person("伞兵", 19, 177));//        Collections.sort(persons, new Comparator&lt;Person&gt;() {//            @Override//            public int compare(Person o1, Person o2) {//                return o1.getAge() - o2.getAge();//            }//        });//        persons.forEach((p) -&gt; {//            System.out.println(p);//        });        System.out.println("===============================");        Collections.sort(persons, (Person o1, Person o2) -&gt; {            return o1.getAge() - o2.getAge();        });        Collections.sort(persons, (o1, o2) -&gt; o2.getAge() - o1.getAge());        persons.forEach((p) -&gt; {            System.out.println(p);        });        System.out.println("-----------------------------");        persons.forEach(t -&gt; System.out.println(t));        // 对集合中的数据进行排序        /*Collections.sort(persons, new Comparator&lt;Person&gt;() {            @Override            public int compare(Person o1, Person o2) {                return o1.getAge() - o2.getAge(); // 升序排序            }        });*///        Collections.sort(persons, (Person o1, Person o2) -&gt; {//            return o2.getAge() - o1.getAge(); // 降序//        });////        for (Person person : persons) {//            System.out.println(person);//        }////        System.out.println("-----------");//        persons.forEach((t) -&gt; {//            System.out.println(t);//        });    }}</code></pre><p><strong>对集合中的数据进行排序：</strong></p><pre><code class="java">Collections.sort(persons, new Comparator&lt;Person&gt;() {            @Override            public int compare(Person o1, Person o2) {                return o1.getAge() - o2.getAge();//升序            }        });</code></pre><p><strong>Lambda写法：</strong></p><pre><code class="java">Collections.sort(persons, (Person o1, Person o2) -&gt; {            return o1.getAge() - o2.getAge();        });</code></pre><p><strong>简化：</strong></p><pre><code class="java">Collections.sort(persons, (o1, o2) -&gt; o2.getAge() - o1.getAge());</code></pre><p><strong>在Lambda标准格式的基础上，使用省略写法的规则为：</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. 小括号内参数的类型可以省略</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2. 如果小括号内 <strong>有且仅有一个参数</strong> ，则小括号可以省略</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. 如果大括号内 <strong>有且仅有一个语句</strong> ，可以同时省略大括号、 return 关键字及语句分号</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p><strong>Lambda遍历写法：</strong></p><pre><code class="java">persons.forEach((p) -&gt; {            System.out.println(p);        });//简化persons.forEach(t -&gt; System.out.println(t));</code></pre><p><strong>函数式接口：</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在<strong>java</strong>中是指：有且仅有一个抽象方法的接口。</p><p>函数式接口就是可以适用于lambda表达式的接口。</p><p><strong>Lambda和匿名内部类的区别：</strong></p><p>1.所需类型不一样：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;匿名内部类所需要的类型可以是抽象类，接口。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lambda表达式需要的类型必须是接口。</p><p>2.抽象方法的数量不一样：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;匿名内部类所需要的接口中抽象方法的数量随意。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lambda表达式所需要的接口只有一个抽象方法。</p><p>3.实现原理不同：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;匿名内部类是在编译以后形成class。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lambda表达式是在程序运行时动态生成class。</p>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java jvm 开发语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>springboot整合liquibase（补充）</title>
      <link href="/2022/10/03/springboot%E6%95%B4%E5%90%88liquibase%EF%BC%88%E8%A1%A5%E5%85%85%EF%BC%89/"/>
      <url>/2022/10/03/springboot%E6%95%B4%E5%90%88liquibase%EF%BC%88%E8%A1%A5%E5%85%85%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>对 参考博客地址：<a href="https://blog.csdn.net/solocoder/article/details/99696715?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-99696715-blog-83857412.pc_relevant_multi_platform_whitelistv4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-99696715-blog-83857412.pc_relevant_multi_platform_whitelistv4&amp;utm_relevant_index=2" title="SpringBoot 整合 liquibase">SpringBoot 整合 liquibase</a>&nbsp;&nbsp;</p><p>做了一些补充：</p><p>目录：</p><p><img src="https://img-blog.csdnimg.cn/ec6db025cc9345aca2c288d400250d8e.png"></p><p>导入依赖：</p><pre><code class="XML">&lt;!-- LiquiBase 数据库版本管理组件 --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.liquibase&lt;/groupId&gt;            &lt;artifactId&gt;liquibase-core&lt;/artifactId&gt;            &lt;version&gt;4.16.1&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><p>导入spring-boot-starter-jdbc，不然后面的配置文件会报错&nbsp;</p><p><img src="https://img-blog.csdnimg.cn/d60542f2b705423a91bc34985c52705c.png">&nbsp;项目启动时也会报这个错误：<img src="https://img-blog.csdnimg.cn/e32877c806604a139140756a05b7ed4e.png"></p><p>连接数据库：为一空的数据库&nbsp;</p><p><img src="https://img-blog.csdnimg.cn/f88826d4978f4b09ab1385e33658660e.png"></p><p>&nbsp;&nbsp;增加LiquibaseConfig这个配置类：</p><pre><code class="java">import liquibase.integration.spring.SpringLiquibase;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import javax.sql.DataSource;/** * @author a1002 */@Configurationpublic class LiquibaseConfig {    @Bean    public SpringLiquibase liquibase(DataSource dataSource) {        SpringLiquibase liquibase = new SpringLiquibase();        liquibase.setDataSource(dataSource);        //指定changelog的位置，这里使用的一个master文件引用其他文件的方式        liquibase.setChangeLog("classpath:liquibase/master.xml");        liquibase.setContexts("development,test,production");        liquibase.setShouldRun(true);        return liquibase;    }}</code></pre><p>&nbsp;在resources下创建目录：</p><p><img src="https://img-blog.csdnimg.cn/01dfa620e333457b8c45984f5a663766.png"></p><p><img src="https://img-blog.csdnimg.cn/8ce2851ece264875bc8946b7c6755554.png"></p><p>changelogs下是使用xml要创建的表。</p><p>master.xml内容：</p><pre><code class="XML">&lt;databaseChangeLog        xmlns="http://www.liquibase.org/xml/ns/dbchangelog"        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"        xsi:schemaLocation="http://www.liquibase.org/xml/ns/dbchangelog         http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd"&gt;    &lt;includeAll path="liquibase/changelogs/" relativeToChangelogFile="false"/&gt;&lt;/databaseChangeLog&gt;</code></pre><p>示例：changelog-1.0.xml内容（参考博客地址：<a href="https://blog.csdn.net/solocoder/article/details/99696715?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-99696715-blog-83857412.pc_relevant_multi_platform_whitelistv4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-99696715-blog-83857412.pc_relevant_multi_platform_whitelistv4&amp;utm_relevant_index=2" title="SpringBoot 整合 liquibase">SpringBoot 整合 liquibase</a>&nbsp;&nbsp;）：</p><pre><code class="XML">&lt;databaseChangeLog        xmlns="http://www.liquibase.org/xml/ns/dbchangelog"        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"        xsi:schemaLocation="http://www.liquibase.org/xml/ns/dbchangelog         http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.1.xsd"&gt;    &lt;changeSet id="20190713-01" author="solo"&gt;        &lt;createTable tableName="project_info"&gt;            &lt;column name="project_id" type="varchar(64)" encoding="utf8" remarks="项目id"&gt;                &lt;constraints primaryKey="true" nullable="false"/&gt;            &lt;/column&gt;            &lt;column name="project_name" type="varchar(255)" encoding="utf8" remarks="项目名字"/&gt;            &lt;column name="project_difficulty" type="float" encoding="utf8" remarks="项目难度"/&gt;            &lt;column name="category_id" type="varchar(64)" encoding="utf8" remarks="项目类型类目编号"/&gt;            &lt;column name="project_status" type="int(11)" encoding="utf8" remarks="项目状态, 0招募中，1 进行中，2已完成，3失败，4延期，5删除"/&gt;            &lt;column name="project_desc" type="varchar(512)" encoding="utf8" remarks="项目简介"/&gt;            &lt;column name="project_creater_id" type="varchar(64)" encoding="utf8" remarks="项目创建者id"/&gt;            &lt;column name="team_id" type="varchar(64)" encoding="utf8" remarks="项目所属团队id"/&gt;            &lt;column name="create_time" type="bigint(64)" encoding="utf8" remarks="创建时间"/&gt;            &lt;column name="update_time" type="bigint(64)" encoding="utf8" remarks="更新时间"/&gt;        &lt;/createTable&gt;    &lt;/changeSet&gt;&lt;/databaseChangeLog&gt;</code></pre><p>参考博客地址：<a href="https://blog.csdn.net/solocoder/article/details/99696715?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-99696715-blog-83857412.pc_relevant_multi_platform_whitelistv4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-99696715-blog-83857412.pc_relevant_multi_platform_whitelistv4&amp;utm_relevant_index=2" title="SpringBoot 整合 liquibase">SpringBoot 整合 liquibase</a>&nbsp;&nbsp;</p><p>启动项目就ok啦。</p><p>下面是个人总结：只看liquibase的孩子可以跳过啦</p><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><hr><p>&nbsp;个人总结：过去的一周里，有过开心，也有过失望遗憾，但个人来说负面情绪所占比还是挺高的。</p><p>不知道怎么说，最近的情绪比较矛盾，可能是在某一程度上太闲了吧。</p><p>说说最近的状态吧，对于一些以前还会比较在意的事情，现在不会再去过多的追究，倒也不是真的不在意了，只是在意了又有什么用呢，多的只是自己的精神内耗，别和自己过不去嘛，于是乎，我就好像真的没那么在意了，也看清了一些事情，更多的时候，我好像变成了一个旁观者，静静地看着自己，以第三人称视角看自己，看自己身边发生的事，当然，有一些当局者迷的事情还是存在的，但那已经无足轻重了。</p><p>我开始慢慢意识到这是我自己的生活，我在过着我自己的生活，没有和父母生活在一起的生活，我需要打理好我自己生活中的鸡毛蒜皮。</p><p>我不愿意去和别人走一样的路，我有太多自己的想法，我更愿意朝着自己给自己既定的目标前行，可能路上会遇到很多阻碍，不过这些都是既定的，也就不用觉得有什么自己会接受不了的事情。</p><p>再说说其他的吧，看的书多了，你就会感觉到你似乎脱离了世界，对这个世界会以冷漠的眼神看待，你看着别人的一言一行，也可能是我自己的原因吧，我看着别人的一言一行，对于一些似乎是携带着一些表演成分的端倪，我没有自我感动的自我相信，只有对既定的冷漠，似乎是早已经预料到的，懒得再费口舌，只是让事情朝着简洁化的路上慢慢靠近，只要事情没有脱离自己掌控的地步，一切就都还好说。</p><p>或许在以前的我看来我还是那么自命不凡，但现在的我是比高中时候的我成熟了很多的，那个时候的我不仅冷漠，还讥讽着世俗，现在看来，好像是青春期正盛时候的敏感中二多疑，但也无法排除有一些观点看法是挺正确的。</p><p>我是一个什么样的人呢，我追求自由，渴望自由。我有时候会想，把一切阻止我自由的事物都扼杀，但转念一想，人们似乎都被困在世俗的牢笼里。人生很短暂，想要陪着的人的生命也在慢慢流逝，很多的时候我是没有资格去渴望自由的，在一些需要既定的结果去弥补的事情完成之前，我都没有资格说出这么不负责任的话。</p><p>最后吧，经过一件事情之后，我开始想，一个每天都成熟稳重的人，在大家面前表现的那么强大，那么稳重成熟，日复一日，对于现在的我来说，我是接受不了自己成为这样的人的，是人就一定会有弱点，就会有脆弱的时候，自己默默在自己脆弱的时候忍受是很难过的，那种日复一日的脆弱突然爆发，积累了这么久的，突然爆发，会和洪水一般把人压的喘不过来气的，在我看来，还不如每一段时间都适当emo一下，将自己的情绪，自己的脆弱，展现给自己信任的人，其他的没有到那种程度的朋友适当的emo一下就ok，与好友分享，当然有一些话自己消化就可，传递太多的负面情绪给别人也是很不值得赞扬的。</p><p>就这样吧，今天的emo准时送达～</p><p>撒花撒花🎉</p>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring boot java 缓存 经验分享 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java部分排序算法</title>
      <link href="/2022/09/23/java%E9%83%A8%E5%88%86%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"/>
      <url>/2022/09/23/java%E9%83%A8%E5%88%86%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><strong>目录</strong></p><p><a href="#1.%E7%9B%B4%E6%8E%A5%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F">1.直接插入排序</a></p><p><a href="#2.%E6%8A%98%E5%8D%8A%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F">2.折半插入排序</a></p><p><a href="#3.%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F">3.选择排序</a></p><p><a href="#4.%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F">4.冒泡排序</a></p><hr><h2 id="十大内部排序算法："><a href="#十大内部排序算法：" class="headerlink" title="十大内部排序算法："></a>十大内部排序算法：</h2><p><strong>选择排序</strong></p><p><strong>直接选择排序、堆排序</strong></p><p><strong>交换排序</strong></p><p><strong>冒泡排序、快速排序</strong></p><p><strong>插入排序</strong></p><p><strong>直接插入排序、折半插入排序、Shell 排序</strong></p><p><strong>归并排序</strong></p><p><strong>桶式排序</strong></p><p><strong>基数排序</strong></p><h2 id="1-直接插入排序"><a href="#1-直接插入排序" class="headerlink" title="1.直接插入排序"></a>1.直接插入排序</h2><p>每插入一个数据，就会在原来序列中进行排序，插入几次排序几次。</p><pre><code class="java">public class YangSort {    public static void main(String[] args) {        int []nums={2,8,5,3,9,3};        numsSort(nums);        for(int i = 0;i &lt; nums.length;i++){            System.out.print(nums[i]+"\t");        }    }    //直接插入排序    public static void numsSort(int []nums){        for(int i = 1; i &lt; nums.length; i++){            int temp = nums[i];//temp=8            int j = i-1;//j=0            for(;j &gt;= 0 &amp;&amp; temp &lt; nums[j]; j--){                nums[j+1] = nums[j];            }            nums[j+1] = temp;        }    }}</code></pre><h2 id="2-折半插入排序"><a href="#2-折半插入排序" class="headerlink" title="2.折半插入排序"></a>2.折半插入排序</h2><p>用二分法根据插入数据大小确定插入数据应所处位置,再把之后的数据后移。</p><pre><code class="java">    //折半插入排序    public static void halfSort(int[]nums){        for(int i = 1; i &lt; nums.length; i++){            int temp = nums[i];            int left = 0,right = i - 1;// 左指针 右指针            while(left &lt;= right){// 通过二分法寻找插入位置                int mid = left +(right - left)/2;                if(nums[mid] &gt; temp){                    right = mid -1;                }                else{                    left = mid + 1;                }            }            int j = i - 1;// 将left后面的数据向后移动,共有i+1个数据            while(j &gt;= left){                nums[j + 1] = nums[j];                j--;            }            nums[left] = temp;// 将数据插入通过二分法找到的位置        }     }</code></pre><h2 id="3-选择排序"><a href="#3-选择排序" class="headerlink" title="3.选择排序"></a>3.选择排序</h2><p>&nbsp;依次选择最小值放在最前面</p><pre><code class="java">//选择排序    public static void selectSort(int []nums){        for(int i=0;i&lt;nums.length;i++){            int min=i;            for(int j=i+1;j&lt;nums.length;j++){//内层循环表示依次选出最小值的索引                if(nums[j]&lt;nums[min]){                    min=j;                }            }            if(min != i){//把i之后选出的最小值与i所在值互换                int temp=nums[i];                nums[i]=nums[min];                nums[min]=temp;            }        }    }</code></pre><h2 id="4-冒泡排序"><a href="#4-冒泡排序" class="headerlink" title="4.冒泡排序"></a>4.冒泡排序</h2><p>每次选择一个最大值放到后面</p><pre><code class="java">    //冒泡排序    public static void bubbleSort(int []nums){//外层循次数 为nums.length-1次        for(int i=0;i&lt;nums.length-1;i++){            for(int j=0; j&lt;nums.length-i-1; j++){//内层循环进行冒泡，因为每完成一次外层循环，就会在后面多一个有序序列，因此可以不用比较                if(nums[j]&gt;nums[j+1]){                    int temp=nums[j];                    nums[j]=nums[j+1];                    nums[j+1]=temp;                }            }        }    }</code></pre><p>上面的是部分排序方法。</p><hr><p>说说最近的情况吧，这几天线下课都转为了线上课，一直在宿舍窝着，同时为即将的项目做准备，说说那个项目吧，还是基于springboot框架，但又添加了很多新的东西，所以这段时间需要把这些新的东西掌握，大概是下周吧，就要进行这个项目的实战了。</p><p>现在每天都要做核酸。</p><p>不知道为什么，我这段时间感觉到身心俱疲，可能是睡眠时间不足吧。<img src="https://img-blog.csdnimg.cn/47944437d6ed4e9da33faedabafd4420.png"></p><p>再过一段时间新生就会返校了，俺也可以被叫学姐了，这个还是挺让人开心的。</p><p>我也不知道该说些什么了，发文助手现在还是不给发步，监测到文章&nbsp;质量较低，行吧行吧，我是在水博客，既然要水博客，那一定要好好水博客，水完之后我就去做核酸。</p><p>43EA4036E9689CE8E53C94C073B1E774，B675266EBD39BA4F5AD9E8EE0D750893，5F051E2996B9D664AC8873BBAB7A80D9。</p><p>上面是用的md5加密，大家自行取之。</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 排序算法 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Maven右侧子项目maven变成灰色</title>
      <link href="/2022/09/17/Maven%E5%8F%B3%E4%BE%A7%E5%AD%90%E9%A1%B9%E7%9B%AEmaven%E5%8F%98%E6%88%90%E7%81%B0%E8%89%B2/"/>
      <url>/2022/09/17/Maven%E5%8F%B3%E4%BE%A7%E5%AD%90%E9%A1%B9%E7%9B%AEmaven%E5%8F%98%E6%88%90%E7%81%B0%E8%89%B2/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p><img src="https://img-blog.csdnimg.cn/7b81d9edee92409c970c2aab7045243e.png"></p><p>蓝色部分为灰色。&nbsp;</p><p>遇到这个问题后，我和大家一样上网查找解决方法，但是网上提供的解决方法都是去设置里面把ignored Files里的钩去掉。于是我开心的打开设置。</p><p>看到了这个：&nbsp;</p><p><img src="https://img-blog.csdnimg.cn/778861f629754e27bde21608defbbd68.png"></p><p>咱就说，为啥我的和别人的不太一样，为啥我的是空的。然后我继续上网查找解决方法，还是一样的操作<img src="https://img-blog.csdnimg.cn/607f7646bc7d49e5a3496aa28c8b2cf3.png"></p><p>于是我只能自己排错，又是一段时间的艰苦奋战。</p><p>最后我找到</p><p><img src="https://img-blog.csdnimg.cn/c33ed723b5f74527a9786f1f30154491.png">&nbsp;点击这个之后maven子项目就变成了正常的颜色。</p><p>但是随之而来的，是我的yml文件还是一个普通文件。</p><p><img src="https://img-blog.csdnimg.cn/d03d9c501fae450c95b0fa22389cbc87.png"></p><p>&nbsp;于是我打算先写启动类，写着写着</p><p><img src="https://img-blog.csdnimg.cn/1f662a0f3cd548c09bd1ff585bce13b5.png"></p><p>最开始上面的两个注解是全红的，鼠标悬浮在上面的提示信息是Add Library。。。什么的，于是我添加之后，我的yml文件出现了那个熟悉的图标，注解也能正常import class了。&nbsp;<img src="https://img-blog.csdnimg.cn/900bdb344cdb48359a1b3eee6d5b18ac.png"></p><p>&nbsp;完结撒花🎉</p><p>再来补充一下吧，就在刚刚</p><p>问题分析：<img src="https://img-blog.csdnimg.cn/e6fd8c98302e4e6dbf00fc61237c0726.png"></p><p>&nbsp;红色框框的子项目变成了灰色，项目中<img src="https://img-blog.csdnimg.cn/6884a525e22247ce9cb8c3988ee3f3a8.png"></p><p>&nbsp;包也变成了普通的文件夹。</p><p>解决方法：</p><p><img src="https://img-blog.csdnimg.cn/9abdacdfbb25485f89ff98640d5a0be4.png"></p><p>点击即可。</p>]]></content>
      
      
      <categories>
          
          <category> 报错 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> maven java 开发语言 经验分享 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MybatisPlus实现乐观锁（实战）</title>
      <link href="/2022/09/15/MybatisPlus%E5%AE%9E%E7%8E%B0%E4%B9%90%E8%A7%82%E9%94%81%EF%BC%88%E5%AE%9E%E6%88%98%EF%BC%89/"/>
      <url>/2022/09/15/MybatisPlus%E5%AE%9E%E7%8E%B0%E4%B9%90%E8%A7%82%E9%94%81%EF%BC%88%E5%AE%9E%E6%88%98%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>一，首先在数据库里加上一个字段VERSION，默认值为0.</p><p>二，在实体类里<img src="https://img-blog.csdnimg.cn/91c02712fbf24041b104d0ec6b177b8d.png"></p><p>三，添加mapper&nbsp;</p><p><img src="https://img-blog.csdnimg.cn/65bea46c7d244505b0cb4cae715dd761.png"></p><pre><code class="java">@Repositorypublic interface InterestMapper extends BaseMapper&lt;Interest&gt; {}</code></pre><p>四，新建一个config包</p><p><img src="https://img-blog.csdnimg.cn/83dc90ac22f849ae999da5ef5170604f.png"></p><p>MyBatisPlusConfig</p><pre><code class="java">package com.interest.config;import com.baomidou.mybatisplus.annotation.DbType;import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.OptimisticLockerInnerInterceptor;import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;import org.mybatis.spring.annotation.MapperScan;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author a1002 */@Configuration@MapperScan("com.interest.mapper")public class MyBatisPlusConfig {    @Bean    public MybatisPlusInterceptor mybatisPlusInterceptor(){        MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();        //添加分页插件        interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));        //添加乐观锁插件        interceptor.addInnerInterceptor(new OptimisticLockerInnerInterceptor());        return interceptor;    }}</code></pre><p>之后在test里面进行模拟修改测试冲突就好啦&nbsp;。</p><p>参考：<a href="https://baomidou.com/pages/0d93c0/" title="乐观锁插件 | MyBatis-Plus">乐观锁插件 | MyBatis-Plus</a></p><p>测试：</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.取出记录时，获取当前version</p><p> 2.更新时，version + 1，如果where语句中的version版本不对，则更新失败</p><hr><p>个人总结：</p><p>今天安全返回原宿舍，果然还是原宿舍香哇。</p><p>前几天忙着写一个小项目练手新东西，按照从前的方法来写的话，快的话半个小时就能完成后端的任务，但这个小项目需要用上一些自己以前没学过的东西，于是就一边学一边写，用了大概不到两天身为后端的我成功完成我负责的那一块儿，其中有一些地方需要用到的东西，我也看了一下别人写的，发现比较麻烦，于是我就还用的原本预定的那个方法来写。</p><p>未来几天的计划当然是按照原计划继续学习，这一阶段之后也要拉几位前端孩子一起做项目。</p><p>这几天也接触到了自己以前没有机会接触到的新思路，完善了之前没有完成的一些东西。</p><p>新小组规定的时间比原小组的时间更多一点，当然我也乐得一天中大部分时间都在小组，正是那一句话，即使累死自己，也要卷死同行。</p><p><img src="https://img-blog.csdnimg.cn/52ffc39dabd34d4aa0cc6289d95d8815.png"></p><p>分享一个好玩的地址：</p><p>用的jwt加密，</p><pre><code class="java">eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyLpk77mjqUiOiJodHRwczovL3d3dy5mYW1pbHlzZWFyY2gub3JnLyIsImV4cCI6MTY2NTgyMjAxOH0.oktjhtrtD0gBhNacqSd7p95k-1OTbY7HDCSj_ieYUow</code></pre><p>签名：</p><pre><code class="java">.sign(Algorithm.HMAC256("!Q@W#E$R"))</code></pre><p>名称为“链接”，大家自行取之。</p>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java 开发语言 mybatis 经验分享 spring boot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构+java基础（1）+进制之间的转换</title>
      <link href="/2022/08/13/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84+java%E5%9F%BA%E7%A1%80%EF%BC%881%EF%BC%89+%E8%BF%9B%E5%88%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/"/>
      <url>/2022/08/13/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84+java%E5%9F%BA%E7%A1%80%EF%BC%881%EF%BC%89+%E8%BF%9B%E5%88%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h3 id="数据结构分类："><a href="#数据结构分类：" class="headerlink" title="数据结构分类："></a><strong>数据结构分类：</strong></h3><hr><p>**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;逻辑结构分类：**</p><p>&nbsp; &nbsp; &nbsp; &nbsp; 1.集合结构：集合结构中数据元素除了属于同一个集合外，他们之间没有任何其他的关系。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.线性结构：线性结构中的数据元素之间存在一对一的关系。</p><p>&nbsp; &nbsp; &nbsp; &nbsp; 3.树形结构：树形结构中的数据元素之间存在一对多的层次关系。</p><p>&nbsp; &nbsp; &nbsp; &nbsp; 4.图形结构：图形结构的数据元素是多对多的关系</p><hr><p>**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;物理结构分类：**</p><hr><p>&nbsp; &nbsp; &nbsp; &nbsp; 1.顺序存储结构&nbsp; &nbsp; &nbsp; &nbsp; 比如：数组</p><p>&nbsp; &nbsp; &nbsp; &nbsp; 2.链式存储结构&nbsp; &nbsp; &nbsp; &nbsp;</p><hr><h3 id="位运算符"><a href="#位运算符" class="headerlink" title="位运算符&amp;"></a>位运算符&amp;</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;定义：参加运算的两个数据，按二进制位进行”与”运算。</p><p>&nbsp; &nbsp; &nbsp; &nbsp; 当&amp;左右同时为true的时候结果才为true</p><p>&nbsp; &nbsp; &nbsp; &nbsp; <strong>&amp;其他用途：</strong></p><p>&nbsp; &nbsp; &nbsp; &nbsp; <strong>1.清零</strong></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果想将一个单元清零，即使其全部二进制位为0，只要与一个各位都为零的数值相与，结果为零。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>2.取一个数的指定位</strong></p><p>比如取数 X=1010 1110 的后4位，只需要另找一个数Y，令Y的后4位为1，其余位为0，即Y=0000 1111，然后将X与Y进行按位与运算（X&amp;Y=0000 1110）即可得到X的指定位。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.判断奇偶</p><p>只要根据最未位是0还是1来决定，为0就是偶数，为1就是奇数。因此可以用if ((a &amp; 1) == 0)代替if (a % 2 == 0)来判断a是不是偶数（参加运算的两个数据，按二进制位进行”与”运算）。</p><blockquote><p>借鉴博客<a href="https://blog.csdn.net/weixin_46540009/article/details/115561876" title="位运算">位运算</a></p></blockquote><h3 id="右移"><a href="#右移" class="headerlink" title="右移(>>)"></a>右移(&gt;&gt;)</h3><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以1234这个数值为例，1234右移1位即： 1234&gt;&gt;1</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（1234转换成二进制）1234右移一位（移除），左边用0补上。</p><p><img src="https://img-blog.csdnimg.cn/883b04bcd4ce416c9a988166d6aa5fd2.png" alt="883b04bcd4ce416c9a988166d6aa5fd2.png"></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;右移后得到的值为 617&nbsp;和int 类型的数据617除以2取整所得的值一样，所以有些时候也会被用来替代除2操作。同时，对于超过32位的位移，和左移运算符一样，，会先进行位数求余数。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如：</p><blockquote><p>if((b &amp; 1) == 1)</p></blockquote><p>==</p><blockquote><p>if(b % 2 ==1)</p></blockquote><hr><blockquote><p>b = b &gt;&gt; 1</p></blockquote><p>==</p><blockquote><p>b = b / 2</p></blockquote><h3 id="进制与进制间的转化："><a href="#进制与进制间的转化：" class="headerlink" title="进制与进制间的转化："></a>进制与进制间的转化：</h3><p>**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关于进制**</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;所有数字在计算机底层都以二进制形式存在。</p><p>对于整数，有 <strong>四种表示方式</strong>：</p><p>二进制 (binary)：0,1 ，满 2 进 1. 以 0b 或 0B 开头。</p><p>十进制 (decimal)：0-9 ，满 10 进 1。</p><p>八进制 (octal)：0-7 ，满 8 进 1. 以数字 0 开头表示。</p><p>十六进制(hex)：0-9及A-F，满16进1. 以0x或0X开头表示。此处的A-F 不区分大小写。如：0x21AF +1= 0X21B0。</p><p>&nbsp;</p><p>Java 整数常量默认是 int 类型，当用二进制定义整数时，其第 32 位是 符号位；当是 long 类型时，二进制默认占 64 位，第 64 位是符号位。</p><p>在Integer类型中有静态方法toBinaryString(int i),这个方法的功能将十进制转换为二进制输出。</p><pre><code class="java">System.out.println("1234二进制数为" + Integer.toBinaryString(1234));</code></pre><pre><code>1234二进制数为10011010010</code></pre><p><strong>同理还有很多函数：</strong></p><p>十进制转成十六进制:<br>Integer.toHexString(int i)<br>十进制转成八进制<br>Integer.toOctalString(int i)<br>十进制转成二进制<br>Integer toBinaryString(int i)<br>十六进制转成十进制<br>Integer.valueOf(“FFFF”,1 6).toString()<br>八进制转成十进制<br>Integer.valueOf(“876” ,8).toString()<br>二进制转十进制<br>Integer.valueOf(“0101”,2).toString()</p><p>（二进制转成十进制乘以 2 的幂数，&nbsp;十进制转成二进制除以 2 取余数。 ）</p><h3 id="java简史（为了这离谱的发文助手）："><a href="#java简史（为了这离谱的发文助手）：" class="headerlink" title="java简史（为了这离谱的发文助手）："></a>java简史（为了这离谱的发文助手）：</h3><p>1991 年 Green 项目，开发语言最初命名为 Oak ( 橡树 )</p><p>1994 年开发组意识到 Oak 非常适合于互联网</p><p>1996 年发布 JDK 1.0，约 8.3 万个网页应用 Java 技术来制作</p><p>1997 年发布 JDK 1.1，JavaOne 会议召开，创当时全球同类会议规模之最</p><p>1998 年发布 JDK 1.2，同年发布企业平台 J2EE</p><p>1999 年 Java 分成 J2SE、J2EE 和 J2ME，JSP/Servlet 技术诞生</p><p>2004 年发布里程碑式版本：JDK 1.5，为突出此版本的重要性，更名为 JDK 5.0</p><p>2005 年 J2SE -&gt; JavaSE，J2EE -&gt; JavaEE，J2ME -&gt; JavaME</p><p>2009 年 Oracle 公司收购 SUN，交易价格 74 亿美元</p><p>2011 年发布 JDK 7.0</p><p>2014 年发布 JDK 8.0，是继 JDK 5.0 以来变化最大的版本</p><p>2017 年发布 JDK 9.0，最大限度实现模块化</p><p>2018 年 3 月发布 JDK 10.0，版本号也称为 18.3</p><p>2018 年 9 月发布 JDK 11.0，版本号也称为 18.9</p><p>2019 年 3 月 20 日 Java SE 12 发布。Java 12 是短期支持版本。</p><p>2019 年 9 月 23 日 Java SE 13 发布，此版本中添加了“文本块”，文本块是 一个多行字符串文字，避免对大多数转义序列的需要，以可预测的方式自动 格式化字符串，并在需要时让开发人员控制格式。</p><p>上一张从尚硅谷那里拿过来的一张java导图（没有水印）：</p><p><img src="https://img-blog.csdnimg.cn/6214a08c0d95452983db31f51e0d11e0.png" alt="6214a08c0d95452983db31f51e0d11e0.png"></p><p>&nbsp;<a href="https://b23.tv/6FtWZ3H" title="尚硅谷">尚硅谷</a></p><p>上一页：<a href="https://blog.csdn.net/Hubery_sky/article/details/126161408" title="分页查询与集合分页查询与html基础知识">分页查询与集合分页查询与html基础知识</a>​​​​​​​</p><p>下一页：<a href="https://blog.csdn.net/Hubery_sky/article/details/126328850?spm=1001.2014.3001.5501" title="请求方法+super+枚举+包装类+正则表达式+学习资料">请求方法+super+枚举+包装类+正则表达式+学习资料</a></p><p>个人总结：</p><p>最近几天比较emo，我们这里的疫情又加重了，学习上的压力也变大了，不知道什么时候考核，只能先准备着，算法虽然也有在写，但是有时候会因为比较忙，而忽略当天的算法，只能第二天补回来。</p><p>最近想明白了一些东西，心也微微沉了下来，平日里懒散惯了，忘记了以前的自己了，也想起来了以前的自己可没有现在这么蠢，以前多多少少心思还是比较缜密的，现在，自从进入大学之后，开始变得有些许懒散了，平日里也不经常每隔一段时间对自己过往的行为进行反思总结了，怎么说呢，有点像，过了很长一段时间之后再去看自己以前写的东西，会突然惊叹，以前的自己文笔怎么这么好，现在的文笔，怎么也写不出当时的了，现在的性格等一些东西就是这样吧。</p><p>仔细想想，自己以前很长一段时间里，多少有点盲目自大了。</p><p>说说最近的状态吧，之前，我有很多想要抓住的东西，可总是抓不住，慢慢的，也就习惯了，抓不住就抓不住了， 抓不住的东西，毕竟连伸手都是多余的，我也知道，自己有时候是真的三分钟热度，不得要浇灭自己的热情的时候，也比较果断，做的多了，有时候就会觉得自己有点太绝情了，想想都感觉有些许离谱。</p><p>换个话题，现在是晚上22:39，大多数人应该都睡了，家人们也都进入了梦乡。</p><p>还是想反思一下最近的情绪，情绪变得很平淡，有点冷漠，和别人聊天的时候，因为是线上聊天，线上我好像还是一个乐观的聊天方式，屏幕这边的我却大部分都是冷着一张脸，提不起兴趣来，感觉很多东西都是多余的，究根结底，还是上次竞选职位留下的问题，我深深的emo了。</p><p>生活还得继续，我好歹来到了这个世界上，虽然不清楚人死后会去哪里，但在活着的这段时间里，我都要格外珍惜，为自己的梦想，愿想努力，这样走到最后，我就能不愧对自己的说，我很满意。</p><p>讲了这么多，还是因为没有人听自己倾诉，所以在博客这里倾诉自己的不快，我自己就是一个挺好的聆听者，可是真正愿意聆听我的人却少之又少，真正理解我懂我的人又有多少，寥寥无几吧，白驹过隙，有一点从未改变，我还是那个追风的人，追求自由的灵魂，人的一生说长不长，能遇到一个知己难之又难。</p><p>说了这么多，最后的最后，还是收拾收拾自己的行囊，继续向前走，过去无可挽回，未来仍旧可期，以后的路，我都愿意认真走下去。清理内心的杂草，丢掉多余的东西，一身轻装，去迎接每天的太阳。</p><p>现在是早上7.47，想了很多，昨天晚上可以说是稍微放肆了一下，也是一个小测试，我在两个群里刷屏(刷屏容易打扰到别人，虽然别人都免打了)，在最后一个群里，从僵尸讲到我的小说，我认真反思了一下，为什么会刷屏，因为焦虑，因为内心的情绪无从发泄，焦虑产生，用刷屏发泄，之后进行反思总结，对自己的了解更多了一些，心情emo焦虑的时候我会感觉到不安，我会刷屏，带着小心翼翼的刷屏，小心的发泄自己的不安，因为向来缺乏安全感，最后得出，刷屏改变不了什么，而且浪费时间，不如早点休息，出去散散步，舒缓心情。</p><p>最后发现，一切又都绕到了原点，在我现在的那个圈子里面，没有真正的所谓朋友，是真的了解我关心我，那里的每个人似乎最在意的都是自己，这些也都情有可原，的确不存在什么义务非要对没有亲缘关系的人示好，无条件的支持与关心，原本索取我想要的东西的方向都错了，在那个圈子里，我没有真正意义上的朋友，每个人都在意着自己，也没有义务要求“朋友”都对自己了解关心。</p><p>最关心自己的还是自己的家人，家人是无可代替的，朋友更多的都是过客，他们只是陪你走了一小段路，之后下站，可能再也不见。</p><p>我也知道无效社交，我也是一个喜欢试探的人，我喜欢从细节里面看人，最后试探出的结果是什么呢，还是自己自找没趣，也许会有人说，自己是什么人，身边的就是什么人，可是你怎么排除一些人是因为一些原因不得已在一起的。</p><p>以前向往的东西，现在得到之后才发现，也不过如此，也许是因为现在得到的不是我真正想要的，我也知道断舍离，在舍不得孩子时候我大部分会继续已有的状态，等弊大于利的时候或者自己腻的时候按着从前的惯例，我也不会留恋，有时候发现，自己有时候太过绝情，真的一点都不在意吗，怎么可能会不在意，但我本来就是一个自尊心强又孤傲的人，这些都不允许我去回头，自己做过的决定，我很少后悔，大部分时候，后悔解决不了问题，只能在现有的时间里将损失降到最小，我还有时间，我也还年轻，我未来会经历的还会很多，也许我会有朋友看到这篇博客，也许会没有，当然 很感谢你能看到这里，认真听我倾诉。</p><p>人生还是应该积极乐观的，我没有的东西我会去争取，朋友也择良木而栖，生活是面镜子，我也知道自己的性格，似乎对每个人都好，未来的路还很长，能陪着我走的人少之又少，所以，未来我会做好一个人走很长一段路的准备。</p><p>试探的越多，付出的希望越大，投入的感情越多，得到的失望也就越大，不如从一开始就把筹码娅在自己身上，精力放在自己身上，自己作为自己最大的筹码，赌输的可能性也会大大降低。</p><p>还有，对自己好点，熬夜真的很伤身体，别把注意力都放在别人身上，时刻保持清醒，沉默大部分时候都是正确的选择。</p><p>也许过一段时间我再看到这些，我会觉得幼稚可笑，但也都是题外话了，这是情绪的一次记录，多少还是有教育意义的。</p><p>就这样吧</p>]]></content>
      
      
      <categories>
          
          <category> java基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java 经验分享 数据结构 推荐算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分页查询与集合分页查询与html基础知识</title>
      <link href="/2022/08/04/%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2%E4%B8%8E%E9%9B%86%E5%90%88%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2%E4%B8%8Ehtml%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
      <url>/2022/08/04/%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2%E4%B8%8E%E9%9B%86%E5%90%88%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2%E4%B8%8Ehtml%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>在写项目的时候几乎都会用到分页查询，分页查询数据库里面的数据。</p><p>我在网上搜索到的大部分都是通过一个类进行的分页。</p><p>下面的是我通过limit进行的分页（直接在service层进行计算，将计算所得的参数传入sql语句）。</p><pre><code class="java">@Override    //pages表示查询第几页，num表示一页查询的数量    public Map findUserPages(int pages, int num) {        Map&lt;String, List&gt; map = new HashMap&lt;&gt;();        int totalPages;//总共的页数        int total;        int count = applicationsRepository.queryAppCounts();//查询总共的数量        if (count % num == 0) {            totalPages = count / num;        }else {               total = count / num;               totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("totalPages", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("totals", list1);        int thePage = (pages - 1) * num;        List&lt;Applications&gt; list2 = applicationsRepository.findUserPages(thePage, num);//@Query(value = "select * from applications limit ?2,?3 ", nativeQuery = true)        map.put("data", list2);        return Response.ok(map);    }</code></pre><p>下面的是对集合进行分页查询，计算方法和上面的一样。</p><p>sql语句就是普通的</p><blockquote><p>@Query(value = “select * from user”, nativeQuery = true) List&lt;User&gt;&nbsp;queryUserPages();</p></blockquote><pre><code class="java">@Override    public Map queryUserPages(int pages, int num) {        // 查找全部用户,使用集合来接收        List&lt;User&gt; userList = userRepository.findUser();        Map&lt;String, List&gt; map = new HashMap&lt;&gt;();        if (userList.size() &gt; num) {            List&lt;User&gt; listIn = new LinkedList&lt;&gt;();//用来存放分页后获取的数据            int count = userList.size();//集合中数据总数量            int totalPages;            int total;            if (count % num == 0) {                totalPages = count / num;            } else {                total = count / num;                totalPages = total + 1;            }            List&lt;Integer&gt; list2 = new LinkedList&lt;&gt;();            list2.add(totalPages);            map.put("totalPages", list2);            int thePage = (pages - 1) * num;            //使用listIn来存放分页查询数据            for (int i = thePage; i &lt; thePage+num &amp;&amp; i &lt; userList.size(); i++) {                listIn.add(userList.get(i));            }            map.put("data", listIn);            List&lt;Integer&gt; listCounts = new LinkedList&lt;&gt;();            listCounts.add(userList.size());            map.put("totals", listCounts);            return map;        } else {            List&lt;Integer&gt; integerList = new LinkedList&lt;&gt;();            integerList.add(userList.size());            map.put("totals", integerList);            map.put("data", userList);            List&lt;Integer&gt; list2 = new LinkedList&lt;&gt;();            list2.add(1);            map.put("totalPages", list2);            return map;        }    }</code></pre><p>&nbsp;最近总结：</p><p>最近在练着科目二，天气也比较炎热，打算开学前把科目二过了。</p><p>要经常锻炼身体，让自己拥有一个比较好的体质。</p><p>调节一下自己的情绪，无论在何时，情绪不轻易被别人左右都是最不错的状态。</p><p>多出去走走，多认识一些朋友，同时也要避免无效社交。</p><p>为了这个有些许离谱的发布博客的情况。</p><p>下面是以前做的笔记：</p><p>根据W3C标准，一个网页主要有三个部分组成：<strong>结构</strong>，<strong>表现</strong>还有<strong>行为</strong>。</p><p>HTML用于描述页面的结构。CSS用于控制页面中元素的样式。JavaScript用于响应用户操作。</p><pre><code class="html">&lt;doctype html&gt; &lt;!--文档说明--&gt;&lt;hteml&gt; &lt;!--根标签--&gt;&lt;head&gt; &lt;!--子标签--&gt;&lt;meta charset="utf-8"/&gt;&lt;title&gt;网页的标题&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;!--网页中所有可见的内容都在此中呈现，也可以不用加&lt;h1&gt;在body中写的话，网页上也会出现写的字--&gt;</code></pre><p>&lt;!–**标题标签**，在HTML中，一共有六级标题标签：h1~h6,在显示效果上，h1最大，h6最小，但是文字的大小我们并不关心，使用HTML标签时，关心的是标签的语义，我们使用的标签都都是语义化标签，六级标题中，h1的最重要，表示一个网页中的主要内容，h2-h6重要性以此降低，对于搜索引擎来说，h1的重要性仅次于title,搜索引擎检索完title,会立即查看h1中的内容，h1标签非常重要，它会影响到页面再搜索引擎中的排名，页面只能写一个h1,一般页面中只使用h1 h2 h3,h3以后的基本不使用–&gt;</p><pre><code class="html">&lt;h1&gt;一级标签&lt;/h1&gt;</code></pre><p>&lt;!– &nbsp; P标签中的文字，默认会独占一行，并且段与段之间会有一个间距，在HTML中，字符之间写再多的空格，浏览器也会当成一个空格解析，换行也会被当成一个空格解析，在页面中可以使用br标签来表示一个换行，br标签是一个自动结束标签–&gt;</p><pre><code class="html">&lt;p&gt;我是一个p标签，我用来表示一个段落&lt;/p&gt;&lt;p&gt;我是一只大老虎&lt;br /&gt;老虎本领大&lt;br&nbsp; /&gt;&lt;/p&gt;&lt;!--hr标签也是一个字结束标签，可以在页面中生成一条水平线--&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><pre><code class="html">&lt;!--在HTML中，一些如&lt;&nbsp; &gt;这种特殊字符是不能直接使用的，需要使用一些特殊的符号来表示这些特殊字符，这些特殊字符我们称为实体(转义字符串）,浏览器解析到实体时，会自动将实体转换为对应的字符 &nbsp;&nbsp;&nbsp; 实体的语法：&amp;实体的名字： &nbsp; &lt;&nbsp; &amp;lt&nbsp; ;&nbsp; &gt;&nbsp; &amp;gt;比如a&gt;b可以写成a&amp;gtb;&nbsp;&nbsp;&nbsp; 空格：&amp;nbsp;(以分号结尾) &nbsp; 版权符号：&amp;copy;（可以去找实体符号参考手册去看）--&gt;</code></pre><p>&lt;!–图片标签，使用img标签来向网页中引入一个外部图片，img标签也是一个自结束标签&nbsp;&nbsp;&nbsp; 属性： src:设置一个外部图片的路径</p><pre><code class="html">&lt;img src="图片的路径" alt="这是一只大老虎" /&gt;</code></pre><p>&nbsp; &nbsp;alt:可以用来设置图片的描述,但是是在图片不能显示时对图片的描述,搜索引擎可以通过alt属性来识别不同的图片，不过不写alt属性，则搜索引擎不会对img中的图片进行收录</p><blockquote><p>width:可以用来修改图片的宽度，一般使用px作为单位&nbsp; height:可以用来修改图片的高度，一般使用px作为单位</p></blockquote><p>宽度和高度两个属性如果只设置一个，则另一个也会等比例调整大小&nbsp; &nbsp; &nbsp;</p><blockquote><p>注：开发过程中指定使用英文符号如果两个之同时指定，则按着所指定的值来设置，一般开发中除了自适应的页面，不建议设置width和height</p></blockquote><p>--&gt;</p><p>&lt;!–如果图片在文件里的文件中，则用/，比如在abc里的bcd中的1.gif，则可以这么表示&lt;img arc=”abc/bcd/1.gif” alt=”大老虎”/&gt;</p><blockquote><p>可以使用../来返回一级目录，返回几级目录就写几个</p></blockquote><p>下一页：<a href="https://blog.csdn.net/Hubery_sky/article/details/126294535" title="数据结构+java基础（1）+进制之间的转换">数据结构+java基础（1）+进制之间的转换</a></p>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java servlet 数据库 经验分享 spring boot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>springboot+springdata jpa后端接口实现</title>
      <link href="/2022/07/22/springboot+springdata%20jpa%E5%90%8E%E7%AB%AF%E6%8E%A5%E5%8F%A3%E5%AE%9E%E7%8E%B0/"/>
      <url>/2022/07/22/springboot+springdata%20jpa%E5%90%8E%E7%AB%AF%E6%8E%A5%E5%8F%A3%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>这个是目录<img src="https://img-blog.csdnimg.cn/a1137ef95382472fbada14291fb59676.png"></p><p>首先导入jpa的依赖</p><pre><code class="java">&lt;!--spring-data-jpa--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><p>&nbsp;</p><p>下面的是SwaggerConfig</p><pre><code class="java">package com.teacher.config;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import springfox.documentation.builders.ApiInfoBuilder;import springfox.documentation.builders.PathSelectors;import springfox.documentation.builders.RequestHandlerSelectors;import springfox.documentation.service.ApiInfo;import springfox.documentation.service.Contact;import springfox.documentation.spi.DocumentationType;import springfox.documentation.spring.web.plugins.Docket;import springfox.documentation.swagger2.annotations.EnableSwagger2;@Configuration@EnableSwagger2public class SwaggerConfig {        @Bean        public Docket createRestApi() {            return new Docket(DocumentationType.SWAGGER_2)                    .apiInfo(apiInfo())                    .select()                    .apis(RequestHandlerSelectors.basePackage("com.teacher.controller"))                    .paths(PathSelectors.any())                    .build();        }        private ApiInfo apiInfo() {            return new ApiInfoBuilder()                    .title("SWAGGER API MANAGEMENT")                    .description("基于 Spring MVC 的 Swagger API 管理")                    .contact(contact())                    .version("1.0")                    .build();        }        private Contact contact() {            return new Contact("yaya", "https://www.wlgzs.net/", "2728771838@qq.com");        }    }</code></pre><p>下面是properties文件的配置</p><pre><code class="java"># 应用名称spring.application.name=teacher-up# 应用服务 WEB 访问端口server.port=8080spring.datasource.url=jdbc:mysql://localhost:3306/teachers?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTCspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.username=rootspring.datasource.password=12345678mybatis.mapper-locations:classpath:mapper/*Dao.xmlmybatis.type-aliases-package=com.teacher.pojomybatis.configuration.map-underscore-to-camel-case=true#自动生成数据库表（关键）spring.jpa.hibernate.ddl-auto=update#mysql数据库驱动程序（重要）#jpa配置：在控制台显示Hibernate的sql(可选)spring.jpa.show-sql = true</code></pre><p>&nbsp;下面的是工具类Response（从网上找的模版进行了适当修改）</p><pre><code class="java">package com.teacher.utils;import lombok.AllArgsConstructor;import lombok.Data;@Data@AllArgsConstructorpublic class Response {    // 统一结果返回类    //标识返回的状态码    private Integer code;    //标识返回的信息    private String message;    //标识返回的数据    private Object data;    //私有化，防止new    private Response() {  }    //成功    public static Response ok(Object data, String message) {        return new Response(1, message, data);  //code 也可以使用字典管理 下面会谈到    }    //成功返回 重载 message没有特别要求    public static Response ok(Object data) {        return Response.ok(data, "success"); //message 也可以使用字典管理 下面会谈到    }    // 失败    public static Response error(Object data, String message) {        return new Response(-1, message, data);    }    public static Response error(Object data) {        return Response.error(data,"fail");  //code 也可以使用字典管理 下面会谈到    }    /************************/    public Integer getCode() {        return code;    }    public void setCode(Integer code) {        this.code = code;    }    public String getMessage() {        return message;    }    public void setMessage(String message) {        this.message = message;    }    public Object getData() {        return data;    }    public void setData(Object data) {        this.data = data;    }    public Response(String message, Object data) {        this.message = message;        this.data = data;    }}</code></pre><p>&nbsp;下面的是实体类</p><pre><code class="java">package com.teacher.pojo;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import org.springframework.data.jpa.domain.support.AuditingEntityListener;import javax.persistence.*;@Data@AllArgsConstructor@NoArgsConstructor@Entity@Table(name="teacher")@EntityListeners(AuditingEntityListener.class)public class Teacher {    @Id    @Column(name = "id")    @GeneratedValue(strategy = GenerationType.IDENTITY)    private int id;    @Column(name = "tea_code")    private String teaCode;    @Column(name = "tea_name")    private String teaName;    @Column(name = "tea_sex")    private String teaSex;    @Column(name = "tea_major")    private String teaMajor;    @Column(name = "tea_education")    private String teaEducation;    @Column(name = "tea_school")    private String teaSchool;    @Column(name = "tea_faculty")    private String teaFaculty;    @Column(name = "tea_academic")    private String teaAcademic;    @Column(name = "tea_data")    private int teaData;    public Teacher(String teaCode, String teaName, String teaSex, String teaMajor, String teaEducation, String teaSchool, String teaFaculty, String teaAcademic, int teaData) {        this.teaCode = teaCode;        this.teaName = teaName;        this.teaSex = teaSex;        this.teaMajor = teaMajor;        this.teaEducation = teaEducation;        this.teaSchool = teaSchool;        this.teaFaculty = teaFaculty;        this.teaAcademic = teaAcademic;        this.teaData = teaData;    }}</code></pre><p>下面的是dao层</p><pre><code class="java">package com.teacher.repository;import com.teacher.pojo.Teacher;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.jpa.repository.JpaSpecificationExecutor;import org.springframework.data.jpa.repository.Query;import org.springframework.data.repository.query.Param;import java.util.List;public interface TeacherRepository extends JpaRepository&lt;Teacher, Integer&gt;, JpaSpecificationExecutor {    @Query(value="select * from teacher where id=?",nativeQuery = true)    Teacher queryTeaByID(int id);    /**     *根据姓名模糊查询     */    @Query(value="select * from teacher where tea_name like %?1% limit ?2,5",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByName(String teaName,int pages);    /**     *根据姓名模糊查询数量     */    @Query(value="select count(*) from teacher where tea_name like %?%",nativeQuery = true)    int queryTeaByNameCount(String teaName);    /**     *根据性别模糊查询     */    @Query(value="select * from teacher where tea_sex like %?1% limit ?2,5",nativeQuery = true)    List&lt;Teacher&gt; queryTeaBySex(String teaSex,int pages);    /**     *根据性别模糊查询数量     */    @Query(value="select count(*) from teacher where tea_sex like %?%",nativeQuery = true)    int queryTeaBySex(String teaSex);    /**     *根据专业模糊查询     */    @Query(value="select * from teacher where tea_major like %?1% limit ?2,5",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByMajor(String teaMajor,int pages);    /**     *根据专业模糊查询数量     */    @Query(value="select count(*) from teacher where tea_major like %?%",nativeQuery = true)    int queryTeaByMajor(String teaMajor);    /**     *根据学历模糊查询     */    @Query(value="select * from teacher where tea_education like %?1% limit ?2,5",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByEdu(String teaEducation,int pages);    /**     *根据学历模糊查询数量     */    @Query(value="select count(*) from teacher where tea_education like %?%",nativeQuery = true)    int queryTeaByEdu(String teaEducation);    /**     *根据职称模糊查询     */    @Query(value="select * from teacher where tea_academic like %?1% limit ?2,5",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByAcademic(String teaAcademic,int pages);    /**     *根据职称模糊查询数量     */    @Query(value="select count(*) from teacher where tea_academic like %?%",nativeQuery = true)    int queryTeaByAcademic(String teaAcademic);    /**     *根据毕业院校模糊查询     */    @Query(value="select * from teacher where tea_school like %?1% limit ?2,5",nativeQuery = true)    List&lt;Teacher&gt; queryTeaBySchool(String teaSchool,int pages);    /**     *根据毕业院校模糊查询数量     */    @Query(value="select count(*) from teacher where tea_school like %?%",nativeQuery = true)    int queryTeaBySchool(String teaSchool);    /**     *根据所在院系模糊查询     */    @Query(value="select * from teacher where tea_faculty like %?1% limit ?2,5",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByFaculty(String teaFaculty,int pages);    /**     *根据所在院系模糊查询数量     */    @Query(value="select count(*) from teacher where tea_faculty like %?%",nativeQuery = true)    int queryTeaByFaculty(String teaFaculty);    /**     *分页查询全部教师     */    @Query(value="select * from teacher limit ?1,?2",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByPage(int pages, int num);    /**     *分页查询全部教师数量     */    @Query(value="select count(*) from teacher",nativeQuery = true)    int queryTeaByPageCount();    /**     * 模糊查询数量     */    @Query(value = "select count(*) from teacher where concat(tea_name,tea_sex,tea_major,tea_education,tea_academic,tea_school,tea_faculty) like concat('%',?1,'%')", nativeQuery = true)    int queryConcatCount(@Param("thing") String thing);    /**     * 模糊查询     */    @Query(value = "select * from teacher where concat(tea_name,tea_sex,tea_major,tea_education,tea_academic,tea_school,tea_faculty) like concat('%',?1,'%') limit ?2,5", nativeQuery = true)    List&lt;Teacher&gt; queryConcat(@Param("thing") String thing,@Param("pages")int pages);}</code></pre><p>&nbsp;下面的是Service层</p><pre><code class="java">package com.teacher.service;import com.teacher.pojo.Teacher;import org.springframework.data.jpa.repository.Query;import org.springframework.data.repository.query.Param;import java.util.List;import java.util.Map;public interface TeacherService {    /**     * 增加老师     */    Teacher insertTeacher(Teacher teacher);    /**     * 删除老师     */    void deleteTeacher(int id);    /**     * 修改老师     */    Teacher updateTeacher(Teacher teacher);    /**     * 查询所有老师     */    List&lt;Teacher&gt; findAllTeacher();    /**     * 通过id查询老师     */    Teacher findTeacherById(int id);    /**     *分页查询全部教师     */    Map queryTeaByPage(int pages);    /************************************************/    /**     *根据姓名模糊查询     */    Map queryTeaByName(String teaName,int pages);    /**     *根据性别模糊查询     */    Map queryTeaBySex(String teaSex,int pages);    /**     *根据专业模糊查询     */    Map queryTeaByMajor(String teaMajor,int pages);    /**     *根据学历模糊查询     */    Map queryTeaByEdu(String teaEducation,int pages);    /**     *根据职称模糊查询     */    Map queryTeaByAcademic(String teaAcademic,int pages);    /**     *根据毕业院校模糊查询     */    Map queryTeaBySchool(String teaSchool,int pages);    /**     *根据所在院系模糊查询     */    Map queryTeaByFaculty(String teaFaculty,int pages);    /**     * 模糊查询     */    Map queryConcat(String thing,int pages);}</code></pre><p>实现类</p><pre><code class="java">package com.teacher.service.impl;import com.teacher.pojo.Teacher;import com.teacher.repository.TeacherRepository;import com.teacher.service.TeacherService;import org.springframework.stereotype.Service;import javax.annotation.Resource;import java.util.HashMap;import java.util.LinkedList;import java.util.List;import java.util.Map;@Servicepublic class TeacherServiceImpl implements TeacherService {    @Resource    private TeacherRepository teacherRepository;    @Override    public Teacher insertTeacher(Teacher teacher) {        return teacherRepository.save(teacher);    }    @Override    public void deleteTeacher(int id) {        teacherRepository.deleteById(id);    }    @Override    public Teacher updateTeacher(Teacher teacher) {        return teacherRepository.save(teacher);    }    @Override    public List&lt;Teacher&gt; findAllTeacher() {        return teacherRepository.findAll();    }    @Override    public Teacher findTeacherById(int id) {        return teacherRepository.findById(id).orElse(null);    }    @Override    public Map queryTeaByPage(int pages) {        Map&lt;String,List&gt; map=new HashMap&lt;&gt;();        int num=5,totalPages,total;        int count=teacherRepository.queryTeaByPageCount();        if (count % num == 0) {            totalPages = count / num;        } else {            total = count / num;            totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("总共的页数", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("总条数", list1);        int thePage = (pages - 1) * num;        List&lt;Teacher&gt; list2 = teacherRepository.queryTeaByPage( thePage, num);        map.put("查询信息", list2);        return map;    }    @Override    public Map queryTeaByName(String teaName, int pages) {        Map&lt;String,List&gt; map=new HashMap&lt;&gt;();        int num=5,totalPages,total;        int count=teacherRepository.queryTeaByNameCount(teaName);        if (count % num == 0) {            totalPages = count / num;        } else {            total = count / num;            totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("总共的页数", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("总条数", list1);        int thePage = (pages - 1) * num;        List&lt;Teacher&gt; list2 = teacherRepository.queryTeaByName(teaName,thePage);        map.put("查询信息", list2);        return map;    }    @Override    public Map queryTeaBySex(String teaSex, int pages) {        Map&lt;String,List&gt; map=new HashMap&lt;&gt;();        int num=5,totalPages,total;        int count=teacherRepository.queryTeaBySex(teaSex);        if (count % num == 0) {            totalPages = count / num;        } else {            total = count / num;            totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("总共的页数", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("总条数", list1);        int thePage = (pages - 1) * num;        List&lt;Teacher&gt; list2 = teacherRepository.queryTeaBySex(teaSex,thePage);        map.put("查询信息", list2);        return map;    }    @Override    public Map queryTeaByMajor(String teaMajor, int pages) {        Map&lt;String,List&gt; map=new HashMap&lt;&gt;();        int num=5,totalPages,total;        int count=teacherRepository.queryTeaByMajor(teaMajor);        if (count % num == 0) {            totalPages = count / num;        } else {            total = count / num;            totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("总共的页数", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("总条数", list1);        int thePage = (pages - 1) * num;        List&lt;Teacher&gt; list2 = teacherRepository.queryTeaByMajor(teaMajor,thePage);        map.put("查询信息", list2);        return map;    }    @Override    public Map queryTeaByEdu(String teaEducation, int pages) {        Map&lt;String,List&gt; map=new HashMap&lt;&gt;();        int num=5,totalPages,total;        int count=teacherRepository.queryTeaByEdu(teaEducation);        if (count % num == 0) {            totalPages = count / num;        } else {            total = count / num;            totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("总共的页数", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("总条数", list1);        int thePage = (pages - 1) * num;        List&lt;Teacher&gt; list2 = teacherRepository.queryTeaByEdu(teaEducation,thePage);        map.put("查询信息", list2);        return map;    }    @Override    public Map queryTeaByAcademic(String teaAcademic, int pages) {        Map&lt;String,List&gt; map=new HashMap&lt;&gt;();        int num=5,totalPages,total;        int count=teacherRepository.queryTeaByAcademic(teaAcademic);        if (count % num == 0) {            totalPages = count / num;        } else {            total = count / num;            totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("总共的页数", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("总条数", list1);        int thePage = (pages - 1) * num;        List&lt;Teacher&gt; list2 = teacherRepository.queryTeaByAcademic(teaAcademic,thePage);        map.put("查询信息", list2);        return map;    }    @Override    public Map queryTeaBySchool(String teaSchool, int pages) {        Map&lt;String,List&gt; map=new HashMap&lt;&gt;();        int num=5,totalPages,total;        int count=teacherRepository.queryTeaBySchool(teaSchool);        if (count % num == 0) {            totalPages = count / num;        } else {            total = count / num;            totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("总共的页数", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("总条数", list1);        int thePage = (pages - 1) * num;        List&lt;Teacher&gt; list2 = teacherRepository.queryTeaBySchool(teaSchool,thePage);        map.put("查询信息", list2);        return map;    }    @Override    public Map queryTeaByFaculty(String teaFaculty, int pages) {        Map&lt;String,List&gt; map=new HashMap&lt;&gt;();        int num=5,totalPages,total;        int count=teacherRepository.queryTeaByFaculty(teaFaculty);        if (count % num == 0) {            totalPages = count / num;        } else {            total = count / num;            totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("总共的页数", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("总条数", list1);        int thePage = (pages - 1) * num;        List&lt;Teacher&gt; list2 = teacherRepository.queryTeaByFaculty(teaFaculty,thePage);        map.put("查询信息", list2);        return map;    }    @Override    public Map queryConcat(String thing, int pages) {        Map&lt;String,List&gt; map=new HashMap&lt;&gt;();        int num=5,totalPages,total;        int count=teacherRepository.queryConcatCount(thing);        if (count % num == 0) {            totalPages = count / num;        } else {            total = count / num;            totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("总共的页数", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("总条数", list1);        int thePage = (pages - 1) * num;        List&lt;Teacher&gt; list2 = teacherRepository.queryConcat(thing,thePage);        map.put("查询信息", list2);        return map;    }}</code></pre><p>&nbsp;下面的是controller层</p><pre><code class="java">package com.teacher.controller;import com.teacher.pojo.Teacher;import com.teacher.service.TeacherService;import com.teacher.utils.Response;import io.swagger.annotations.Api;import io.swagger.annotations.ApiImplicitParam;import io.swagger.annotations.ApiImplicitParams;import io.swagger.annotations.ApiOperation;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.*;import org.springframework.web.servlet.ModelAndView;import javax.annotation.Resource;import java.util.List;import java.util.Map;@Api(tags = "teacher")@RestController@RequestMapping("/teacher")public class TeacherController {    @Resource    private TeacherService teacherService;    /**     * 增加老师     */    @ApiOperation(value = "增加老师")    @PostMapping("/addTeacher")    @ResponseBody    public Teacher addTeacher(String code,String name,String sex,String major,String education,String school,String faculty,String academic,int data){        Teacher teacher=new Teacher(code,name,sex,major,education,school,faculty,academic,data);        return teacherService.insertTeacher(teacher);    }    /**     * 删除老师     */    @DeleteMapping("/deleteTeacher")    @ApiOperation(value = "删除老师")    @ResponseBody    public Response deleteUser(int id){        teacherService.deleteTeacher(id);        return Response.ok("success!");    }    /**     * 修改老师     */    @PutMapping("/updateTeacher")    @ApiOperation(value = "修改老师")    @ResponseBody    public Response updateTeacher(Teacher teacher){        teacherService.updateTeacher(teacher);        return Response.ok("success!");    }    /**     * 查询所有老师     */    @GetMapping("/findAll")    @ApiOperation(value = "查询所有老师")    @ResponseBody    public List&lt;Teacher&gt; findAll(){         return teacherService.findAllTeacher();    }    /**     * 通过id查询老师     */    @GetMapping("/findTeacherById")    @ApiOperation(value = "通过id查询老师")    @ResponseBody    public Teacher findByIdyId(int id){        return teacherService.findTeacherById(id);    }    /**     * 分页查询     */    @GetMapping("/pageTest")    @ApiOperation(value = "分页查询（一页五条）")    @ResponseBody    public Map find(int pages){        return teacherService.queryTeaByPage(pages);    }    /****************************************/    /**     *根据姓名模糊查询     */    @GetMapping("/queryTeaByName")    @ApiOperation(value = "根据姓名模糊查询")    @ResponseBody    @ApiImplicitParams(            {                    @ApiImplicitParam(name = "teaName", value = "姓名", required = true),                    @ApiImplicitParam(name = "pages", value = "第几页", required = true),            }    )    public Map queryTeaByName(String teaName,int pages){        return teacherService.queryTeaByName(teaName,pages);    }    /**     *根据性别模糊查询     */    @GetMapping("/queryTeaBySex")    @ApiOperation(value = "根据性别模糊查询")    @ResponseBody    @ApiImplicitParams(            {                    @ApiImplicitParam(name = "teaSex", value = "性别", required = true),                    @ApiImplicitParam(name = "pages", value = "第几页", required = true),            }    )    public Map queryTeaBySex(String teaSex,int pages){        return teacherService.queryTeaBySex(teaSex,pages);    }    /**     *根据专业模糊查询     */    @GetMapping("/queryTeaByMajor")    @ApiOperation(value = "根据专业模糊查询")    @ResponseBody    @ApiImplicitParams(            {                    @ApiImplicitParam(name = "teaMajor", value = "专业", required = true),                    @ApiImplicitParam(name = "pages", value = "第几页", required = true),            }    )    public Map queryTeaByMajor(String teaMajor,int pages){        return teacherService.queryTeaByMajor(teaMajor,pages);    }    /**     *根据学历模糊查询     */    @GetMapping("/queryTeaByEdu")    @ApiOperation(value = "根据学历模糊查询")    @ResponseBody    @ApiImplicitParams(            {                    @ApiImplicitParam(name = "teaEducation", value = "学历", required = true),                    @ApiImplicitParam(name = "pages", value = "第几页", required = true),            }    )    public Map queryTeaByEdu(String teaEducation,int pages){        return teacherService.queryTeaByEdu(teaEducation,pages);    }    /**     *根据职称模糊查询     */    @GetMapping("/queryTeaByAcademic")    @ApiOperation(value = "根据职称模糊查询")    @ResponseBody    @ApiImplicitParams(            {                    @ApiImplicitParam(name = "teaAcademic", value = "职称", required = true),                    @ApiImplicitParam(name = "pages", value = "第几页", required = true),            }    )    public Map queryTeaByAcademic(String teaAcademic,int pages){        return teacherService.queryTeaByAcademic(teaAcademic,pages);    }    /**     *根据毕业院校模糊查询     */    @GetMapping("/queryTeaBySchool")    @ApiOperation(value = "根据毕业院校模糊查询")    @ResponseBody    @ApiImplicitParams(            {                    @ApiImplicitParam(name = "teaSchool", value = "毕业院校", required = true),                    @ApiImplicitParam(name = "pages", value = "第几页", required = true),            }    )    public Map queryTeaBySchool(String teaSchool,int pages){        return teacherService.queryTeaBySchool(teaSchool,pages);    }    /**     *根据所在院系模糊查询     */    @GetMapping("/queryTeaByFaculty")    @ApiOperation(value = "根据所在院系模糊查询")    @ResponseBody    @ApiImplicitParams(            {                    @ApiImplicitParam(name = "teaFaculty", value = "所在院系", required = true),                    @ApiImplicitParam(name = "pages", value = "第几页", required = true),            }    )    public Map queryTeaByFaculty(String teaFaculty,int pages){        return teacherService.queryTeaByFaculty(teaFaculty,pages);    }    /**     * 模糊查询     */    @GetMapping("/queryConcat")    @ApiOperation(value = "模糊查询")    @ResponseBody    @ApiImplicitParams(            {                    @ApiImplicitParam(name = "thing", value = "输入内容", required = true),                    @ApiImplicitParam(name = "pages", value = "第几页", required = true),            }    )    public Map queryConcat(String thing,int pages){        return teacherService.queryConcat(thing,pages);    }}</code></pre><p>&nbsp;接着启动项目，输入<a href="http://localhost:8080/swagger-ui.html">http://localhost:8080/swagger-ui.html</a></p><p>&nbsp;就可以看到接口了</p><p>-———————————————我是完美的分割线呜啦啦————————————————</p><p>在使用thymeleaf时，我在方法return xxx；在页面返回的是xxx，经过查阅得知，@Controller +@ResponseBody= @RestController ，也就是</p><blockquote><p>@Controller</p></blockquote><ul><li></li></ul><blockquote><p>@ResponseBody</p></blockquote><p>==</p><blockquote><p>@RestController</p></blockquote><p>如果使用@RestController注解Controller，那么该Controller中的方法，就无法返回jsp，html页面，就是说如果在方法中return “xx”，那么它只会返回”xx”的内容。</p><p>所以将controller层controller类上面的@RestController注解更换成@Controller，在方法上系上@ResponseBody注解即可返回正常的jsp，html页面。</p><p>详细实例可以参考<a href="https://blog.csdn.net/Hubery_sky/article/details/125825400" title="springboot+springdata jpa+thymeleaf项目实战_雾喔的博客-CSDN博客">springboot+springdata jpa+thymeleaf项目实战_雾喔的博客-CSDN博客</a></p><p>-———————————————我是完美的分割线呜啦啦————————————————</p><p>个人总结：</p><p>最近在准备科目一，项目的话还是零零散散的接口，或者和另一位后端小伙伴抢抢接口，总而言之我还是觉得自己写的功能有点少，虽然有一些接口麻烦一点。。。</p><p>现在也在忙着小组的招新海报，现在卡了有一阵儿了，不知道数字怎么做，其他人也没什么方法，啊，争取今天把海报的文字啥的完成。</p><p>这几天着实是有点懒散了。就在刚刚，鼠标没电了，外面也下雨了，心情也随着鼠标电量暗淡了下去，努力想想，最近好像没什么能牵动我的心情了，啊，昨天测了一下体重，发现，我居然瘦了两斤，我的两斤肉啊，好不容易养的肉肉，就这样没了！</p><p>心情低落啊，太难受了，计划着未来几天调一下生物钟，晚上十点多就睡觉，谁也别想阻挡我早点睡觉的步伐！</p><p>争取把我的肉肉弄回来，胖胖的多可爱啊呜呜呜呜，咱就说，未来一周内，我要增肥两斤+。</p>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring boot spring java 后端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>springboot+springdata jpa+thymeleaf项目实战</title>
      <link href="/2022/07/16/springboot+springdata%20jpa+thymeleaf%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"/>
      <url>/2022/07/16/springboot+springdata%20jpa+thymeleaf%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>前几天把java实训项目写好了，项目使用的是springboot+spring data jpa+thymeleaf。</p><p>对于我这个后端的孩子来说，写前端页面太折磨了。</p><p>这个是我们的项目要求，还是很简单的：</p><p><img src="https://img-blog.csdnimg.cn/7faf23748cb64f6a9146c08fbb98eca1.png"></p><p>&nbsp;</p><p>下面是properties文件的配置</p><pre><code>spring.application.name=teacher# 应用服务 WEB 访问端口server.port=8080# THYMELEAF (ThymeleafAutoConfiguration)# 开启模板缓存（默认值： true ）spring.thymeleaf.cache=false# 检查模板是否存在，然后再呈现spring.thymeleaf.check-template=true# 检查模板位置是否正确（默认值 :true ）spring.thymeleaf.check-template-location=true#Content-Type 的值（默认值： text/html ）spring.thymeleaf.content-type=text/html# 开启 MVC Thymeleaf 视图解析（默认值： true ）spring.thymeleaf.enabled=true# 模板编码spring.thymeleaf.encoding=UTF-8# 要被排除在解析之外的视图名称列表，⽤逗号分隔spring.thymeleaf.excluded-view-names=# 要运⽤于模板之上的模板模式。另⻅ StandardTemplate-ModeHandlers( 默认值： HTML5)spring.thymeleaf.mode=HTML5# 在构建 URL 时添加到视图名称前的前缀（默认值： classpath:/templates/ ）spring.thymeleaf.prefix=classpath:/templates/# 在构建 URL 时添加到视图名称后的后缀（默认值： .html ）spring.thymeleaf.suffix=.htmlspring.datasource.url=jdbc:mysql://localhost:3306/teachers?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=UTCspring.datasource.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.username=rootspring.datasource.password=12345678mybatis.mapper-locations:classpath:mapper/*Dao.xmlmybatis.type-aliases-package=com.teacher.pojomybatis.configuration.map-underscore-to-camel-case=true#自动生成数据库表（关键）spring.jpa.hibernate.ddl-auto=update#mysql数据库驱动程序（重要）#jpa配置：在控制台显示Hibernate的sql(可选)spring.jpa.show-sql = truepagehelper.helperDialect=mysqlpagehelper.reasonable=truepagehelper.supportMethodsArguments=truepagehelper.params=count=countSql</code></pre><p>这个是controller层</p><pre><code class="java">package com.teacher.controller;import com.teacher.pojo.Teacher;import com.teacher.service.TeacherService;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.*;import org.springframework.web.servlet.ModelAndView;import javax.annotation.Resource;import java.util.List;import java.util.Map;@Controller@RequestMapping("/teacher")public class TeacherController {    @Resource    private TeacherService teacherService;    /**     * 增加老师     */    @RequestMapping("/addTeacher")    public String addTeacher(String code,String name,String sex,String major,String education,String school,String faculty,String academic,int data){        Teacher teacher=new Teacher(code,name,sex,major,education,school,faculty,academic,data);        teacherService.insertTeacher(teacher);       // ModelAndView mv=new ModelAndView("teacher-main");        return "redirect:/teacher/pageTest";    }    /**     * 删除老师     */    @RequestMapping("/deleteTeacher/{id}")    public String deleteUser(@PathVariable int id){        teacherService.deleteTeacher(id);        return "redirect:/teacher/findAll";    }    //查出原来的数据    @GetMapping("/modify/{id}")    public String goUpdate(@PathVariable("id")int id, Model model){        Teacher teacher=teacherService.findTeacherById(id);        model.addAttribute("modify",teacher);        return "modify";    }    /**     * 修改老师     */    @RequestMapping("/updateTeacher")    public String updateTeacher(Teacher teacher){        teacherService.updateTeacher(teacher);        return "redirect:/teacher/pageTest";    }    /**     * 查询所有老师     */    @RequestMapping("/findAll")    public ModelAndView findAll(){        ModelAndView mv=new ModelAndView();        mv.addObject("newText","你好，Thymeleaf！");        mv.addObject("gender","1");        List&lt;Teacher&gt;teacherList= teacherService.findAllTeacher();        mv.addObject("teacherList",teacherList);        mv.setViewName("teacher-main");        return mv;    }    /**     * 通过id查询老师     */    @RequestMapping("/findTeacherById/{id}")    public ModelAndView findByIdyId(@PathVariable int id){        ModelAndView mv=new ModelAndView();        mv.addObject("teacherList",teacherService.findTeacherById(id));        mv.setViewName("findOne");        return mv;    }    /**     * 根据条件模糊查询教师     */    @RequestMapping("/queryByRe")    public ModelAndView findByIdy(String thing,String type){        ModelAndView mv=new ModelAndView();        mv.addObject("teacherList",teacherService.findTeacherByRequire(thing,type));        System.out.println(teacherService.findTeacherByRequire(thing,type));        mv.setViewName("require");        return mv;    }    /**     * 分页查询     */    @RequestMapping("/pageTest")    public ModelAndView find(@RequestParam(value = "pages",defaultValue = "1") int pages){        ModelAndView mv=new ModelAndView();        if(pages&gt;0) {            Map&lt;String, List&gt; map = teacherService.queryTeaByPage(pages);            List&lt;Integer&gt; list = map.get("总共的页数");            int totalPages = list.get(0);            List&lt;Integer&gt; list1 = map.get("总条数");            int count = list1.get(0);            List&lt;Teacher&gt; teacherList = map.get("查询信息");            mv.addObject("teacherList", teacherList);            mv.addObject("totalPages", totalPages);            mv.addObject("count", count);            mv.addObject("pages", pages);            mv.setViewName("teacher-main");            return mv;        }else{            return null;        }    }    /**     * 分页缓存     */    @RequestMapping("/page")    public String find1(@RequestParam(value = "pages")int pages){        if(pages&lt;=0){            return "redirect:/teacher/pageTest?pages=1";        }else{            return "redirect:/teacher/pageTest?pages="+pages;        }    }    /**     * 分页缓存下一页     */    @RequestMapping("/page1")    public String find2(@RequestParam(value = "pages")int pages){        Map&lt;String, List&gt; map = teacherService.queryTeaByPage(pages);        List&lt;Integer&gt; list = map.get("总共的页数");        int totalPages = list.get(0);        if(pages&gt;totalPages){            return "redirect:/teacher/pageTest?pages="+totalPages;        }else{            return "redirect:/teacher/pageTest?pages="+pages;        }    }    /**     * 模糊查询     */    @RequestMapping("/queryConcat")    public ModelAndView findByIdy1(String thing){        ModelAndView mv=new ModelAndView();        mv.addObject("teacherList",teacherService.queryConcat(thing));        mv.setViewName("require");        return mv;    }}</code></pre><p>主要的也就是在controller层了，与thymeleaf的结合。</p><p>thymeleaf实现分页，之前我在网上也找了相关教程，但是不知道咋回事都没什么效果，于是我就使用limit自己写了一个分页。</p><p>在controller层中的代码（上面代码中也有）</p><pre><code class="java">/**     * 分页查询     */    @RequestMapping("/pageTest")    public ModelAndView find(@RequestParam(value = "pages",defaultValue = "1") int pages){        ModelAndView mv=new ModelAndView();        if(pages&gt;0) {            Map&lt;String, List&gt; map = teacherService.queryTeaByPage(pages);            List&lt;Integer&gt; list = map.get("总共的页数");            int totalPages = list.get(0);            List&lt;Integer&gt; list1 = map.get("总条数");            int count = list1.get(0);            List&lt;Teacher&gt; teacherList = map.get("查询信息");            mv.addObject("teacherList", teacherList);            mv.addObject("totalPages", totalPages);            mv.addObject("count", count);            mv.addObject("pages", pages);            mv.setViewName("teacher-main");            return mv;        }else{            return null;        }    }    /**     * 分页缓存     */    @RequestMapping("/page")    public String find1(@RequestParam(value = "pages")int pages){        if(pages&lt;=0){            return "redirect:/teacher/pageTest?pages=1";        }else{            return "redirect:/teacher/pageTest?pages="+pages;        }    }    /**     * 分页缓存下一页     */    @RequestMapping("/page1")    public String find2(@RequestParam(value = "pages")int pages){        Map&lt;String, List&gt; map = teacherService.queryTeaByPage(pages);        List&lt;Integer&gt; list = map.get("总共的页数");        int totalPages = list.get(0);        if(pages&gt;totalPages){            return "redirect:/teacher/pageTest?pages="+totalPages;        }else{            return "redirect:/teacher/pageTest?pages="+pages;        }    }</code></pre><p>&nbsp;下面的两个缓存主要是为了应对用户点击上一页时避免进入空白页面而写的。</p><p>前端代码：</p><pre><code class="html">&lt;table&gt;                                &lt;thead&gt;                                &lt;tr&gt;                                    &lt;th&gt;序号&lt;/th&gt;                                    &lt;th&gt;工号&lt;/th&gt;                                    &lt;th&gt;名字&lt;/th&gt;                                    &lt;th&gt;性别&lt;/th&gt;                                    &lt;th&gt;专业&lt;/th&gt;                                    &lt;th&gt;学历&lt;/th&gt;                                    &lt;th&gt;毕业院校&lt;/th&gt;                                    &lt;th&gt;所在院系&lt;/th&gt;                                    &lt;th&gt;职称&lt;/th&gt;                                    &lt;th&gt;参加工作日期&lt;/th&gt;                                    &lt;th&gt;操作&lt;/th&gt;                                &lt;/tr&gt;                                &lt;/thead&gt;                                &lt;tbody&gt;                                &lt;tr th:each="t:${teacherList}"&gt;                                    &lt;td th:text="${t.id}"&gt;id&lt;/td&gt;                                    &lt;td th:text="${t.teaCode}"&gt;code&lt;/td&gt;                                    &lt;td th:text="${t.teaName}"&gt;name&lt;/td&gt;                                    &lt;td th:text="${t.teaSex}"&gt;sex&lt;/td&gt;                                    &lt;td th:text="${t.teaMajor}"&gt;major&lt;/td&gt;                                    &lt;td th:text="${t.teaEducation}"&gt;education&lt;/td&gt;                                    &lt;td th:text="${t.teaSchool}"&gt;school&lt;/td&gt;                                    &lt;td th:text="${t.teaFaculty}"&gt;faculty&lt;/td&gt;                                    &lt;td th:text="${t.teaAcademic}"&gt;academic&lt;/td&gt;                                    &lt;td th:text="${t.teaData}"&gt;data&lt;/td&gt;                                    &lt;td&gt;&lt;a th:href="@{'/teacher/modify/'+${t.id}}"&gt;修改&lt;/a&gt; &lt;a th:href="@{'/teacher/deleteTeacher/'+${t.id}}"&gt;删除&lt;/a&gt; &lt;/td&gt;                                &lt;/tr&gt;                                &lt;/tbody&gt;                            &lt;/table&gt;                            &lt;p&gt;当前为第&lt;span th:text="${pages}"&gt;&lt;/span&gt;页，总 &lt;span th:text="${totalPages}"&gt;&lt;/span&gt; 页,共 &lt;span th:text="${count}"&gt;&lt;/span&gt; 条记录&lt;/p&gt;                            &lt;a th:href="@{/teacher/pageTest(pages=1)}"&gt;首页&lt;/a&gt;                            &lt;a th:href="@{/teacher/page(pages=${pages}-1)}"&gt;上一页&lt;/a&gt;                            &lt;a th:href="@{/teacher/page1(pages=${pages}+1)}"&gt;下一页&lt;/a&gt;                            &lt;a th:href="@{/teacher/pageTest(pages=${totalPages})}"&gt;尾页&lt;/a&gt;</code></pre><p><img src="https://img-blog.csdnimg.cn/8b00f4c30bed47b786a06e0550b345da.png">&nbsp;</p><p>这个是呈现效果。</p><p>下面的是service层：</p><pre><code class="java">package com.teacher.service;import com.teacher.pojo.Teacher;import java.util.List;import java.util.Map;public interface TeacherService {    /**     * 增加老师     */    Teacher insertTeacher(Teacher teacher);    /**     * 删除老师     */    void deleteTeacher(int id);    /**     * 修改老师     */    Teacher updateTeacher(Teacher teacher);    /**     * 查询所有老师     */    List&lt;Teacher&gt; findAllTeacher();    /**     * 通过id查询老师     */    Teacher findTeacherById(int id);    /**     * 根据条件模糊查询教师     */    List&lt;Teacher&gt; findTeacherByRequire(String thing,String type);    /**     *分页查询全部教师     */    Map queryTeaByPage(int pages);    /**     * 模糊查询申请表数量     */    List&lt;Teacher&gt; queryConcat(String thing);}package com.teacher.service.impl;import com.teacher.pojo.Teacher;import com.teacher.repository.TeacherRepository;import com.teacher.service.TeacherService;import org.springframework.stereotype.Service;import javax.annotation.Resource;import java.util.HashMap;import java.util.LinkedList;import java.util.List;import java.util.Map;@Servicepublic class TeacherServiceImpl implements TeacherService {    @Resource    private TeacherRepository teacherRepository;    @Override    public Teacher insertTeacher(Teacher teacher) {        return teacherRepository.save(teacher);    }    @Override    public void deleteTeacher(int id) {        teacherRepository.deleteById(id);    }    @Override    public Teacher updateTeacher(Teacher teacher) {        return teacherRepository.save(teacher);    }    @Override    public List&lt;Teacher&gt; findAllTeacher() {        return teacherRepository.findAll();    }    @Override    public Teacher findTeacherById(int id) {        return teacherRepository.findById(id).orElse(null);    }    @Override    public List&lt;Teacher&gt; findTeacherByRequire(String thing,String type) {        if(type.equals("teaName")){            return teacherRepository.queryTeaByName(thing);        }        if(type.equals("teaSex")){            return teacherRepository.queryTeaBySex(thing);        }        if(type.equals("teaMajor")){            return teacherRepository.queryTeaByMajor(thing);        }        if(type.equals("teaEducation")){            return teacherRepository.queryTeaByEdu(thing);        }        if(type.equals("teaAcademic")){            return teacherRepository.queryTeaByAcademic(thing);        }        if(type.equals("teaSchool")){            return teacherRepository.queryTeaBySchool(thing);        }        if(type.equals("teaFaculty")){            return teacherRepository.queryTeaByFaculty(thing);        }else{            return null;        }    }    @Override    public Map queryTeaByPage(int pages) {        Map&lt;String,List&gt; map=new HashMap&lt;&gt;();        int num=5,totalPages,total;        int count=teacherRepository.queryTeaByPageCount();        if (count % num == 0) {            totalPages = count / num;        } else {            total = count / num;            totalPages = total + 1;        }        List&lt;Integer&gt; list = new LinkedList&lt;&gt;();        list.add(totalPages);        map.put("总共的页数", list);        List&lt;Integer&gt; list1 = new LinkedList&lt;&gt;();        list1.add(count);        map.put("总条数", list1);        int thePage = (pages - 1) * num;        List&lt;Teacher&gt; list2 = teacherRepository.queryTeaByPage( thePage, num);        map.put("查询信息", list2);        return map;    }    @Override    public List&lt;Teacher&gt; queryConcat(String thing) {        return teacherRepository.queryConcat(thing);    }}</code></pre><p>当然，尽量把逻辑层写在service层。</p><p>&nbsp;下面的是repository层：</p><pre><code class="java">package com.teacher.repository;import com.teacher.pojo.Teacher;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.jpa.repository.JpaSpecificationExecutor;import org.springframework.data.jpa.repository.Query;import org.springframework.data.repository.query.Param;import java.util.List;public interface TeacherRepository extends JpaRepository&lt;Teacher, Integer&gt;, JpaSpecificationExecutor {    @Query(value="select * from teacher where id=?",nativeQuery = true)    Teacher queryTeaByID(int id);    /**     *根据姓名模糊查询     */    @Query(value="select * from teacher where tea_name like %?%",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByName(String teaName);    /**     *根据性别模糊查询     */    @Query(value="select * from teacher where tea_sex like %?%",nativeQuery = true)    List&lt;Teacher&gt; queryTeaBySex(String teaSex);    /**     *根据专业模糊查询     */    @Query(value="select * from teacher where tea_major like %?%",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByMajor(String teaMajor);    /**     *根据学历模糊查询     */    @Query(value="select * from teacher where tea_education like %?%",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByEdu(String teaEducation);    /**     *根据职称模糊查询     */    @Query(value="select * from teacher where tea_academic like %?%",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByAcademic(String teaAcademic);    /**     *根据毕业院校模糊查询     */    @Query(value="select * from teacher where tea_school like %?%",nativeQuery = true)    List&lt;Teacher&gt; queryTeaBySchool(String teaSchool);    /**     *根据所在院系模糊查询     */    @Query(value="select * from teacher where tea_faculty like %?%",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByFaculty(String teaFaculty);    /**     *分页查询全部教师     */    @Query(value="select * from teacher limit ?1,?2",nativeQuery = true)    List&lt;Teacher&gt; queryTeaByPage(int pages,int num);    /**     *分页查询全部教师数量     */    @Query(value="select count(*) from teacher",nativeQuery = true)    int queryTeaByPageCount();    /**     * 模糊查询申请表数量     */    @Query(value = "select * from teacher where concat(tea_name,tea_sex,tea_major,tea_education,tea_academic,tea_school,tea_faculty) like concat('%',?1,'%')", nativeQuery = true)    List&lt;Teacher&gt; queryConcat(@Param("thing") String thing);}</code></pre><p>下面的是实体类：</p><pre><code class="java">package com.teacher.pojo;import lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor;import org.springframework.data.jpa.domain.support.AuditingEntityListener;import javax.persistence.*;@Data@AllArgsConstructor@NoArgsConstructor@Entity@Table(name="teacher")@EntityListeners(AuditingEntityListener.class)public class Teacher{    @Id    @Column(name = "id")    @GeneratedValue(strategy = GenerationType.IDENTITY)    private int id;    @Column(name = "tea_code")    private String teaCode;    @Column(name = "tea_name")    private String teaName;    @Column(name = "tea_sex")    private String teaSex;    @Column(name = "tea_major")    private String teaMajor;    @Column(name = "tea_education")    private String teaEducation;    @Column(name = "tea_school")    private String teaSchool;    @Column(name = "tea_faculty")    private String teaFaculty;    @Column(name = "tea_academic")    private String teaAcademic;    @Column(name = "tea_data")    private int teaData;    public Teacher(String teaCode, String teaName, String teaSex, String teaMajor, String teaEducation, String teaSchool, String teaFaculty, String teaAcademic, int teaData) {        this.teaCode = teaCode;        this.teaName = teaName;        this.teaSex = teaSex;        this.teaMajor = teaMajor;        this.teaEducation = teaEducation;        this.teaSchool = teaSchool;        this.teaFaculty = teaFaculty;        this.teaAcademic = teaAcademic;        this.teaData = teaData;    }}</code></pre><p>&nbsp;下面是pom文件在项目建成后加的依赖：</p><pre><code>&lt;!--spring-data-jpa--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;!-- https://mvnrepository.com/artifact/org.mybatis.spring.boot/mybatis-spring-boot-starter --&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;            &lt;version&gt;2.2.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--mysql--&gt;        &lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;            &lt;version&gt;8.0.28&lt;/version&gt;            &lt;scope&gt;runtime&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><p>下面的是我的页面展示效果（页面比较丑，大家做好心理准备）：</p><p>下面的是主页</p><p><img src="https://img-blog.csdnimg.cn/07678be28e6b45e88892115e37312370.png">&nbsp;</p><p>这个是录入教师</p><p><img src="https://img-blog.csdnimg.cn/95ca33931eb74b7cbe0ddd23ad467f93.png">&nbsp;</p><p>这个是教师查询：</p><p><img src="https://img-blog.csdnimg.cn/a12d6b3614bc44989177bcdcf9e61eb0.png">&nbsp;</p><p>下面的是我的查询后跳转的页面（为了偷懒，没有写分页）：</p><p><img src="https://img-blog.csdnimg.cn/08eeb886c8324a1692ddeed58d8eab67.png">&nbsp;</p><p>这个是修改页面：</p><p><img src="https://img-blog.csdnimg.cn/c1d83e1ebe6d478189ce9bedca059257.png">&nbsp;</p><p>&nbsp;原本我想要的效果是局部更新，但是经询问前端孩子之后，我决定放弃局部更新转为多写几个页面。</p><p>近日总结：</p><p>最近其实大部分时间是比较闲一点的，我们的项目我负责的接口已经写完了，这几天也是写一些零零散散的前端需要的接口，特别是实训项目完成后，闲的感觉更甚。</p><p>对于未来一段时间，我打算考驾照，先把科目一和科目二过了，其他的看时间安排，还有就是学英语，复习java基础知识，每天一道剑指offer。</p>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java 大数据 spring spring boot 后端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis.conf的一些配置+密码的设置（mac）+个人总结</title>
      <link href="/2022/06/18/redis.conf%E7%9A%84%E4%B8%80%E4%BA%9B%E9%85%8D%E7%BD%AE+%E5%AF%86%E7%A0%81%E7%9A%84%E8%AE%BE%E7%BD%AE%EF%BC%88mac%EF%BC%89+%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/"/>
      <url>/2022/06/18/redis.conf%E7%9A%84%E4%B8%80%E4%BA%9B%E9%85%8D%E7%BD%AE+%E5%AF%86%E7%A0%81%E7%9A%84%E8%AE%BE%E7%BD%AE%EF%BC%88mac%EF%BC%89+%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>首先连接你的linux</p><blockquote><p>ssh -q -l root -p 22 你的服务器ip地址&nbsp;</p></blockquote><p>输入密码</p><p>连接成功！</p><p>Redis的配置文件默认在<code>/etc/redis.conf</code></p><blockquote><p>vi /etc/redis.conf&nbsp;</p></blockquote><p>咱们的redis.conf文件在etc下</p><p>进去之后,划到底部（我的是mac os系统）</p><p>shift+# 之后点击cc（我是这么做的，之后就可以编辑文件了）</p><p><img src="https://img-blog.csdnimg.cn/be9d09c724a8428d95d95096d72c7461.png" alt="be9d09c724a8428d95d95096d72c7461.png"></p><p>找到</p><p><img src="https://img-blog.csdnimg.cn/89274d52cdaf45fe8e5433bb3be9af74.png" alt="89274d52cdaf45fe8e5433bb3be9af74.png"></p><p><strong>bing 127.0.0.1：绑定的ip</strong>，在保护模式开启的情况下，只有绑定的ip才可以访问redis服务</p><p>默认情况下 <code>bind=127.0.0.1</code> 只能接受本机的访问请求，注释掉可以远程</p><p><img src="https://img-blog.csdnimg.cn/1a6f7271d3ce487a9017aabbbba2fc97.png" alt="1a6f7271d3ce487a9017aabbbba2fc97.png">no：保护模式关闭，外网可以直接访问redis，不安全</p><p>yes：保护模式开启，访问redis服务需要通过bind绑定的IP进行访问或者通过设置的密码进行访问</p><p><img src="https://img-blog.csdnimg.cn/fd44c6b931984d7dbd365587fc0550c1.png" alt="fd44c6b931984d7dbd365587fc0550c1.png"></p><p>no：客户端运行，客户端关闭redis服务也停止</p><p>yes：后台运行，客户端关闭redis服务也在运行</p><p><img src="https://img-blog.csdnimg.cn/281e25b29ee04aa29b9b31990c06ae84.png" alt="281e25b29ee04aa29b9b31990c06ae84.png"></p><p><img src="https://img-blog.csdnimg.cn/d2669cf9ba734929a68948d7a84a7c9d.png" alt="d2669cf9ba734929a68948d7a84a7c9d.png"></p><p>&nbsp;设置你的登录密码</p><p>之后划到最下面</p><p>点击esc退出修改文本</p><p>输入&nbsp; &nbsp;</p><blockquote><p>:wq</p></blockquote><p>即保存退出</p><p>查看进程</p><blockquote><p>ps -ef |grep redis</p></blockquote><p>关闭进程</p><blockquote><p>kill -9 你的进程号</p></blockquote><p>启动redis服务</p><blockquote><p>redis-server /etc/redis.conf&nbsp;</p></blockquote><p>然后进入&nbsp;</p><blockquote><p>redis-cli -h 127.0.0.1 -p 6379&nbsp;</p></blockquote><p>&nbsp;<img src="https://img-blog.csdnimg.cn/358a3accc6744db19751c7d54050a68e.png" alt="358a3accc6744db19751c7d54050a68e.png"></p><p>&nbsp;验证</p><blockquote><p>keys *</p></blockquote><p>&nbsp;<img src="https://img-blog.csdnimg.cn/669f5c071f754850b44f2906be84a83f.png" alt="669f5c071f754850b44f2906be84a83f.png"></p><p>会报错，因为需要密码，没有密码是没有权限的</p><blockquote><p>auth password&nbsp;</p></blockquote><p>&nbsp;<img src="https://img-blog.csdnimg.cn/d99f86e06eb849cc9e3634136c07a4bf.png" alt="d99f86e06eb849cc9e3634136c07a4bf.png"></p><p>&nbsp;就有权限了</p><p>也可以直接在进去的时候加上密码</p><blockquote><p>redis-cli -h 127.0.0.1 -p 6379 -a password</p></blockquote><p>&nbsp;<img src="https://img-blog.csdnimg.cn/430db8ac853b4a84b1d117ddb86f58e5.png" alt="430db8ac853b4a84b1d117ddb86f58e5.png"></p><p>&nbsp;警告可以不用管他</p><p>完结撒花🎉</p><p>（经查询得知（我也是刚学习的小白，如果有什么问题，欢迎下面评论区指出）：</p><p>在命令行下输入 vim /etc/文件名.conf编辑（本人用的vi /etc/redis.conf）</p><p>按 i 进入编辑模式，可以编辑文本</p><p>按esc键，退出修改文本</p><p>输入 :wq保存并退出（一定要有冒号哦）</p><p>完结撒花🎉</p><p><strong>个人总结：</strong></p><p>哎，疲于配置各种东西，正文进度太慢了。</p><p>今天突然被当头一棒，学长学姐们已经进入大三了啊，我也已经步入大二了啊，他们也都快要离开我们了，我们很快就要接管一些事务，而现在的我还在依赖着学长，遇到问题后百度是常态，但当百度一直找不到我要的结果或解决不了我的问题时，我还是会把目光投向学长，向学长寻求帮助，可是，学长们已经大三了啊，他们也在开始更加认真的备战工作面试等事情，他们只会更忙，再开学我们这一届也就要成为学长学姐带下一届了，而现在的我却连解决问题的能力也没有完全培养出来，如果学弟学妹问我问题我不会我要怎么回答？去百度？百度不出来再问去学长？</p><p>别闹了好吗。</p><p>趁着暑假，这三个月时间，我会努力培养自己解决问题的能力，不再依赖别人，自己独立自强。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis 数据库 java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>linux下搭建redis+设置密码</title>
      <link href="/2022/06/16/linux%E4%B8%8B%E6%90%AD%E5%BB%BAredis+%E8%AE%BE%E7%BD%AE%E5%AF%86%E7%A0%81/"/>
      <url>/2022/06/16/linux%E4%B8%8B%E6%90%AD%E5%BB%BAredis+%E8%AE%BE%E7%BD%AE%E5%AF%86%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>&nbsp;redis下载<a href="https://redis.io/download/" title="Download | Redis">Download | Redis</a></p><p>首先，在本地连接服务器</p><blockquote><p>ssh -q -l root -p 22 你的服务器ip地址</p></blockquote><p>输入密码</p><p>之后就是下面，连接成功</p><p><img src="https://img-blog.csdnimg.cn/85bcb1f3eaa14c9789ed9f54fb2fb433.png"></p><p>搭建redis需要c语言环境</p><p>可以先检测一下你是否已经安装了gcc</p><blockquote><p>gcc --version</p></blockquote><p>已经安装的话会是下面那样&nbsp;</p><p><img src="https://img-blog.csdnimg.cn/e5da368a98b6483fba3c803137d8a681.png">&nbsp;如果没有安装的话，按照下面的步骤依次进行</p><blockquote><p>yum install centos-release-scl scl-utils-build</p></blockquote><blockquote><p>yum install -y devtoolset-8-toolchain</p></blockquote><blockquote><p>scl enable devtoolset-8 bash</p></blockquote><p>或者</p><blockquote><p>yum install -y gcc&nbsp;</p></blockquote><p>或者</p><blockquote><p>apt-get install -y gcc&nbsp;</p></blockquote><p>之后通过wget下载</p><blockquote><p>wget https:/ /download. redis. io/ releases/redis-你要下载的redis版本.tar.gz&nbsp;</p></blockquote><p>解压至当前目录&nbsp;</p><blockquote><p>tar -zxvf redis-你要下载的redis版本.tar.gz&nbsp;</p></blockquote><blockquote><p>cd redis-&nbsp;你要下载的redis版本</p></blockquote><p>执行make</p><blockquote><p>make</p><p>make install&nbsp;</p></blockquote><p>&nbsp;判断是否安装成功</p><blockquote><p>cd /usr/local/bin</p><p>ls</p></blockquote><p>安装成功则会&nbsp;<img src="https://img-blog.csdnimg.cn/ed7b9bb5de2543c19622a9c5d5282727.png"></p><p>&nbsp;启动分为前台启动和后台启动，推荐通过后台启动</p><p>前台启动：</p><p>关闭此窗口后就会停止运行</p><blockquote><p>redis-server</p></blockquote><p><img src="https://img-blog.csdnimg.cn/36ad657366cf4e3daeacfcf0e07df639.png"></p><p>&nbsp;按住control+c即可退出</p><p>查看redis是否在运行</p><blockquote><p>ps -ef |grep redis</p></blockquote><p>或</p><blockquote><p>ps -aux|grep redis&nbsp;</p></blockquote><p>后台启动：</p><p>将/redis.conf复制到/etc下</p><blockquote><p>cp redis. conf /etc/ redis. conf</p></blockquote><p>将redis.conf的daemonize no修改为daemonize yes&nbsp;</p><blockquote><p>vim redis.conf# daemonize no 修改为daemonize yes</p></blockquote><p>在/usr/local.bin目录下启动redis：</p><blockquote><p>redis-server /etc/redis. conf</p></blockquote><p>关闭</p><blockquote><p>redis-cli shutdown</p></blockquote><p>&nbsp;或</p><p><img src="https://img-blog.csdnimg.cn/a4aa11c6a17d4045afa2938192e300cf.png"></p><blockquote><p>kill -9 进程号</p></blockquote><p>完结撒花🎉</p><p>查找redis安装目录</p><blockquote><p>whereis redis</p></blockquote><p>后面的话最好设置一下密码</p><p>我在设置永久密码的时候无法编辑redis.conf文件，查找了相关资料也没有找到问题出在哪里</p><p>设置永久密码大家可以参考这位大佬的文章</p><p>先</p><blockquote><p>vim /etc/redis.conf</p></blockquote><p><a href="https://www.shuzhiduo.com/A/q4zV4ZaG5K/" title="转：Redis设置认证密码 Redis使用认证密码登录 在Redis集群中使用认证密码">转：Redis设置认证密码 Redis使用认证密码登录 在Redis集群中使用认证密码</a></p><p>下面是临时密码的设置</p><p>打开redis，依次执行下列操作</p><blockquote><p>redis-cli</p><p>config get requirepass</p><p>config set requirepass 你的密码&nbsp;</p></blockquote><p>设置完成后输入exit退出</p><p>验证的话也可以参考上面那位大佬的文章</p><p>完结撒花🎉&nbsp;</p><p>redis默认有16个数据库，类似数组下标从0开始，初始默认使用0</p><p>号库</p><p><img src="https://img-blog.csdnimg.cn/c256ab9e1d8c43aeb5e195226aaa4072.png"></p>]]></content>
      
      
      <categories>
          
          <category> 中间件&amp;amp;服务框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 服务器 linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>idea右侧的maven项目下的tomcat7插件报红</title>
      <link href="/2022/04/03/idea%E5%8F%B3%E4%BE%A7%E7%9A%84maven%E9%A1%B9%E7%9B%AE%E4%B8%8B%E7%9A%84tomcat7%E6%8F%92%E4%BB%B6%E6%8A%A5%E7%BA%A2/"/>
      <url>/2022/04/03/idea%E5%8F%B3%E4%BE%A7%E7%9A%84maven%E9%A1%B9%E7%9B%AE%E4%B8%8B%E7%9A%84tomcat7%E6%8F%92%E4%BB%B6%E6%8A%A5%E7%BA%A2/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>这是已解决的样子<img src="https://img-blog.csdnimg.cn/c742f71d8d504c92a0d39f8cef1c57a5.jpg?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zu-5ZaU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>刚开始Tomcat7插件报红，大约这个样子<img src="https://img-blog.csdnimg.cn/8392957a46e3490286cb63319947892c.jpg?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zu-5ZaU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>(之后修改好之后我把相关修改的地方去掉，重新启动，tomcat7很奇怪的没有再报错，希望有大佬告知原因~)</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="* 解决方法 *"></a>* 解决方法 *</h1><p>来到pom.xml下，找到自己引入tomcat7插件的地方，这是我之前的配置<br><img src="https://img-blog.csdnimg.cn/f1342c2ce1a7439085cd8ee13e15c129.jpg?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zu-5ZaU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>这是更改后的配置<br><img src="https://img-blog.csdnimg.cn/7940a54ceb7b4f419a441fa4e4da1518.jpg?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zu-5ZaU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br>7070是我的端口号，大家修改成自己的端口号就可。<br>这么修改之后，可以看到右侧的maven下的tomcat7插件已经不报红了。</p>]]></content>
      
      
      <categories>
          
          <category> 报错 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tomcat 经验分享 maven 其他 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>foreach，Thymeleaf相关jar包的下载，spring，数据库的概念</title>
      <link href="/2022/04/02/foreach%EF%BC%8CThymeleaf%E7%9B%B8%E5%85%B3jar%E5%8C%85%E7%9A%84%E4%B8%8B%E8%BD%BD%EF%BC%8Cspring%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%A6%82%E5%BF%B5/"/>
      <url>/2022/04/02/foreach%EF%BC%8CThymeleaf%E7%9B%B8%E5%85%B3jar%E5%8C%85%E7%9A%84%E4%B8%8B%E8%BD%BD%EF%BC%8Cspring%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1 id="foreach"><a href="#foreach" class="headerlink" title="foreach"></a><em>foreach</em></h1><p>java里面的for循环的格式: for(String s : arr)是什么意思<br>NaNfor的循环语句for(String s : args)这个格式是foreach的形式，表示取出数组args[]中的每一个元素，就是循环一次就依次取出一个元素赋值给s，直到取完为止java中的foreach也是用for表示具体语法分两种：第一种-数组for(type var : arr) {//循环体}示例（这里以List为例）：<br>Listlist = new ArrayList();<br>for(String item : list){<!-- --><br>System.out.println(“循环元素：” + item);<br>}<br>第二种-非数组类可迭代对象for(type var : coll) {//循环体}示例：<br>Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();<br>for(Entry&lt;String, String&gt; item : map.entrySet()){<!-- --><br>System.out.println(“循环元素 key:” + item.getKey() + “ value:” + item.getValue());<br>}<br>其实本质上和for(int i=0;i&lt;length;i++)没太大区别，但是for(String s : arr)中的arr一定是字符串数组，每次循环取一个字符串出来赋值给s，直到arr数组长度-1结束。<br>for(String s:array)</p><h1 id="thymeleaf相关包的下载"><a href="#thymeleaf相关包的下载" class="headerlink" title="thymeleaf相关包的下载"></a>thymeleaf相关包的下载</h1><p>attoparser-2.0.5.RELEASE.jar包下载地址<br><a href="https://mvnrepository.com/artifact/org.attoparser/attoparser/2.0.5.RELEASE">https://mvnrepository.com/artifact/org.attoparser/attoparser/2.0.5.RELEASE</a><br>点击jar就可<br>当然下载jar包去<a href="https://mvnrepository.com/%E8%BF%99%E4%B8%AA%E7%BD%91%E7%AB%99%E5%8E%BB%E6%89%BE%E5%B0%B1%E5%8F%AF">https://mvnrepository.com/这个网站去找就可</a><br>我看视频的thymeleaf相关jar包是这些：<br><img src="https://img-blog.csdnimg.cn/10aabd71becb4b89a1f7307ecd0041bc.jpg?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zu-5ZaU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p><h1 id="spring"><a href="#spring" class="headerlink" title="spring"></a>spring</h1><p>Spring是轻量级的开源的javaEE框架<br>目的：解决企业应用开发的复杂性</p><h3 id="Spring有两个核心部分：IOC和AOP"><a href="#Spring有两个核心部分：IOC和AOP" class="headerlink" title="Spring有两个核心部分：IOC和AOP"></a>Spring有两个核心部分：IOC和AOP</h3><p>&lt;1&gt;IOC：控制反转，把创建的对象过程交给Spring进行管理<br>&lt;2&gt;AOP：面向切面，不修改源代码进行功能增强</p><h3 id="Spring特点"><a href="#Spring特点" class="headerlink" title="Spring特点"></a>Spring特点</h3><p>&lt;1&gt;方便解耦，简化开发<br>&lt;2&gt;AOP编程支持<br>&lt;3&gt;方便程序的测试<br>&lt;4&gt;方便和其他框架进行整合<br>&lt;5&gt;方便进行事物操作<br>&lt;6&gt;降低API开发难度</p><h3 id="注解："><a href="#注解：" class="headerlink" title="注解："></a>注解：</h3><p>@AutoWired 根据属性类型自动装配</p><p>@Qualifier 根据属性名称注入<br>需要和@AutoWired一起使用<br>@Resource 可以根据类型注入 可以根据名称注入（是javax里的resourse）</p><p>@Value 注入普通类型属性<br>建议使用@AutoWired和@Qualifier</p><h1 id="数据库的概念"><a href="#数据库的概念" class="headerlink" title="数据库的概念"></a>数据库的概念</h1><p>数据库是按照一定的数据结构来组织、存储和管理数据的仓库数据库管理系统(Dta<br>Base Management System DBMS）是一种操纵和管理数据库的大件,用于建立,使用和<br>维护数据库;而数据库系统( database system)由数据库,数据管理系统以及应用程序<br>成。为了能够使用户访问和更新数据库,需要在数据库管理系统上建立应用程序因此,可<br>以把应用程序视为用户与数据库之间的接口。应用程序可以是单机上的应用程序,也可以<br>是Web应用程序,并且可以在网络上访问多个不同的数据库系统,</p>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring 经验分享 数据库开发 其他 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java笔记</title>
      <link href="/2022/03/26/java%E7%AC%94%E8%AE%B0/"/>
      <url>/2022/03/26/java%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1 id="八种基本数据类型："><a href="#八种基本数据类型：" class="headerlink" title="八种基本数据类型："></a>八种基本数据类型：</h1><p>基本数据类型如下：<br>1、整数型：byte（字节型）、short（短整型）、int（整型）、long（长整型）。<br>2、浮点型：float（单精度浮点）、double（双精度浮点）.<br>3、字符型：char（字符型）。<br>4、布尔型：boolean（布尔型）。</p><h1 id="面向对象："><a href="#面向对象：" class="headerlink" title="面向对象："></a>面向对象：</h1><p>java语言最吸引人之处，就在于它是一种以对象为中心，以消息为驱动的面向对象的编程语言。面向对象的编程语言都支持封装，继承，多态三个概念，java语言也是如此。</p><h1 id="抛出异常有三种形式："><a href="#抛出异常有三种形式：" class="headerlink" title="抛出异常有三种形式："></a>抛出异常有三种形式：</h1><p>①系统自动抛出 ②throws ③throw<br>①系统自动抛出 ：当程序出现一些逻辑错误、转换错误时，系统会自动抛出异常除数为0还会抛出ArithmeticException（算数异常），这里不一一例举，同学们自己在工具上实验。<br>②throws 用来标明一个成员函数可能抛出的各种“异常”。出现在方法头。这也是我们经常用的一个。<br>③ throw 语句用来明确地抛出一个“异常”。<br>eg：</p><pre><code class="java">int a=5;int b=1;if(b==0){throw new   ArithmeticException();}else{System.out.println(a/b);}}</code></pre><h1 id="Static-静态方法-："><a href="#Static-静态方法-：" class="headerlink" title="Static(静态方法)："></a>Static(静态方法)：</h1><pre><code>   static可以用来修饰成员变量、成员方法以及代码块等，被static关键字修饰的成员都会具备一些特殊属性。 在类中，被static修饰的方法称作静态方法。同静态变量一样，如果该静态方法的访问权限高于private，则该静态方法可通过“类名.方法名”直接调用，而不需要创建对象调用。</code></pre><h1 id="与equals"><a href="#与equals" class="headerlink" title="==与equals"></a>==与equals</h1><p>1.”” 的作用是判断两个对象的地址是不是相等。即判断两个对象是不是同一个对象。(基本数据类型比较的是值，引用数据类型比较的是内存地址)<br>2.equals() : 它的作用也是判断两个对象是否相等。但它一般有两种使用情况：<br>类没有覆盖equals()方法。则通过equals()比较该类的两个对象时，等价于通过“”比较这两个对象。<br>类覆盖了equals()方法。一般，我们都覆盖equals()方法来两个对象的内容相等；若它们的内容相等，则返回true(即，认为这两个对象相等)。<br>equals方法实现的等价关系如下：<br>1.自反性，对于任何非null的引用值x，x.equals(x)必须返回true。<br>若覆盖时违反这一条等价关系，则把该类的实例添加到集合中，该集合的contains方法将告诉你，该集合不包含这个实例。<br>2.对称性，对于任何非null的引用值x和y，当且仅当y.equals(x)返回true时，x.equals(y)必须返回true。<br>3.传递性，对任何非null的引用值x、y和z，如果x.equals(y)返回true，并y.equals(z)返回true，那么x.equals(z)也应该返回true。</p><h1 id="JavaWeb三大组件"><a href="#JavaWeb三大组件" class="headerlink" title="JavaWeb三大组件"></a>JavaWeb三大组件</h1><p>Servlet ，Filter，Listenner</p><h1 id="list-isEmpty-list-size-0-listnull的区别："><a href="#list-isEmpty-list-size-0-listnull的区别：" class="headerlink" title="list.isEmpty() list.size()0 listnull的区别："></a>list.isEmpty() list.size()0 listnull的区别：</h1><ol><li><p>isEmpty()方法是用来判断集合中有没有元素</p></li><li><p>size（）方法是判断集合中的元素个数</p></li><li><p>isEmpty（）和size（）==0意思一样</p></li><li><p>if（list ==null）是判断有没有这个集合<br>BeanHandler:表示把结果集中的一行数据，封装成一个对象，专门针对结果集中只有一行数据的情况。</p></li></ol><p>BeanListHandler:表示把结果集中的多行数据，封装成一个对象的集合，针对结果集中有多行数据。</p><h1 id="return的两种用法："><a href="#return的两种用法：" class="headerlink" title="return的两种用法："></a>return的两种用法：</h1><p>一个是返回方法指定类型的值（这个值总是确定的）。</p><p>一个是结束方法的执行（仅仅一个return语句）。</p>]]></content>
      
      
      <categories>
          
          <category> java基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 经验分享 其他 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>springmvc固定代码</title>
      <link href="/2022/03/24/springmvc%E5%9B%BA%E5%AE%9A%E4%BB%A3%E7%A0%81/"/>
      <url>/2022/03/24/springmvc%E5%9B%BA%E5%AE%9A%E4%BB%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>springmvc 固定代码<br>src/main/resources/springmvc-servlet.xml</p><pre><code class="java">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans"       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"       xmlns:context="http://www.springframework.org/schema/context"       xmlns:mvc="http://www.springframework.org/schema/mvc"       xsi:schemaLocation="http://www.springframework.org/schema/beans       http://www.springframework.org/schema/beans/spring-beans.xsd       http://www.springframework.org/schema/context       https://www.springframework.org/schema/context/spring-context.xsd       http://www.springframework.org/schema/mvc       https://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt;    &lt;!-- 自动扫描包，让指定包下的注解生效,由IOC容器统一管理 --&gt;    &lt;context:component-scan base-package="com.ysy.controller"/&gt;    &lt;!-- 让Spring MVC不处理静态资源 --&gt;    &lt;mvc:default-servlet-handler /&gt;    &lt;!--    支持mvc注解驱动        在spring中一般采用@RequestMapping注解来完成映射关系        要想使@RequestMapping注解生效        必须向上下文中注册DefaultAnnotationHandlerMapping        和一个AnnotationMethodHandlerAdapter实例        这两个实例分别在类级别和方法级别处理。        而annotation-driven配置帮助我们自动完成上述两个实例的注入。     --&gt;    &lt;mvc:annotation-driven /&gt;    &lt;!-- 视图解析器 --&gt;    &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"          id="internalResourceViewResolver"&gt;        &lt;!-- 前缀 --&gt;        &lt;property name="prefix" value="/WEB-INF/jsp/" /&gt;        &lt;!-- 后缀 --&gt;        &lt;property name="suffix" value=".jsp" /&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><p>web/WEB-INF/web.xml</p><pre><code class="java">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee"         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd"         version="4.0"&gt;    &lt;!--1.注册DispatcherServlet--&gt;    &lt;servlet&gt;        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;        &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;        &lt;!--关联一个springmvc的配置文件:【servlet-name】-servlet.xml--&gt;        &lt;init-param&gt;            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;            &lt;param-value&gt;classpath:springmvc-servlet.xml&lt;/param-value&gt;        &lt;/init-param&gt;        &lt;!--启动级别-1--&gt;        &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;    &lt;/servlet&gt;    &lt;!--/ 匹配所有的请求；（不包括.jsp）--&gt;    &lt;!--/* 匹配所有的请求；（包括.jsp）--&gt;    &lt;servlet-mapping&gt;        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;        &lt;url-pattern&gt;/&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;&lt;/web-app&gt;```</code></pre>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mybatis固定代码</title>
      <link href="/2022/03/24/mybatis%E5%9B%BA%E5%AE%9A%E4%BB%A3%E7%A0%81/"/>
      <url>/2022/03/24/mybatis%E5%9B%BA%E5%AE%9A%E4%BB%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>mybatis固定代码</p><p>首先是pom.xml</p><pre><code class="java">&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0"         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;!--父工程--&gt;    &lt;groupId&gt;org.example&lt;/groupId&gt;    &lt;artifactId&gt;mybatis_Study&lt;/artifactId&gt;    &lt;packaging&gt;pom&lt;/packaging&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;modules&gt;        &lt;module&gt;mybatis-01&lt;/module&gt;        &lt;module&gt;mybatis-02&lt;/module&gt;        &lt;module&gt;mybatis-03&lt;/module&gt;        &lt;module&gt;mybatis-04&lt;/module&gt;        &lt;module&gt;mybatis-05&lt;/module&gt;        &lt;module&gt;mybatis-06&lt;/module&gt;        &lt;module&gt;mybatis-07&lt;/module&gt;    &lt;/modules&gt;    &lt;repositories&gt;        &lt;repository&gt;            &lt;id&gt;central&lt;/id&gt;            &lt;name&gt;aliyun maven&lt;/name&gt;            &lt;url&gt;https://maven.aliyun.com/repository/public/&lt;/url&gt;            &lt;layout&gt;default&lt;/layout&gt;            &lt;!-- 是否开启发布版构件下载 --&gt;            &lt;releases&gt;                &lt;enabled&gt;true&lt;/enabled&gt;            &lt;/releases&gt;            &lt;!-- 是否开启快照版构件下载 --&gt;            &lt;snapshots&gt;                &lt;enabled&gt;false&lt;/enabled&gt;            &lt;/snapshots&gt;        &lt;/repository&gt;    &lt;/repositories&gt;    &lt;!--导入依赖--&gt;    &lt;dependencies&gt;        &lt;!--mysql驱动--&gt;        &lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;            &lt;version&gt;8.0.28&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--mybatis--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;            &lt;artifactId&gt;mybatis&lt;/artifactId&gt;            &lt;version&gt;3.5.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--junit--&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;4.12&lt;/version&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;log4j&lt;/groupId&gt;            &lt;artifactId&gt;log4j&lt;/artifactId&gt;            &lt;version&gt;1.2.12&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;version&gt;1.18.22&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;!--在bulid中配置resource，来防止我们资源导出失败的问题--&gt;&lt;build&gt;        &lt;resources&gt;            &lt;resource&gt;                &lt;directory&gt;src/main/java&lt;/directory&gt;                &lt;includes&gt;                    &lt;include&gt;**/*.properties&lt;/include&gt;                    &lt;include&gt;**/*.xml&lt;/include&gt;                &lt;/includes&gt;                &lt;filtering&gt;false&lt;/filtering&gt;            &lt;/resource&gt;            &lt;resource&gt;                &lt;directory&gt;src/main/resources&lt;/directory&gt;                &lt;includes&gt;                    &lt;include&gt;**/*.properties&lt;/include&gt;                    &lt;include&gt;**/*.xml&lt;/include&gt;                &lt;/includes&gt;                &lt;filtering&gt;false&lt;/filtering&gt;            &lt;/resource&gt;        &lt;/resources&gt;&lt;/build&gt;&lt;/project&gt;</code></pre><p>src/main/java/com.ysy/utils</p><pre><code class="java">package com.ysy.utils;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import javax.annotation.Resource;import java.io.IOException;import java.io.InputStream;//工具类，用来获取sqlSessionFactory--》sqlSessionpublic class MybatisUtils {    private static SqlSessionFactory sqlSessionFactory;    static{        try {            //使用Mybatis第一次获取SessionFactory对象            String resource="mybatis-config.xml";            InputStream inputStream = Resources.getResourceAsStream(resource);            sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);        } catch (IOException e) {            e.printStackTrace();        }    }    //既然有了 SqlSessionFactory，顾名思义，我们可以从中获得 SqlSession 的实例。    // SqlSession 提供了在数据库执行 SQL 命令所需的所有方法。你可以通过 SqlSession 实例来直接执行已映射的 SQL 语句。    public static SqlSession getSession(){        return sqlSessionFactory.openSession();    }}</code></pre><p>接口的xml文件</p><pre><code class="java">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper        PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"        "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;!--namespace=绑定一个对应的Dao/Mapper接口--&gt;&lt;mapper namespace="com.ysy.dao.UserMapper"&gt; &lt;!--包/名/类--&gt;&lt;!--select * from test1.user where id=?select * from test1.user where id=1 or 1=1使用到模糊查询时"%"#{value}"%"要这样写死--&gt;    &lt;select id="getUserLike" resultType="com.ysy.pojo.User"&gt;        select * from test1.user where name like "%"#{value}"%"    &lt;/select&gt;    &lt;!--select查询语句--&gt;    &lt;select id="selectUser" resultType="com.ysy.pojo.User"&gt;    select * from user  &lt;/select&gt;    &lt;select id="getUserById" parameterType="int" resultType="com.ysy.pojo.User"&gt;        select * from test1.user where id=#{id}    &lt;/select&gt;    &lt;!--对象中的属性，可以直接取出来--&gt;    &lt;insert id="addUser" parameterType="com.ysy.pojo.User"&gt;        insert into test1.user(id,name,pwd)values(#{id},#{name},#{pwd});    &lt;/insert&gt;&lt;!--Map  传递map的key--&gt;    &lt;insert id="addUser2" parameterType="map"&gt;        insert into test1.user(id,name,pwd)values(#{userId},#{userName},#{password});    &lt;/insert&gt;    &lt;!--ǧλ 潻 ͬ ˵ ֻҪ ﵽһ ġ ǿ ɿ Խ Լ TENGZIYUE$B$5$^(B$BF|K\8lG=NO  乱码测试--&gt;    &lt;update id="updateUser" parameterType="com.ysy.pojo.User"&gt;        update test1.user set name=#{name},pwd=#{pwd} where id=#{id};    &lt;/update&gt;    &lt;delete id="deleteUser" parameterType="com.ysy.pojo.User"&gt;        delete from test1.user where id=#{id};    &lt;/delete&gt;&lt;/mapper&gt;</code></pre><p>resources中的mybatis-config.xml的配置</p><pre><code class="java">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration        PUBLIC "-//mybatis.org//DTD Config 3.0//EN"        "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;!--核心配置文件--&gt;&lt;configuration&gt;    &lt;environments default="development"&gt;        &lt;environment id="development"&gt;            &lt;transactionManager type="JDBC"/&gt;            &lt;dataSource type="POOLED"&gt;                &lt;property name="driver" value="com.mysql.cj.jdbc.Driver"/&gt;                &lt;property name="url" value="jdbc:mysql://localhost:3306/test1?useSSL=true&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf8"/&gt;                &lt;property name="username" value="root"/&gt;                &lt;property name="password" value="12345678"/&gt;            &lt;/dataSource&gt;        &lt;/environment&gt;    &lt;/environments&gt;    &lt;!--每一个Mapper。xml都需要在MyBatis核心配置文件中注册--&gt;    &lt;mappers&gt;        &lt;mapper resource="com/ysy/dao/UserMappr.xml"/&gt;  &lt;!--resource是一个资源路径 用/隔开--&gt;    &lt;/mappers&gt;&lt;/configuration&gt;</code></pre><p>/test/java/com.ysy.dao/UserDaoTest</p><pre><code class="java">package com.ysy.dao;import com.ysy.pojo.User;import com.ysy.utils.MybatisUtils;import org.apache.ibatis.session.SqlSession;import org.junit.Test;import java.util.HashMap;import java.util.List;import java.util.Map;public class UserDaoTest {    @Test    public void selectUser() {        SqlSession session = MybatisUtils.getSession();        //方法一:        //List&lt;User&gt; users = session.selectList("com.ysy.mapper.UserMapper.selectUser");        //方法二:        UserMapper mapper = session.getMapper(UserMapper.class);        List&lt;User&gt; users = mapper.selectUser();        for (User user: users){            System.out.println(user);        }        session.close();    }    @Test    public void getUserById(){        SqlSession session=MybatisUtils.getSession();        UserMapper mapper=session.getMapper(UserMapper.class);        User user=mapper.getUserById(1);        System.out.println(user);        session.close();    }//增删改查需要提交事务    @Test    public void addUser(){        SqlSession session=MybatisUtils.getSession();        UserMapper mapper=session.getMapper(UserMapper.class);        int res=mapper.addUser(new User(4,"嘿嘿","123456"));        if(res&gt;0){            System.out.println("插入成功！");        }        session.commit();        session.close();    }    @Test    public void updateUser(){        SqlSession session=MybatisUtils.getSession();        UserMapper mapper=session.getMapper(UserMapper.class);        int res=mapper.updateUser(new User(1,"杨赛雅","13456"));        if(res&gt;0){            System.out.println("修改成功！");        }        session.commit();        session.close();    }    @Test    public void deleteUser(){        SqlSession session=MybatisUtils.getSession();        UserMapper mapper=session.getMapper(UserMapper.class);        int res=mapper.deleteUser(1);        if(res&gt;0){            System.out.println("删除成功！");        }        session.commit();        session.close();    }    @Test    public void addUser2(){        SqlSession session=MybatisUtils.getSession();        UserMapper mapper=session.getMapper(UserMapper.class);        Map&lt;String,Object&gt;map=new HashMap&lt;String,Object&gt;();        map.put("userId",5);        map.put("userName","hello");        map.put("password","123456");        mapper.addUser2(map);        session.commit();        session.close();    }    @Test    public void getUserLike(){        SqlSession session=MybatisUtils.getSession();        UserMapper mapper=session.getMapper(UserMapper.class);        List&lt;User&gt; li=mapper.getUserLike("杨");        for (User user: li){            System.out.println(user);        }        session.commit();        session.close();    }    }</code></pre><p>也可以在mybatis-config.xml中引入外部配置文件</p><pre><code class="java">&lt;!--引入外部配置文件--&gt;    &lt;properties resource="db.properties"/&gt;    &lt;!--优先使用外部文件--&gt;    &lt;!--可以给实体类起别名--&gt;```    外部配置文件    ```java    driver=com.mysql.cj.jdbc.Driverurl=jdbc:mysql://localhost:3306/test1?useSSL=true&amp;useUnicode=true&amp;characterEncoding=utf8username=rootpassword=password```写的比较乱，其中含有我的增删改查的代码，去掉即可</code></pre>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring 数据库开发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring的下载</title>
      <link href="/2022/03/11/Spring%E7%9A%84%E4%B8%8B%E8%BD%BD/"/>
      <url>/2022/03/11/Spring%E7%9A%84%E4%B8%8B%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>从今天开始就要学习Spring了，从今天开始我就要更技术文了，以前写的东西太幼稚了，一言难尽啊，下面是Spring的下载，有什么不足之处还请大家指出来我都会努力改正的。</p><p>进入这个网站<a href="https://repo.spring.io/ui/native/release/org/springframework/spring/5.3.9/">https://repo.spring.io/ui/native/release/org/springframework/spring/5.3.9/</a></p><p>会进入这个页面<img src="https://img-blog.csdnimg.cn/7a38be9b8aff44a9acd7c33ee00e2203.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zu-5ZaU,size_20,color_FFFFFF,t_70,g_se,x_16" alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zu-5ZaU,size_20,color_FFFFFF,t_70,g_se,x_16"></p><p>&nbsp;点击左上角的压缩包进行下载就完成了</p><p><img src="https://img-blog.csdnimg.cn/cff4ac9f9a234881be49526bfa362f03.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zu-5ZaU,size_16,color_FFFFFF,t_70,g_se,x_16" alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6Zu-5ZaU,size_16,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> java开发框架 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IO+集合+泛型实现僵尸查询系统</title>
      <link href="/2022/01/19/IO+%E9%9B%86%E5%90%88+%E6%B3%9B%E5%9E%8B%E5%AE%9E%E7%8E%B0%E5%83%B5%E5%B0%B8%E6%9F%A5%E8%AF%A2%E7%B3%BB%E7%BB%9F/"/>
      <url>/2022/01/19/IO+%E9%9B%86%E5%90%88+%E6%B3%9B%E5%9E%8B%E5%AE%9E%E7%8E%B0%E5%83%B5%E5%B0%B8%E6%9F%A5%E8%AF%A2%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>昨天进行了小组考核，下面是我做的僵尸查询系统，这个查询系统具有增删改查，登录注册功能，用IO，集合和泛型实现，其中也有很多不足，欢迎大家在下面评论区指出，每一个评论我都会认真对待的。<br>下面是我做的僵尸查询系统<br>还有就是我用的相对路径，大家根据自己的路径来就好。</p><pre><code class="java">import java.io.*;import java.util.ArrayList;import java.util.Scanner;/*   名称   外形或特征    等级   紫僵     淡紫      一   白僵     白色      二   绿僵     绿色      三   毛僵     有毛      四   飞僵     会飞      五   游尸     会动      六   伏尸     不朽      七   不化     不化      八   猰羭     食人      九   后卿     厉害      十   赢勾     大将      十一   旱魃     变异      十二   将臣     吸血      十三*/public class ZombieManager {    public static void main(String[]args)throws IOException {        BufferedReader bff = new BufferedReader(new FileReader("User.txt"));        ArrayList&lt;User&gt; sign = new ArrayList&lt;&gt;();        String file;        int flag = 0;        int simple=0,repeat=0;        while ((file = bff.readLine()) != null) {            String[] stringSign = file.split(",");            User u = new User();            u.setUsername(stringSign[0]);            u.setPassword(stringSign[1]);            sign.add(u);        }        bff.close();        System.out.println("======注册请输入1======\n======登录请输入2======\n---请输入你的选择，输入其他选则可能会发生错误---\n");        Scanner reader = new Scanner(System.in);        int re = reader.nextInt();        if (re == 1) {           do{            System.out.println("请输入你的名字\n");            Scanner rea = new Scanner(System.in);            String username = rea.nextLine();            for (int f = 0; f &lt; sign.size(); f++) {                User zo = sign.get(f);                if (!zo.getUsername().equals(username)&amp;&amp;f==(sign.size()-1))                    repeat = 2;                if(zo.getUsername().equals(username)) {                    System.out.println("输入名字与其他用户重名，请重新输入！");                    break;                }            }            if (repeat == 2) {                System.out.println("请输入你的密码\n");                Scanner read = new Scanner(System.in);                String password = read.nextLine();                User u = new User();                u.setUsername(username);                u.setPassword(password);                sign.add(u);                System.out.println("注册成功！");                BufferedWriter bw = new BufferedWriter(new FileWriter("User.txt"));                for (User us : sign) {                    StringBuilder strB = new StringBuilder();   //String类型的字符串是常量，字符串创建出来后不允许修改，而StringBuilder类型的字符串是可修改的                    strB.append(us.getUsername()).append(",").append(us.getPassword());//append()方法相当于+，将指定字符串追加到此字符序列                    bw.write(strB.toString());                    bw.newLine();                    bw.flush();                }                bw.close();                repeat=3;            }        }while(repeat == 0);        }        if (re == 2) {            BufferedReader bfr = new BufferedReader(new FileReader("User.txt"));            sign.clear();            String fil;            while ((fil = bfr.readLine()) != null) {                String[] stringSign = fil.split(",");                User us = new User();                us.setUsername(stringSign[0]);                us.setPassword(stringSign[1]);                sign.add(us);            }            while(flag!=1) {                System.out.println("请输入正确的名字");                Scanner rea = new Scanner(System.in);                String username = rea.nextLine();                for (int j = 0; j &lt; sign.size(); j++) {                    User u = sign.get(j);                    if (u.getUsername().equals(username)) {                        System.out.println("名字正确！");                        simple = 1;                        break;                    }                }                while(simple==1){                    System.out.println("请输入正确的密码");                    String password = rea.nextLine();                    for (int j = 0; j &lt; sign.size(); j++) {                        User u = sign.get(j);                        if (u.getPassword().equals(password)) {                            System.out.println("密码正确！");                            flag = 1;                            break;                        }                    }                    if(flag==1) break;                }            }            bfr.close();        }        else if(re != 1&amp;&amp;re!=2) System.out.println("请选择！！！");        ArrayList&lt;Zombie&gt; array = new ArrayList&lt;&gt;();        if (flag ==1) {            while (true) {        //while死循环,用while(1){}会报错                System.out.println("======亲爱的小道士，欢迎来到僵尸查询系统======");                System.out.println("（请注意，如果僵尸仓库里没有僵尸，则在查找僵尸时将会出现错误）");                System.out.println("1.录入僵尸");                System.out.println("2.删除僵尸");                System.out.println("3.修改僵尸");                System.out.println("4.查找僵尸");                System.out.println("5.退出当前页面");                System.out.println("----=请输入你要进行的操作=-----");                BufferedReader br = new BufferedReader(new FileReader("Zombie.txt"));                array.clear();                String row;                while ((row = br.readLine()) != null) {                    String[] stringArray = row.split(",");                    Zombie z = new Zombie();                    z.setName(stringArray[0]);                    z.setShape(stringArray[1]);                    z.setGrade(stringArray[2]);                    array.add(z);                }                Scanner sc = new Scanner(System.in);                String aline = sc.nextLine();                switch (aline) {                    case "1":                        addZombie(array);                        break;                    case "2":                        deleteZombie(array);                        break;                    case "3":                        modifyZombie(array);                        break;                    case "4":                        seekZombie(array);                        break;                    case "5":                        System.out.println("谢谢使用，祝愿小道士能抓到更多僵尸来维护世界和平");                        System.exit(0);  //退出虚拟机  System.exit（0）正常退出，程序正常执行结束退出 System.exit（1）非正常退出，无论程序正在执行与否，都退出                }            }        }    }        public static void addZombie (ArrayList &lt; Zombie &gt; array)throws IOException {            System.out.println("请小道士认真录入，僵尸名称和外形特征和等级一定要符合规范");            Scanner sc = new Scanner(System.in);            //注：输入僵尸名称时记得在名称后面加上数字，以便辨别每一个僵尸            System.out.println("请输入僵尸名称");            String name = sc.nextLine();            System.out.println("请输入僵尸外形或特征");        //注：输入外形或特征时记得在外形或特征后面加上数字，以便识别每一位僵尸            String shape = sc.nextLine();                    //小道士,每一个僵尸都是独一无二的            System.out.println("请输入僵尸等级");            String grade = sc.nextLine();            Zombie z = new Zombie();            z.setName(name);            z.setShape(shape);            z.setGrade(grade);            array.add(z);            System.out.println("录入成功");            BufferedWriter bw = new BufferedWriter(new FileWriter("Zombie.txt"));            for (Zombie zom : array) {                StringBuilder strB = new StringBuilder();   //String类型的字符串是常量，字符串创建出来后不允许修改，而StringBuilder类型的字符串是可修改的                strB.append(zom.getName()).append(",").append(zom.getShape()).append(",").append(zom.getGrade());                bw.write(strB.toString());                bw.newLine();                bw.flush();            }            bw.close();        }        public static void seekZombie (ArrayList &lt; Zombie &gt; array)throws IOException {            BufferedReader br = new BufferedReader(new FileReader("Zombie.txt"));            array.clear();            String aline;            while ((aline = br.readLine()) != null) {                String[] stringArray = aline.split(",");                Zombie z = new Zombie();                z.setName(stringArray[0]);                z.setShape(stringArray[1]);                z.setGrade(stringArray[2]);                array.add(z);            }            if (array.size() == 0) {                System.out.println("---小道士，僵尸仓库空空如也呢，请先录入僵尸哦---");            } else {                System.out.println("请输入你想要查找的僵尸的-名称-或-外形和特征-\n如果你想要通过名称查找请输入 1\n如果你想要通过外形或特征查找请输入 2\n如果你想要查看所有僵尸请输入3\n");                Scanner sc = new Scanner(System.in);                Integer na = sc.nextInt();                if (na == 1) {                    System.out.println("请输入你想要查找的僵尸的名称\n请注意，如果输入名称不存在，则可能会出现一些错误，所以请小道士输入正确的名称\n");                    Scanner sca = new Scanner(System.in);                    String name = sca.nextLine();                    for (int j = 0; j &lt; array.size(); j++) {                        Zombie zo = array.get(j);                        if (zo.getName().equals(name)) {                            System.out.println("名称\t外形\t等级\t");                            System.out.println(zo.getName() + "\t" + zo.getShape() + "\t" + zo.getGrade());                            break;                        }                    }                }                if (na == 2) {                    System.out.println("请输入你想要查找的僵尸的外形或特征\n请注意，如果输入的外形或特征不存在，则可能会出现一些错误，所以请小道士输入正确的外形或特征\n");                    Scanner sca = new Scanner(System.in);                    String shape = sca.nextLine();                    for (int j = 0; j &lt; array.size(); j++) {                        Zombie zo = array.get(j);                        if (zo.getShape().equals(shape)) {                            System.out.println("名称\t外形\t等级\t");                            System.out.println(zo.getName() + "\t" + zo.getShape() + "\t" + zo.getGrade());                            break;                        }                    }                }                if (na == 3) {                    System.out.println("名称\t外形\t等级\t");                    for (int i = 0; i &lt; array.size(); i++) {                        Zombie z = array.get(i);                        System.out.println(z.getName() + "\t" + z.getShape() + "\t" + z.getGrade());                    }                }            }            br.close();        }        public static void deleteZombie (ArrayList &lt; Zombie &gt; array)throws IOException {            BufferedReader br = new BufferedReader(new FileReader("Zombie.txt"));            array.clear();            String aline;            while ((aline = br.readLine()) != null) {                String[] stringArray = aline.split(",");                Zombie z = new Zombie();                z.setName(stringArray[0]);                z.setShape(stringArray[1]);                z.setGrade(stringArray[2]);                array.add(z);            }            Scanner sc = new Scanner(System.in);            System.out.println("如果你想要通过僵尸的名字删除僵尸请输入1\n如果你想要通过僵尸的外形或特征来删除僵尸请输入2\n如果你想要删除所有僵尸请输入3\n如果你突然不想删了就输入4\n");            Integer na = sc.nextInt();            if (na == 1) {                System.out.println("小道士，请输入你想要删除的僵尸的名称\n请注意，如果输入的名称不存在，则可能会出现一些错误，所以请小道士输入正确的名称\n");                Scanner rd = new Scanner(System.in);                String name = rd.nextLine();                for (int j = 0; j &lt; array.size(); j++) {                    Zombie zo = array.get(j);                    if (zo.getName().equals(name)) {                        array.remove(j);                        break;                    }                }                System.out.println("删除僵尸成功");            }            if (na == 2) {                System.out.println("小道士，请输入你想要删除的僵尸的外形或特征\n请注意，如果输入的外形或特征不存在，则可能会出现一些错误，所以请小道士输入正确的外形或特征\n");                Scanner rd = new Scanner(System.in);                String shape = rd.nextLine();                for (int h = 0; h &lt; array.size(); h++) {                    Zombie zo = array.get(h);                    if (zo.getShape().equals(shape)) {                        array.remove(h);                        break;                    }                }                System.out.println("删除僵尸成功");            }            if (na == 3) {                array.clear();                System.out.println("删除僵尸成功");            }            if(na==4){                System.out.println(" ");            }            BufferedWriter bw = new BufferedWriter(new FileWriter("Zombie.txt"));            for (Zombie zom : array) {                StringBuilder strBuilder = new StringBuilder();                strBuilder.append(zom.getName()).append(",").append(zom.getShape()).append(",").append(zom.getGrade());                bw.write(strBuilder.toString());                bw.newLine();                bw.flush();            }            bw.close();        }        public static void modifyZombie (ArrayList &lt; Zombie &gt; array) throws IOException {        //修改僵尸modify            BufferedReader br = new BufferedReader(new FileReader("Zombie.txt"));            array.clear();            String aline;            while ((aline = br.readLine()) != null) {                String[] stringArray = aline.split(",");                Zombie z = new Zombie();                z.setName(stringArray[0]);                z.setShape(stringArray[1]);                z.setGrade(stringArray[2]);                array.add(z);            }            System.out.println("亲爱的小道士\n如果你想要通过僵尸的名称来修改僵尸请输入1\n如果你想要通过僵尸的外形或特征来修改僵尸请输入2\n");            Scanner sc = new Scanner(System.in);            Integer na = sc.nextInt();            if (na == 1) {                System.out.println("小道士，输入你想要修改的僵尸的名称\n请注意，如果输入的名称不存在，则可能会出现一些错误，所以请小道士输入正确的名称\n");                Scanner sc1 = new Scanner(System.in);                String name = sc1.nextLine();                System.out.println("请输入僵尸的新名称");                String newName = sc1.nextLine();                System.out.println("请输入僵尸的新外形或特征");                String newShape = sc1.nextLine();                System.out.println("请输入僵尸的新的等级");                String newGrade = sc1.nextLine();                //根据输入的新的信息创建zombie的对象，因为下面是用的getName（）方法                Zombie zo = new Zombie();                zo.setName(newName);                zo.setShape(newShape);                zo.setGrade(newGrade);                for (int a = 0; a &lt; array.size(); a++) {                    Zombie zom = array.get(a);                    if (zom.getName().equals(name)) {                        array.set(a, zo);    //因为要修改这三个信息，所以用zo，而不是nameNew                        break;                    }                }            }            if (na == 2) {                System.out.println("小道士，输入你想要修改的僵尸的外形或特征\n请注意，如果输入的外形或特征不存在，则可能会出现一些错误，所以请小道士输入正确的外形或特征\n");                Scanner sc1 = new Scanner(System.in);                String shape = sc1.nextLine();                System.out.println("请输入僵尸的新名称");                String newName = sc1.nextLine();                System.out.println("请输入僵尸的新外形或特征");                String newShape = sc1.nextLine();                System.out.println("请输入僵尸的新的等级");                String newGrade = sc1.nextLine();                //根据输入的新的信息创建zombie的对象，因为下面是用的getShape()                Zombie zo = new Zombie();                zo.setName(newName);                zo.setShape(newShape);                zo.setGrade(newGrade);                for (int a = 0; a &lt; array.size(); a++) {                    Zombie zom = array.get(a);                    if (zom.getShape().equals(shape)) {                        array.set(a, zo);    //因为要修改这三个信息，所以用zo，而不是nameNew,zo中包含了这三个信息                        break;                    }                }            }            System.out.println("修改僵尸成功");            BufferedWriter bw = new BufferedWriter(new FileWriter("Zombie.txt"));            for (Zombie zom : array) {                StringBuilder strBuilder = new StringBuilder();                strBuilder.append(zom.getName()).append(",").append(zom.getShape()).append(",").append(zom.getGrade());                bw.write(strBuilder.toString());                bw.newLine();                bw.flush();            }            bw.close();        }}</code></pre><p>其中我并没有对抛出的异常进行处理，代码也比较臃肿，学长也给我提了一些很有用的建议，大家可以根据喜好改进使用我的代码。<br>下面的是两个类：<br>用户类</p><pre><code class="java">public class User {    private String username;    private String password;    public User(){}    public User(String username,String password){        this.username=username;        this.password=password;    }    public String getUsername() {        return username;    }    public void setUsername(String username) {        this.username=username;    }    public String getPassword(){        return password;    }    public void setPassword(String password){        this.password=password;    }}</code></pre><p>僵尸类</p><pre><code class="java">public class Zombie {    private String name;    private String shape;    private String grade;    public Zombie() {}    public Zombie(String name,String shape,String grade) {        this.name=name;        this.shape=shape;        this.grade=grade;    }    public String getName() {        return name;    }    public void setName(String name) {        this.name=name;    }    public String getShape() {        return shape;    }    public void setShape(String shape) {        this.shape=shape;    }    public String getGrade() {        return grade;    }    public void setGrade(String grade) {        this.grade=grade;    }}</code></pre><p>我还只是小白QWQ，里面存在的一些BUG或大家给我的建议都欢迎在下面评论区写出。</p>]]></content>
      
      
      <categories>
          
          <category> java基础 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>io实现登录注册功能+本周总结</title>
      <link href="/2022/01/16/io%E5%AE%9E%E7%8E%B0%E7%99%BB%E5%BD%95%E6%B3%A8%E5%86%8C%E5%8A%9F%E8%83%BD+%E6%9C%AC%E5%91%A8%E6%80%BB%E7%BB%93/"/>
      <url>/2022/01/16/io%E5%AE%9E%E7%8E%B0%E7%99%BB%E5%BD%95%E6%B3%A8%E5%86%8C%E5%8A%9F%E8%83%BD+%E6%9C%AC%E5%91%A8%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><p>这周快结束了，嗯，今天周日。</p><ul><li><p>学习篇<br>小组布置了考核任务，用io做一个系统，我就做了一个僵尸查询系统，不仅仅是为了完成考核任务，也是怀念我的童年，怀念以前的僵尸电影，怀念英叔。系统我用了集合和文件，从集合到文件，从文件到集合，敲代码的过程中也遇到了很多困难，有时候改bug一改就改一下午，也很无奈，最后实在改不了的就向学长寻求帮助，最后系统还是做好了，虽然有十几个警告。。。但能运行（￣▽￣）／</p></li><li><p>生活篇<br>我发现在家里认真学习学习效率还挺高的<br>下面是我用io实现登录注册功能，其中有一些地方写的不太好的地方，希望大家帮忙指出来，谢谢啦～<br>import java.io.*;<br>import java.util.ArrayList;<br>import java.util.Scanner;</p></li></ul><p>public class UserSign {<!-- --><br>public static void main(String[]args) throws IOException {<!-- --><br>BufferedReader bff=new BufferedReader(new FileReader(“User.txt”));<br>ArrayListsign=new ArrayList&lt;&gt;();<br>sign.clear();<br>String file;<br>boolean flag=false;<br>while((file=bff.readLine())!=null){<!-- --><br>String[]stringSign=file.split(“,”);<br>User u=new User();<br>u.setUsername(stringSign[0]);<br>u.setPassword(stringSign[1]);<br>sign.add(u);<br>}<br>bff.close();<br>System.out.println(“注册请输入1\n登录请输入2”);<br>Scanner reader = new Scanner(System.in);<br>int re = reader.nextInt();<br>if (re == 1) {<!-- --><br>System.out.println(“请输入正确的名字\n”);<br>Scanner rea = new Scanner(System.in);<br>String username = rea.nextLine();<br>System.out.println(“请输入正确的密码”);<br>String password = rea.nextLine();<br>User u = new User();<br>u.setUsername(username);<br>u.setPassword(password);<br>sign.add(u);<br>System.out.println(“注册成功！”);<br>BufferedWriter bw = new BufferedWriter(new FileWriter(“User.txt”));<br>for (User us : sign) {<!-- --><br>StringBuilder strB = new StringBuilder(); //String类型的字符串是常量，字符串创建出来后不允许修改，而StringBuilder类型的字符串是可修改的<br>strB.append(us.getUsername()).append(“,”).append(us.getPassword());<br>bw.write(strB.toString());<br>bw.newLine();<br>bw.flush();<br>}<br>bw.close();<br>}<br>if (re == 2) {<!-- --><br>BufferedReader bfr=new BufferedReader(new FileReader(“User.txt”));<br>sign.clear();<br>String fil;<br>while((fil=bfr.readLine())!=null){<!-- --><br>String[]stringSign=fil.split(“,”);<br>User us=new User();<br>us.setUsername(stringSign[0]);<br>us.setPassword(stringSign[1]);<br>sign.add(us);<br>}<br>System.out.println(“请输入你的名字”);<br>Scanner rea = new Scanner(System.in);<br>String username = rea.nextLine();<br>for (int j = 0; j &lt; sign.size(); j++) {<!-- --><br>User u = sign.get(j);<br>if (u.getUsername().equals(username)) {<!-- --><br>System.out.println(“名字正确！”);<br>break;<br>}<br>}<br>System.out.println(“请输入你的密码”);<br>String password = rea.nextLine();<br>for (int j = 0; j &lt; sign.size(); j++) {<!-- --><br>User u = sign.get(j);<br>if (u.getPassword().equals(password)) {<!-- --><br>System.out.println(“密码正确！”);<br>break;<br>}<br>}<br>bfr.close();<br>flag=true;<br>}</p><pre><code>}</code></pre><p>}</p>]]></content>
      
      
      <categories>
          
          <category> java基础 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
